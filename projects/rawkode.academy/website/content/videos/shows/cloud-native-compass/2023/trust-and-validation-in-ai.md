---
id: trust-and-validation-in-ai
slug: trust-and-validation-in-ai
title: Trust and Validation in AI
description: "Here are 5 key takeaways from this episode that you don't want to miss:\n\n1️⃣ The People Problem: Laura Santamaria raises an important concern about verifying AI-generated outputs and tackling the challenge of the \"people problem\" in AI development.\n\n2️⃣ Verifying Data Authenticity: JJ discusses the challenge of proving that a data blob originated from a specific model and how this issue is being addressed by companies like IBM through pile cleaning and legal penalties.\n\n3️⃣ AI Misconceptions: We debunk some common misconceptions about AI, including the belief that it is an all-knowing fact machine.\n\n4️⃣ Trusted AI: IBM's approach to building trusted models, with dedicated engineers responsible for cleaning and verifying data, is explained. Plus, we discover IBM's partnerships with Hugging Face to leverage the open-source ecosystem.\n\n5️⃣ The Impact of AI: We delve into the potential positive and negative implications of AI, and how the rapid advancement of this technology presents challenges with trust and validation.\n\n\U0001F4A1 Fun Fact: Did you know that 95% of open-source language models are trained on a data set called \"the pile,\" which contains pirated and copyrighted material? Discover why this has implications for copyright and patent laws!\n\nAs always, the conversation in this episode is engaging and eye-opening. JJ Asghar provides insightful perspectives and sheds light on the future of AI development. Don't miss out on the valuable information shared!\n\nQuestions We Covered\n\n1. How can the problem of untrusted data in AI models be effectively addressed?\n2. Should companies like OpenAI and Microsoft be required to provide their data sets for verification purposes? Why or why not?\n3. What are the potential risks and challenges associated with using AI technology without proper regulation?\n4. Should AI creations be eligible for copyright protection? Why or why not?\n5. How can we ensure the accuracy and trustworthiness of AI-generated data, especially when it comes to extracting information from sources like PDFs?\n6. What are some potential positive impacts of AI technology, and how can we maximize its benefits while minimizing its negative implications?\n7. How can the rapid advancement of AI technology be balanced with the need for trust and validation?\n8. In what ways do copyright and patent laws need to evolve to accommodate AI technology?\n9. What are the implications of China having its own set of laws and approaches to technology that may differ from other countries?\n10. How can individuals navigate and better understand the AI space in order to make informed decisions and contributions?\n\nTimestamps\n\n00:00 Introductions\n02:14 What is watsonx?\n05:30 AI for the Enterprise\n07:00 AI as a Yes Man\n11:20 The Wikipedia AI Challenge\n19:05 AI Needs Trust\n27:20 People Problem in AI\n29:20 Ethical Dilemmas\n40:20 Final Thoughts"
publishedAt: 2023-11-01T17:00:00.000Z
technologies: []
show: cloud-native-compass
videoId: ce0y3h3wgv2vt9m4rcux1s7x
chapters:
  - startTime: 0
    title: Introductions
  - startTime: 7
    title: Host Introductions and Episode Topic
  - startTime: 21
    title: 'AI in Practice: Kubernetes Sonnet'
  - startTime: 81
    title: 'Introducing the Guest, JJ Asgar'
  - startTime: 94
    title: JJ's Role and Introduction to IBM WatsonX.ai
  - startTime: 134
    title: What is watsonx?
  - startTime: 228
    title: Why Enterprises Distrust Current AI (The Black Box Problem)
  - startTime: 330
    title: AI for the Enterprise
  - startTime: 360
    title: 'WatsonX: The Trusted Enterprise AI Solution (Napster vs iTunes)'
  - startTime: 420
    title: AI as a Yes Man
  - startTime: 428
    title: 'Developer Concerns: Bias and Data Augmentation'
  - startTime: 504
    title: Understanding AI Models and Foundational Data
  - startTime: 556
    title: 'Open Source AI: Hugging Face and The Pile'
  - startTime: 674
    title: The Pile's Data Quality & Legal Issues (Copyright/Licensing)
  - startTime: 680
    title: The Wikipedia AI Challenge
  - startTime: 741
    title: 'Copyright, Patents, and Industry Fragility'
  - startTime: 874
    title: Why Public Data (Wikipedia) Isn't Ideal for Training
  - startTime: 933
    title: 'Practical Enterprise Use Case: The AI Librarian'
  - startTime: 1046
    title: The Human Problem of Verification and Hallucinations
  - startTime: 1145
    title: AI Needs Trust
  - startTime: 1208
    title: IBM's Data Cleaning and Trust Strategy
  - startTime: 1305
    title: IBM's B2B API Approach ("Red Solo Cups of AI")
  - startTime: 1391
    title: 'Specific Use Case: Kubernetes Monitoring'
  - startTime: 1611
    title: The Challenge of Proving Data Origin and Trust
  - startTime: 1640
    title: People Problem in AI
  - startTime: 1760
    title: Ethical Dilemmas
  - startTime: 1838
    title: Ethical Dilemmas and AI Transparency
  - startTime: 2156
    title: The "Printing Press" Analogy and Global Impact
  - startTime: 2279
    title: Reflections and Hope for the Future
  - startTime: 2420
    title: Final Thoughts
  - startTime: 2441
    title: Guest Final Thoughts & Contact Information
  - startTime: 2535
    title: Hosts' Wrap-up and Outro
duration: 2591
---

