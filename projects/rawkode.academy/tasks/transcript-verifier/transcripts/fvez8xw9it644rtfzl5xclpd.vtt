WEBVTT

NOTE
Transcription provided by Deepgram
Request Id: 74c3e1bc-5612-4fe4-b131-e78e2e0ff772
Created: 2025-04-29T17:13:33.599Z
Duration: 5142.089
Channels: 1

00:00:48.990 --> 00:00:49.710
<v Speaker 0>Hello,

00:00:49.950 --> 00:00:52.430
<v Speaker 0>and welcome back to the Rawkode Academy. This

00:00:52.430 --> 00:00:54.670
<v Speaker 0>is Rawkode Live and I am your host

00:00:54.670 --> 00:00:55.630
<v Speaker 0>Rawkode.

00:00:55.710 --> 00:00:57.230
<v Speaker 0>I've now said my name three times in

00:00:57.230 --> 00:00:58.670
<v Speaker 0>ten seconds and I hate it.

00:00:59.070 --> 00:01:01.095
<v Speaker 0>Today, we are taking a look at an

00:01:01.095 --> 00:01:04.215
<v Speaker 0>open source project to bring continuous profiling to

00:01:04.215 --> 00:01:04.854
<v Speaker 0>everyone.

00:01:05.095 --> 00:01:07.015
<v Speaker 0>The project is called Parca and we are

00:01:07.015 --> 00:01:08.695
<v Speaker 0>joined by the CEO.

00:01:08.854 --> 00:01:10.695
<v Speaker 0>Hey, I turned that little video off.

00:01:14.020 --> 00:01:15.460
<v Speaker 0>Alright. I'm just gonna ignore it. I'm gonna

00:01:15.460 --> 00:01:18.500
<v Speaker 0>pop over here where I'm just put

00:01:18.500 --> 00:01:21.220
<v Speaker 0>myself off now. I'm joined by the CEO

00:01:21.460 --> 00:01:22.500
<v Speaker 0>and founder,

00:01:22.500 --> 00:01:23.620
<v Speaker 0>Polar Signals,

00:01:23.700 --> 00:01:25.780
<v Speaker 0>Frederic Brancic. Hey, man. How's it going?

00:01:26.605 --> 00:01:28.205
<v Speaker 1>Hey. Pretty good.

00:01:29.085 --> 00:01:30.525
<v Speaker 0>See, you know, I say at the start,

00:01:30.525 --> 00:01:31.965
<v Speaker 0>don't worry if things go wrong. It happens

00:01:31.965 --> 00:01:33.485
<v Speaker 0>all the time. It's usually me. In fact,

00:01:33.485 --> 00:01:35.165
<v Speaker 0>it's it's always me. I just break stuff

00:01:35.165 --> 00:01:36.525
<v Speaker 0>every single episode.

00:01:37.645 --> 00:01:39.965
<v Speaker 0>So thank you for for joining us today.

00:01:39.965 --> 00:01:42.390
<v Speaker 0>For anyone who's not familiar with yourself, can

00:01:42.390 --> 00:01:43.430
<v Speaker 0>you give us just a a little bit

00:01:43.430 --> 00:01:45.030
<v Speaker 0>of a hello and an introduction, and then

00:01:45.030 --> 00:01:47.110
<v Speaker 0>we'll take it from there? Of course.

00:01:47.510 --> 00:01:48.150
<v Speaker 1>Yeah.

00:01:48.390 --> 00:01:50.150
<v Speaker 1>First of all, thank you for having me.

00:01:50.230 --> 00:01:53.190
<v Speaker 1>So, yeah, I'm I'm Frederick. I founded

00:01:53.190 --> 00:01:53.990
<v Speaker 1>Polar Signals.

00:01:54.455 --> 00:01:57.895
<v Speaker 1>I've been part of the, like, cloud native

00:01:58.135 --> 00:01:59.015
<v Speaker 1>ecosystem

00:01:59.015 --> 00:02:00.135
<v Speaker 1>for, gosh,

00:02:01.175 --> 00:02:02.455
<v Speaker 1>six, seven years.

00:02:03.495 --> 00:02:04.375
<v Speaker 1>I was,

00:02:04.535 --> 00:02:05.575
<v Speaker 1>part of the,

00:02:06.215 --> 00:02:08.535
<v Speaker 1>I joined the Prometheus team in

00:02:08.615 --> 00:02:10.900
<v Speaker 1>twenty sixteen sixteen as a maintainer.

00:02:10.979 --> 00:02:13.380
<v Speaker 1>Basically, like, I think a a few months

00:02:13.380 --> 00:02:16.420
<v Speaker 1>after Prometheus had joined as the second CNCF

00:02:16.420 --> 00:02:17.140
<v Speaker 1>project

00:02:17.700 --> 00:02:18.980
<v Speaker 1>of all time.

00:02:20.420 --> 00:02:22.900
<v Speaker 1>So, yeah, I've been around for a while.

00:02:22.900 --> 00:02:24.835
<v Speaker 1>And as I said, Prometheus was kind of

00:02:24.835 --> 00:02:26.035
<v Speaker 1>my entry point,

00:02:26.275 --> 00:02:29.075
<v Speaker 1>but I kind of was in charge for

00:02:29.075 --> 00:02:30.835
<v Speaker 1>all things that connected

00:02:30.915 --> 00:02:33.715
<v Speaker 1>Prometheus and Kubernetes. And so to this day,

00:02:33.715 --> 00:02:34.835
<v Speaker 1>I'm actually still

00:02:35.155 --> 00:02:36.355
<v Speaker 1>maintainer for

00:02:37.220 --> 00:02:40.100
<v Speaker 1>the Kubernetes integrations in Prometheus.

00:02:40.340 --> 00:02:41.460
<v Speaker 1>And over time,

00:02:43.220 --> 00:02:45.860
<v Speaker 1>I I also I I co created, but

00:02:45.860 --> 00:02:49.300
<v Speaker 1>also eventually became the tech lead of the

00:02:49.379 --> 00:02:52.019
<v Speaker 1>special interest group for instrumentation in Kubernetes.

00:02:53.515 --> 00:02:55.515
<v Speaker 1>After, I think, four or five years of

00:02:55.515 --> 00:02:57.435
<v Speaker 1>service, I recently

00:02:58.555 --> 00:03:01.035
<v Speaker 1>handed off that that position to

00:03:01.275 --> 00:03:03.435
<v Speaker 1>make room for some new blood. But,

00:03:05.050 --> 00:03:05.690
<v Speaker 1>yeah,

00:03:06.010 --> 00:03:08.970
<v Speaker 1>kind of that that that intersection of Prometheus

00:03:08.970 --> 00:03:11.370
<v Speaker 1>or more generally observability

00:03:11.370 --> 00:03:12.010
<v Speaker 1>and

00:03:12.490 --> 00:03:14.730
<v Speaker 1>Kubernetes has been has been my thing for

00:03:14.730 --> 00:03:15.530
<v Speaker 1>a very long time.

00:03:17.465 --> 00:03:20.025
<v Speaker 1>I originally started doing all of this when

00:03:20.025 --> 00:03:22.584
<v Speaker 1>I joined CoreOS. I don't know if people

00:03:22.584 --> 00:03:24.105
<v Speaker 1>still remember CoreOS,

00:03:24.105 --> 00:03:24.665
<v Speaker 1>but

00:03:26.345 --> 00:03:28.665
<v Speaker 1>after the CoreOS acquisition by Red Hat, I

00:03:28.665 --> 00:03:30.504
<v Speaker 1>kind of stuck around at Red Hat for

00:03:30.504 --> 00:03:32.750
<v Speaker 1>a while. I became architect for all things

00:03:32.750 --> 00:03:33.870
<v Speaker 1>observability.

00:03:34.750 --> 00:03:36.750
<v Speaker 1>And kind of long story short is that

00:03:36.750 --> 00:03:38.190
<v Speaker 1>I eventually quit

00:03:38.350 --> 00:03:40.510
<v Speaker 1>Red Hat to found Polar Signals because I

00:03:40.510 --> 00:03:43.550
<v Speaker 1>felt like there was something about continuous profiling

00:03:43.550 --> 00:03:44.990
<v Speaker 1>that was worth pursuing.

00:03:47.035 --> 00:03:47.675
<v Speaker 0>Awesome.

00:03:47.915 --> 00:03:49.915
<v Speaker 0>Yeah. That's a a really good overview of

00:03:49.915 --> 00:03:50.715
<v Speaker 0>your history.

00:03:51.675 --> 00:03:53.515
<v Speaker 0>You're you're you've got one of those usernames

00:03:53.515 --> 00:03:55.515
<v Speaker 0>and faces that because you were so active

00:03:55.515 --> 00:03:56.635
<v Speaker 0>in the Prometheus

00:03:56.715 --> 00:03:59.170
<v Speaker 0>ecosystem and community. That, you know, I see

00:03:59.170 --> 00:04:01.329
<v Speaker 0>your little avatar on GitHub all the time,

00:04:01.329 --> 00:04:01.970
<v Speaker 0>and then,

00:04:02.609 --> 00:04:04.689
<v Speaker 0>yeah, you started showing up on a doing

00:04:04.689 --> 00:04:06.370
<v Speaker 0>a lot of KubeCon talks and other com

00:04:06.530 --> 00:04:09.409
<v Speaker 0>talks talking about observability instrumentation.

00:04:09.409 --> 00:04:12.415
<v Speaker 0>I think the Prometheus operator as well. It's

00:04:12.415 --> 00:04:13.455
<v Speaker 0>great to have you on the show and

00:04:13.455 --> 00:04:15.535
<v Speaker 0>I'm really looking forward to taking a look

00:04:15.535 --> 00:04:16.894
<v Speaker 0>at Parca and what you've been working on

00:04:16.894 --> 00:04:18.095
<v Speaker 0>for the last little while.

00:04:20.015 --> 00:04:21.535
<v Speaker 0>So I guess,

00:04:22.175 --> 00:04:25.375
<v Speaker 0>I've said that Parker brings continuous profile

00:04:25.639 --> 00:04:27.000
<v Speaker 0>but could we dive into that a little

00:04:27.000 --> 00:04:28.440
<v Speaker 0>bit more and just understand

00:04:28.760 --> 00:04:30.040
<v Speaker 0>what is Parca?

00:04:30.360 --> 00:04:32.120
<v Speaker 0>What are its main components? And and what

00:04:32.120 --> 00:04:33.880
<v Speaker 0>do people get out of deploying Parca to

00:04:33.880 --> 00:04:34.760
<v Speaker 0>their infrastructure?

00:04:35.400 --> 00:04:38.120
<v Speaker 1>Yeah. Maybe maybe before we dive into Parca

00:04:38.120 --> 00:04:40.485
<v Speaker 1>as a project itself, maybe let's talk a

00:04:40.485 --> 00:04:42.885
<v Speaker 1>little bit about continuous profiling because I think

00:04:42.885 --> 00:04:44.885
<v Speaker 1>it's still an emerging

00:04:47.125 --> 00:04:48.245
<v Speaker 1>methodology.

00:04:49.525 --> 00:04:50.245
<v Speaker 1>So

00:04:51.045 --> 00:04:54.500
<v Speaker 1>while hype hyperscalers have been doing this strategy

00:04:54.500 --> 00:04:58.260
<v Speaker 1>for almost a decade, it was pretty inaccessible

00:04:58.260 --> 00:05:00.420
<v Speaker 1>to to most other companies, and that that

00:05:00.420 --> 00:05:02.820
<v Speaker 1>is what we're trying to fix with with

00:05:02.820 --> 00:05:06.260
<v Speaker 1>the Parca project. But continuous profiling in its

00:05:06.260 --> 00:05:07.540
<v Speaker 1>essence is

00:05:09.335 --> 00:05:13.335
<v Speaker 1>basically that we always profile absolutely everything in

00:05:13.335 --> 00:05:14.455
<v Speaker 1>our infrastructure.

00:05:15.175 --> 00:05:15.815
<v Speaker 1>And

00:05:16.375 --> 00:05:18.055
<v Speaker 1>this is useful

00:05:18.215 --> 00:05:18.935
<v Speaker 1>because

00:05:19.095 --> 00:05:21.655
<v Speaker 1>because of the same reasons why we generally

00:05:21.655 --> 00:05:24.139
<v Speaker 1>do profiling of our software. Right? We want

00:05:24.139 --> 00:05:26.860
<v Speaker 1>to understand where our resources spend, where is

00:05:26.860 --> 00:05:30.219
<v Speaker 1>my CPU time spend, where is my memory

00:05:30.219 --> 00:05:31.180
<v Speaker 1>being spent,

00:05:31.419 --> 00:05:34.860
<v Speaker 1>where are my memory allocations happening, or, really,

00:05:34.860 --> 00:05:35.740
<v Speaker 1>you can

00:05:36.060 --> 00:05:38.460
<v Speaker 1>think of profiling data

00:05:39.165 --> 00:05:40.445
<v Speaker 1>as anything

00:05:40.685 --> 00:05:43.325
<v Speaker 1>anything pass that you can possibly think of

00:05:43.325 --> 00:05:46.285
<v Speaker 1>where you can you have a stack trace,

00:05:46.285 --> 00:05:48.365
<v Speaker 1>and you attach a number to it. That's

00:05:48.365 --> 00:05:51.165
<v Speaker 1>basically what a profile is. Right? Just a

00:05:51.165 --> 00:05:52.605
<v Speaker 1>collection of many stack traces

00:05:53.140 --> 00:05:54.980
<v Speaker 1>with a number attached to it.

00:05:55.780 --> 00:05:57.780
<v Speaker 1>In the case of a CPU profile,

00:05:58.100 --> 00:06:00.740
<v Speaker 1>it's how often have we seen this particular

00:06:00.740 --> 00:06:03.620
<v Speaker 1>stack trace, and we translate that to time

00:06:03.620 --> 00:06:04.740
<v Speaker 1>spent in that function.

00:06:06.435 --> 00:06:09.395
<v Speaker 1>And so as I said, CPU profiles is

00:06:09.395 --> 00:06:12.115
<v Speaker 1>something that is really interesting because CPU tends

00:06:12.115 --> 00:06:14.435
<v Speaker 1>to be the most expensive thing in

00:06:14.755 --> 00:06:17.955
<v Speaker 1>in cloud environments, but memory is certainly

00:06:18.800 --> 00:06:20.800
<v Speaker 1>a next contender or

00:06:20.800 --> 00:06:21.520
<v Speaker 1>network

00:06:22.080 --> 00:06:24.480
<v Speaker 1>network IO or, like,

00:06:24.720 --> 00:06:27.120
<v Speaker 1>disk IO. All of these are things that

00:06:27.120 --> 00:06:29.040
<v Speaker 1>contribute to cost.

00:06:29.040 --> 00:06:30.720
<v Speaker 1>And this is kind of a a good

00:06:30.720 --> 00:06:34.025
<v Speaker 1>segue to why why do people want to

00:06:34.025 --> 00:06:36.905
<v Speaker 1>do this? And the the most common answer

00:06:36.905 --> 00:06:39.705
<v Speaker 1>to that is people want to optimize their

00:06:39.705 --> 00:06:42.825
<v Speaker 1>cloud builds. And that's that's exactly why

00:06:42.905 --> 00:06:45.785
<v Speaker 1>companies like Google have been doing this kind

00:06:45.785 --> 00:06:47.705
<v Speaker 1>of methodology for over a decade.

00:06:48.889 --> 00:06:51.050
<v Speaker 1>They kind of identified, and I think it's

00:06:51.050 --> 00:06:53.850
<v Speaker 1>it's obvious once you say it. But once

00:06:53.850 --> 00:06:56.729
<v Speaker 1>you have that data about where your resources

00:06:56.729 --> 00:06:58.729
<v Speaker 1>are being spent down to the line number,

00:06:58.729 --> 00:07:01.449
<v Speaker 1>right, like, that's how granular profiling data is,

00:07:02.405 --> 00:07:04.645
<v Speaker 1>you can actually do something about it. If

00:07:04.645 --> 00:07:06.085
<v Speaker 1>you don't have that data, you just don't

00:07:06.085 --> 00:07:07.205
<v Speaker 1>know where to start.

00:07:08.165 --> 00:07:11.525
<v Speaker 1>And continuous profiling, as I said, is the

00:07:11.525 --> 00:07:13.925
<v Speaker 1>methodology of just always

00:07:14.405 --> 00:07:15.365
<v Speaker 1>doing profiling.

00:07:16.099 --> 00:07:18.419
<v Speaker 1>And there are a couple of things involved

00:07:18.419 --> 00:07:20.980
<v Speaker 1>in actually making that possible because

00:07:21.379 --> 00:07:24.099
<v Speaker 1>maybe maybe this is, like, something that's already,

00:07:24.099 --> 00:07:24.820
<v Speaker 1>you know,

00:07:25.460 --> 00:07:27.300
<v Speaker 1>a a question that was queued up in

00:07:27.300 --> 00:07:30.035
<v Speaker 1>your head. When typically, when we talk about

00:07:30.035 --> 00:07:32.995
<v Speaker 1>talk about or think about profiling, people immediately

00:07:32.995 --> 00:07:37.075
<v Speaker 1>think about overhead of profiling. Right? And

00:07:37.635 --> 00:07:39.955
<v Speaker 1>they wanna know, like, how much is doing

00:07:40.435 --> 00:07:42.995
<v Speaker 1>this actually going to cost me. Right?

00:07:45.000 --> 00:07:45.720
<v Speaker 1>And

00:07:45.880 --> 00:07:48.360
<v Speaker 1>the the answer to that is essentially

00:07:51.880 --> 00:07:52.520
<v Speaker 1>we

00:07:52.760 --> 00:07:55.560
<v Speaker 1>we we've developed a couple of

00:07:56.505 --> 00:07:57.465
<v Speaker 1>strategies

00:07:57.465 --> 00:08:00.185
<v Speaker 1>to reduce profiling overhead

00:08:00.505 --> 00:08:02.745
<v Speaker 1>so that we can always do this. And

00:08:02.745 --> 00:08:04.265
<v Speaker 1>there are there are kind of two

00:08:04.505 --> 00:08:06.745
<v Speaker 1>main things that are that are contributors to

00:08:06.745 --> 00:08:08.105
<v Speaker 1>this. One

00:08:08.345 --> 00:08:10.585
<v Speaker 1>is the type of profiling that we do,

00:08:11.510 --> 00:08:14.790
<v Speaker 1>and what we do is called sampling profiling.

00:08:16.150 --> 00:08:17.270
<v Speaker 1>And that essentially

00:08:17.670 --> 00:08:20.390
<v Speaker 1>we can think of it as how often

00:08:20.390 --> 00:08:22.870
<v Speaker 1>are we looking at this the current stack

00:08:22.870 --> 00:08:25.590
<v Speaker 1>traces, let's say, for a CPU profile.

00:08:28.035 --> 00:08:30.755
<v Speaker 1>And the obviously, the more often we sample

00:08:30.755 --> 00:08:32.115
<v Speaker 1>those stack traces,

00:08:32.515 --> 00:08:34.915
<v Speaker 1>the higher the overhead is going to be.

00:08:35.075 --> 00:08:36.515
<v Speaker 1>But we found that

00:08:36.915 --> 00:08:39.955
<v Speaker 1>for, like, looking a hundred times per second

00:08:40.434 --> 00:08:41.315
<v Speaker 1>is still

00:08:41.700 --> 00:08:44.340
<v Speaker 1>like, offers enough granularity,

00:08:44.900 --> 00:08:47.780
<v Speaker 1>at low very low overhead, something less than

00:08:47.780 --> 00:08:49.460
<v Speaker 1>a percent of overhead,

00:08:49.860 --> 00:08:51.300
<v Speaker 1>of a CPU core.

00:08:51.780 --> 00:08:53.380
<v Speaker 1>And the reality is,

00:08:54.260 --> 00:08:56.100
<v Speaker 1>once you have this type of data,

00:08:56.665 --> 00:09:00.105
<v Speaker 1>almost everyone we find has easy very easy

00:09:00.105 --> 00:09:00.985
<v Speaker 1>optimization

00:09:00.985 --> 00:09:03.865
<v Speaker 1>potential of, like, 10 to 30% of their

00:09:03.865 --> 00:09:04.665
<v Speaker 1>infrastructure.

00:09:04.825 --> 00:09:07.065
<v Speaker 1>So the trade off is, am I spending

00:09:07.065 --> 00:09:08.265
<v Speaker 1>1% overhead

00:09:09.160 --> 00:09:12.760
<v Speaker 1>to gain 10 to 30% optimization? I think

00:09:12.760 --> 00:09:15.880
<v Speaker 1>that's an easy calculation to make. Right? Yep.

00:09:15.880 --> 00:09:16.520
<v Speaker 0>Definitely.

00:09:17.800 --> 00:09:19.640
<v Speaker 0>There there was a lot of information there,

00:09:19.640 --> 00:09:21.160
<v Speaker 0>so thank you for for getting into that.

00:09:21.425 --> 00:09:23.185
<v Speaker 0>And you're right, one of the things that

00:09:23.185 --> 00:09:24.464
<v Speaker 0>I had on the back of my head

00:09:24.464 --> 00:09:25.505
<v Speaker 0>was like, what

00:09:26.545 --> 00:09:28.464
<v Speaker 0>am I paying for this for my own

00:09:28.464 --> 00:09:29.425
<v Speaker 0>infrastructure?

00:09:29.584 --> 00:09:31.665
<v Speaker 0>And you said the overhead is

00:09:32.305 --> 00:09:34.064
<v Speaker 0>I don't think you said negligible, but I'm

00:09:34.064 --> 00:09:35.700
<v Speaker 0>gonna throw that word out there. Just a

00:09:35.700 --> 00:09:36.980
<v Speaker 0>certain point where it's not that much because

00:09:36.980 --> 00:09:38.500
<v Speaker 0>of your sampling strategy,

00:09:38.660 --> 00:09:40.580
<v Speaker 0>which I think is is really interesting because

00:09:40.580 --> 00:09:43.140
<v Speaker 0>I think the more visibility people can have

00:09:43.540 --> 00:09:45.779
<v Speaker 0>into what's running in their clusters, it can

00:09:45.779 --> 00:09:47.940
<v Speaker 0>answer two of the hardest questions I think

00:09:47.940 --> 00:09:50.335
<v Speaker 0>people have in the Kubernetes space. Like, I

00:09:50.335 --> 00:09:51.535
<v Speaker 0>don't think there's been

00:09:52.175 --> 00:09:53.775
<v Speaker 0>a conference or a user group that I

00:09:53.775 --> 00:09:55.855
<v Speaker 0>went to where someone hasn't asked me, how

00:09:55.855 --> 00:09:57.215
<v Speaker 0>do I set resource

00:09:57.695 --> 00:09:59.135
<v Speaker 0>constraints on my pod?

00:09:59.455 --> 00:10:01.375
<v Speaker 0>I'm like, ah, yeah,

00:10:01.695 --> 00:10:03.695
<v Speaker 0>you have to profile your application and understand

00:10:03.695 --> 00:10:05.940
<v Speaker 0>what normal looks like. And it's just, it's

00:10:05.940 --> 00:10:08.100
<v Speaker 0>just quite a scary thing. I don't think

00:10:08.100 --> 00:10:10.260
<v Speaker 0>a lot of people have profiled their applications

00:10:10.260 --> 00:10:12.580
<v Speaker 0>before, well, probably ever.

00:10:13.540 --> 00:10:16.020
<v Speaker 0>And the second question is, how do I

00:10:16.020 --> 00:10:16.900
<v Speaker 0>debug

00:10:16.900 --> 00:10:19.635
<v Speaker 0>garbage collection and memory leaks and other things?

00:10:19.635 --> 00:10:21.154
<v Speaker 0>And again, you're back to the profile and

00:10:21.154 --> 00:10:22.274
<v Speaker 0>I was like, I'm sorry, you're gonna have

00:10:22.274 --> 00:10:23.795
<v Speaker 0>to learn this stuff eventually.

00:10:24.995 --> 00:10:28.195
<v Speaker 0>So it's nice to see that Parca can

00:10:28.195 --> 00:10:30.355
<v Speaker 0>come into this space and do the continuous

00:10:30.355 --> 00:10:32.435
<v Speaker 0>thing in a way that isn't gonna cause

00:10:32.435 --> 00:10:34.435
<v Speaker 0>too much overhead and just increase

00:10:34.700 --> 00:10:37.500
<v Speaker 0>that visibility without it being too daunting, too

00:10:37.500 --> 00:10:40.540
<v Speaker 0>scary, too to never acting like we're all

00:10:40.540 --> 00:10:43.260
<v Speaker 0>very careful, I hope, about what we deploy

00:10:43.260 --> 00:10:45.820
<v Speaker 0>to production. And there's my next question. Can

00:10:45.820 --> 00:10:48.700
<v Speaker 0>I run Parca in my production infrastructure, and

00:10:48.700 --> 00:10:50.220
<v Speaker 0>is that something that is encouraged?

00:10:51.274 --> 00:10:52.714
<v Speaker 1>Yeah. I mean, the

00:10:53.035 --> 00:10:55.595
<v Speaker 1>you you it's it's really just like any

00:10:55.595 --> 00:10:56.154
<v Speaker 1>other

00:10:56.475 --> 00:10:57.995
<v Speaker 1>observability data.

00:10:58.634 --> 00:11:02.074
<v Speaker 1>You can certainly run it in preproduction environments

00:11:02.074 --> 00:11:04.074
<v Speaker 1>or something, and we encourage that as well.

00:11:05.930 --> 00:11:08.089
<v Speaker 1>But in a in a similar line on

00:11:08.089 --> 00:11:10.330
<v Speaker 1>a similar note as, like,

00:11:10.649 --> 00:11:13.050
<v Speaker 1>your metrics are just never gonna behave the

00:11:13.050 --> 00:11:15.930
<v Speaker 1>same way in your local dev environment or

00:11:15.930 --> 00:11:17.370
<v Speaker 1>even a staging cluster.

00:11:18.010 --> 00:11:20.010
<v Speaker 1>It's always gonna be different in production, and

00:11:20.010 --> 00:11:22.185
<v Speaker 1>so you you're gonna always have to measure

00:11:22.185 --> 00:11:23.465
<v Speaker 1>these things in production.

00:11:24.265 --> 00:11:25.465
<v Speaker 0>Yeah. Definitely.

00:11:26.425 --> 00:11:27.865
<v Speaker 0>If you're trying to work at what normal

00:11:27.865 --> 00:11:29.625
<v Speaker 0>looks like in the staging environment, it's never

00:11:29.625 --> 00:11:31.305
<v Speaker 0>never gonna correlate to what you have in

00:11:31.305 --> 00:11:33.305
<v Speaker 0>your your real production environment. I couldn't agree

00:11:33.305 --> 00:11:33.865
<v Speaker 0>more. Yeah.

00:11:34.709 --> 00:11:35.430
<v Speaker 1>And

00:11:35.589 --> 00:11:38.149
<v Speaker 1>in in terms of, like, how production ready

00:11:38.149 --> 00:11:40.390
<v Speaker 1>is this this this,

00:11:40.630 --> 00:11:42.550
<v Speaker 1>like, open source project, let's say,

00:11:43.589 --> 00:11:44.550
<v Speaker 1>like, I think

00:11:45.350 --> 00:11:47.269
<v Speaker 1>it should be at least a little bit

00:11:47.269 --> 00:11:48.790
<v Speaker 1>taken with a grain of salt because it

00:11:48.790 --> 00:11:51.345
<v Speaker 1>is a very young project. Right? Like, it's

00:11:51.345 --> 00:11:53.505
<v Speaker 1>existed for maybe a couple of months.

00:11:54.705 --> 00:11:56.865
<v Speaker 1>But it's every week.

00:11:57.185 --> 00:11:58.945
<v Speaker 1>We we have an entire company working on

00:11:58.945 --> 00:12:01.025
<v Speaker 1>this and improving it. Right? Like, every week,

00:12:01.025 --> 00:12:02.385
<v Speaker 1>it improves drastically

00:12:02.465 --> 00:12:03.345
<v Speaker 1>from

00:12:04.150 --> 00:12:07.990
<v Speaker 1>literally every dimension. Like, on overhead, it continues

00:12:07.990 --> 00:12:08.790
<v Speaker 1>to improve.

00:12:09.110 --> 00:12:11.590
<v Speaker 1>On the storage, it continues to improve.

00:12:12.390 --> 00:12:14.630
<v Speaker 1>Yeah. Just on on every really really on

00:12:14.630 --> 00:12:16.565
<v Speaker 1>every dimension, which kind of, I think, is

00:12:16.565 --> 00:12:17.685
<v Speaker 1>also a good

00:12:18.085 --> 00:12:20.645
<v Speaker 1>point where we can talk about what you

00:12:20.645 --> 00:12:23.045
<v Speaker 1>said earlier, what makes up the Parca project.

00:12:23.045 --> 00:12:24.805
<v Speaker 1>Right? Because there are actually a couple of

00:12:24.885 --> 00:12:26.165
<v Speaker 1>moving components

00:12:26.165 --> 00:12:27.685
<v Speaker 1>that I think are good to understand.

00:12:28.470 --> 00:12:29.029
<v Speaker 1>So,

00:12:30.070 --> 00:12:31.590
<v Speaker 1>the Parca project,

00:12:31.990 --> 00:12:34.310
<v Speaker 1>largely, you can think of it as having

00:12:34.310 --> 00:12:35.350
<v Speaker 1>two components,

00:12:35.430 --> 00:12:38.709
<v Speaker 1>the server and the agent or the collector,

00:12:38.709 --> 00:12:39.589
<v Speaker 1>you could say as well.

00:12:40.895 --> 00:12:41.615
<v Speaker 1>The

00:12:41.855 --> 00:12:44.335
<v Speaker 1>the agent, the collector is the thing that

00:12:44.335 --> 00:12:47.215
<v Speaker 1>actually does the profiling part. It's the thing

00:12:47.215 --> 00:12:49.295
<v Speaker 1>that captures the raw data,

00:12:50.015 --> 00:12:50.895
<v Speaker 1>and then

00:12:51.455 --> 00:12:52.975
<v Speaker 1>batches it up essentially

00:12:53.055 --> 00:12:55.430
<v Speaker 1>and then sends that to the server, which

00:12:55.430 --> 00:12:57.670
<v Speaker 1>then stores it and where you can also

00:12:57.670 --> 00:13:00.149
<v Speaker 1>query it through its API and and UI

00:13:00.149 --> 00:13:01.589
<v Speaker 1>that is all integrated.

00:13:02.070 --> 00:13:04.310
<v Speaker 1>It's all very inspired.

00:13:04.310 --> 00:13:06.070
<v Speaker 1>At least the server part is very inspired

00:13:06.070 --> 00:13:09.264
<v Speaker 1>by Prometheus. It's probably not to a not

00:13:09.264 --> 00:13:12.305
<v Speaker 1>much of a surprise given my my background.

00:13:13.824 --> 00:13:16.945
<v Speaker 1>It like, we really focused on having this

00:13:16.945 --> 00:13:18.305
<v Speaker 1>extremely simple,

00:13:18.704 --> 00:13:19.505
<v Speaker 1>really great

00:13:19.839 --> 00:13:23.200
<v Speaker 1>first experience where it's a single statically linked

00:13:23.200 --> 00:13:24.000
<v Speaker 1>binary.

00:13:24.720 --> 00:13:27.200
<v Speaker 1>You know, all the container images exist. There

00:13:27.200 --> 00:13:30.720
<v Speaker 1>are, like, manifests available for Kubernetes.

00:13:31.200 --> 00:13:32.000
<v Speaker 1>Hopefully,

00:13:32.160 --> 00:13:34.925
<v Speaker 1>you know, your your first interaction with the

00:13:34.925 --> 00:13:37.245
<v Speaker 1>project is very, very smooth and very

00:13:38.125 --> 00:13:38.845
<v Speaker 1>simple.

00:13:39.805 --> 00:13:40.525
<v Speaker 1>Sweet.

00:13:40.685 --> 00:13:42.205
<v Speaker 0>Well, we're gonna take a look at it

00:13:42.205 --> 00:13:44.365
<v Speaker 0>in just one second. Before we do that,

00:13:44.365 --> 00:13:45.725
<v Speaker 0>I'll throw one more question

00:13:45.965 --> 00:13:47.005
<v Speaker 0>at you. Like,

00:13:47.970 --> 00:13:49.889
<v Speaker 0>it's it's an easy question, you know, but

00:13:49.889 --> 00:13:51.810
<v Speaker 0>no stress or anything like that. But I

00:13:51.810 --> 00:13:53.490
<v Speaker 0>feel like we're in a really great position

00:13:53.490 --> 00:13:55.490
<v Speaker 0>these days in the cloud native ecosystem,

00:13:55.569 --> 00:13:57.970
<v Speaker 0>you know, where Kubernetes is almost ubiquitous with

00:13:57.970 --> 00:14:00.370
<v Speaker 0>people. Maybe that's it's a good thing depending

00:14:00.370 --> 00:14:02.209
<v Speaker 0>on who you're talking to. But we're at

00:14:02.209 --> 00:14:03.569
<v Speaker 0>a stage where it's ubiquitous.

00:14:04.355 --> 00:14:06.675
<v Speaker 0>Almost everybody has a metric server. Everybody's got

00:14:06.675 --> 00:14:09.555
<v Speaker 0>a premium face. Everybody is doing some monitoring.

00:14:09.954 --> 00:14:11.795
<v Speaker 0>We're seeing a bit of a push with

00:14:11.795 --> 00:14:15.075
<v Speaker 0>observability and people looking at distributed tracing,

00:14:15.315 --> 00:14:15.635
<v Speaker 0>etcetera.

00:14:16.449 --> 00:14:18.449
<v Speaker 0>Do you feel that Parca is one of

00:14:18.449 --> 00:14:20.930
<v Speaker 0>these components that if you have a production

00:14:20.930 --> 00:14:23.250
<v Speaker 0>cluster, then Parca should just be installed? Like,

00:14:23.250 --> 00:14:25.329
<v Speaker 0>is that we looking at a project here

00:14:25.329 --> 00:14:27.649
<v Speaker 0>that we're saying to people, if you have

00:14:27.649 --> 00:14:30.655
<v Speaker 0>production infrastructure at this Kubernetes base, yes, you

00:14:30.655 --> 00:14:32.255
<v Speaker 0>must have this installed, like, next to your

00:14:32.255 --> 00:14:33.055
<v Speaker 0>Prometheus.

00:14:33.295 --> 00:14:34.575
<v Speaker 1>Absolutely.

00:14:35.055 --> 00:14:38.495
<v Speaker 1>The the whole point of or the the

00:14:38.495 --> 00:14:41.375
<v Speaker 1>the the reason that actually motivated me to

00:14:42.200 --> 00:14:45.640
<v Speaker 1>found an entire company around this is entirely

00:14:45.640 --> 00:14:47.960
<v Speaker 1>based on the premise that I believe that

00:14:47.960 --> 00:14:51.240
<v Speaker 1>this type of data is completely complementary to

00:14:51.240 --> 00:14:52.360
<v Speaker 1>your existing

00:14:52.600 --> 00:14:53.480
<v Speaker 1>observability

00:14:53.480 --> 00:14:56.040
<v Speaker 1>stack. As a matter of fact, kind of

00:14:56.394 --> 00:14:58.154
<v Speaker 1>I didn't know it back then, but I

00:14:58.154 --> 00:14:59.834
<v Speaker 1>think the seed for all of this was

00:14:59.834 --> 00:15:00.955
<v Speaker 1>planted in

00:15:01.195 --> 00:15:01.835
<v Speaker 1>a,

00:15:03.595 --> 00:15:05.595
<v Speaker 1>like, an invited keynote that I gave at

00:15:05.595 --> 00:15:07.274
<v Speaker 1>KubeCon in Barcelona

00:15:07.355 --> 00:15:08.315
<v Speaker 1>in 2019

00:15:08.810 --> 00:15:11.529
<v Speaker 1>where Tom Wilkie and I kind of gave,

00:15:11.769 --> 00:15:14.170
<v Speaker 1>he's the VP of product at Grafana now.

00:15:15.529 --> 00:15:17.130
<v Speaker 1>He and I kind of gave

00:15:17.690 --> 00:15:18.570
<v Speaker 1>an

00:15:21.005 --> 00:15:23.805
<v Speaker 1>a like, some guesses, let's say, what the

00:15:23.805 --> 00:15:26.205
<v Speaker 1>future holds for observability.

00:15:26.445 --> 00:15:28.445
<v Speaker 1>And part of that was

00:15:29.964 --> 00:15:32.445
<v Speaker 1>where where I predicted that I thought that

00:15:32.445 --> 00:15:35.570
<v Speaker 1>continuous profiling was going to become a major

00:15:36.210 --> 00:15:39.730
<v Speaker 1>player in the observability world simply because

00:15:39.970 --> 00:15:42.530
<v Speaker 1>it just like any other observability

00:15:42.770 --> 00:15:43.970
<v Speaker 1>type of data,

00:15:44.210 --> 00:15:47.490
<v Speaker 1>it gives you a unique kind of insight

00:15:47.945 --> 00:15:49.865
<v Speaker 1>into your running application.

00:15:49.945 --> 00:15:53.385
<v Speaker 1>It's unlike metrics. It's unlike tracing. It's just

00:15:53.945 --> 00:15:56.025
<v Speaker 1>just like metrics and tracing

00:15:56.185 --> 00:15:58.025
<v Speaker 1>are complementary to each other,

00:15:58.665 --> 00:16:02.130
<v Speaker 1>continuous profiling data is also complementary to to

00:16:02.130 --> 00:16:02.690
<v Speaker 1>those.

00:16:03.170 --> 00:16:05.490
<v Speaker 0>Sweet. I love that. You make a prediction

00:16:05.490 --> 00:16:07.570
<v Speaker 0>and then go out on a multiyear journey

00:16:07.570 --> 00:16:09.730
<v Speaker 0>to prove the prediction correct yourself.

00:16:10.450 --> 00:16:12.290
<v Speaker 1>It's it's as they say. Like, if you

00:16:12.290 --> 00:16:13.890
<v Speaker 1>wanna predict the future, you gotta build it

00:16:13.890 --> 00:16:14.210
<v Speaker 1>yourself.

00:16:14.774 --> 00:16:17.495
<v Speaker 0>Yeah. Perfect. That's awesome. Okay.

00:16:17.495 --> 00:16:18.935
<v Speaker 0>So we're gonna jump to the screen share

00:16:18.935 --> 00:16:20.615
<v Speaker 0>in just one second. We do have a

00:16:20.615 --> 00:16:22.615
<v Speaker 0>question from the audience, so I'll pop that

00:16:22.615 --> 00:16:24.214
<v Speaker 0>up on the screen and read that out.

00:16:24.375 --> 00:16:27.014
<v Speaker 0>But Ivan Ash is asking, can Parca also

00:16:27.014 --> 00:16:29.095
<v Speaker 0>collect metrics and be used for dashboards and

00:16:29.095 --> 00:16:31.950
<v Speaker 0>stuff, or do we need separate monitoring agent?

00:16:33.390 --> 00:16:34.910
<v Speaker 1>So it

00:16:38.190 --> 00:16:39.070
<v Speaker 1>it's not

00:16:39.550 --> 00:16:41.230
<v Speaker 1>exactly like metrics,

00:16:41.470 --> 00:16:43.230
<v Speaker 1>but you can think of it as a

00:16:43.230 --> 00:16:44.190
<v Speaker 1>super

00:16:44.190 --> 00:16:44.589
<v Speaker 1>high,

00:16:45.335 --> 00:16:46.535
<v Speaker 1>highly granular

00:16:46.535 --> 00:16:49.895
<v Speaker 1>CPU metric, for example. Right now, you probably

00:16:49.895 --> 00:16:50.935
<v Speaker 1>only have,

00:16:51.735 --> 00:16:55.495
<v Speaker 1>CPU being measured on a per process basis.

00:16:55.495 --> 00:16:57.815
<v Speaker 1>Maybe maybe if you're talking about Kubernetes, maybe

00:16:57.815 --> 00:17:00.380
<v Speaker 1>on a per container basis or on a

00:17:00.380 --> 00:17:01.980
<v Speaker 1>per per pod basis.

00:17:02.620 --> 00:17:04.859
<v Speaker 1>And in this this case, we would actually

00:17:04.859 --> 00:17:07.660
<v Speaker 1>be getting data down to the line number

00:17:07.660 --> 00:17:10.380
<v Speaker 1>and not just to the process, but also

00:17:10.380 --> 00:17:12.540
<v Speaker 1>with process metadata. And we'll see in a

00:17:12.540 --> 00:17:15.304
<v Speaker 1>second just how similar the experience

00:17:15.384 --> 00:17:16.184
<v Speaker 1>actually

00:17:16.184 --> 00:17:18.744
<v Speaker 1>is to to Prometheus

00:17:18.744 --> 00:17:22.744
<v Speaker 1>because the entire, like, labeling strategy of of

00:17:22.744 --> 00:17:23.944
<v Speaker 1>Parca is

00:17:24.184 --> 00:17:27.660
<v Speaker 1>very intentionally based on what Prometheus does. And,

00:17:27.660 --> 00:17:30.060
<v Speaker 1>hopefully, it'll all feel natural to

00:17:31.420 --> 00:17:34.140
<v Speaker 1>to someone who's already used Prometheus before.

00:17:34.860 --> 00:17:37.020
<v Speaker 0>Alright. Let's get straight over to the screen

00:17:37.020 --> 00:17:38.780
<v Speaker 0>share and get Parca deployed then.

00:17:41.054 --> 00:17:44.094
<v Speaker 0>Here we go. So this is parca.dev.

00:17:45.215 --> 00:17:46.654
<v Speaker 0>And we have the website, we've got some

00:17:46.654 --> 00:17:47.695
<v Speaker 0>basic instructions.

00:17:48.255 --> 00:17:50.734
<v Speaker 0>We have prepared upfront

00:17:51.294 --> 00:17:53.054
<v Speaker 0>Civo KCS cluster.

00:17:53.640 --> 00:17:56.520
<v Speaker 0>This has nothing installed. It wasn't installed out

00:17:56.520 --> 00:17:58.440
<v Speaker 0>the box by Civo, so we're starting completely

00:17:58.440 --> 00:17:59.720
<v Speaker 0>from afresh.

00:18:00.600 --> 00:18:02.760
<v Speaker 0>We'll jump back over here. So,

00:18:04.120 --> 00:18:05.400
<v Speaker 0>I mean, I could ask what the next

00:18:05.400 --> 00:18:06.920
<v Speaker 0>step is, but I'm going to assume it

00:18:06.920 --> 00:18:08.040
<v Speaker 0>is to install Parca.

00:18:09.125 --> 00:18:10.165
<v Speaker 0>Yes. Yeah.

00:18:11.125 --> 00:18:13.205
<v Speaker 0>Step one's always the easy one. After that,

00:18:13.205 --> 00:18:14.405
<v Speaker 0>I get a little bit I'm not as

00:18:14.405 --> 00:18:15.765
<v Speaker 0>confident with my predictions.

00:18:15.925 --> 00:18:18.405
<v Speaker 0>But so that's just let me zoom in

00:18:18.405 --> 00:18:19.605
<v Speaker 0>on this actually. Just

00:18:20.485 --> 00:18:22.885
<v Speaker 0>because some really simple instructions here for Kubernetes.

00:18:22.885 --> 00:18:24.325
<v Speaker 0>We're not using many cubes. I can skip

00:18:24.325 --> 00:18:24.565
<v Speaker 0>this.

00:18:25.230 --> 00:18:27.550
<v Speaker 0>We're deploying Parca to its own namespace. I

00:18:27.550 --> 00:18:29.549
<v Speaker 0>assume that's the preferred approach.

00:18:29.950 --> 00:18:32.030
<v Speaker 0>And then we deploy the two components that

00:18:32.030 --> 00:18:33.870
<v Speaker 0>you mentioned just a few moments ago, the

00:18:33.870 --> 00:18:36.749
<v Speaker 0>Parca server and a Parca agent.

00:18:36.830 --> 00:18:38.510
<v Speaker 0>I'm assuming this just runs as a daemon

00:18:38.510 --> 00:18:41.304
<v Speaker 0>set. This is a deployment. And by magic,

00:18:41.384 --> 00:18:42.904
<v Speaker 0>the thing just starts working.

00:18:43.225 --> 00:18:45.625
<v Speaker 0>Yeah. What I am curious about is, like,

00:18:45.625 --> 00:18:48.344
<v Speaker 0>when I deploy these, has the profiling started

00:18:48.825 --> 00:18:49.544
<v Speaker 0>already?

00:18:50.184 --> 00:18:52.505
<v Speaker 1>Yeah. So that's a that's a great question.

00:18:54.080 --> 00:18:56.800
<v Speaker 1>The the Parca agent, as we said previously,

00:18:56.800 --> 00:18:59.600
<v Speaker 1>is the thing that does the profiling,

00:18:59.840 --> 00:19:03.760
<v Speaker 1>and it actually starts to automatically profile absolutely

00:19:03.760 --> 00:19:06.240
<v Speaker 1>every container in your Kubernetes cluster.

00:19:06.775 --> 00:19:09.254
<v Speaker 1>It kind of discovers everything that's there,

00:19:09.735 --> 00:19:11.654
<v Speaker 1>and it uses eBPF

00:19:11.655 --> 00:19:14.054
<v Speaker 1>to attach an eBPF program

00:19:14.615 --> 00:19:15.415
<v Speaker 1>to

00:19:15.415 --> 00:19:18.375
<v Speaker 1>each of those containers. And that's essentially how

00:19:18.375 --> 00:19:21.640
<v Speaker 1>the entire construct of the profilers are built.

00:19:21.640 --> 00:19:23.800
<v Speaker 0>You said the magic words. Like, I can't

00:19:23.800 --> 00:19:26.120
<v Speaker 0>believe we're nineteen minutes seventy has just popped

00:19:26.120 --> 00:19:28.520
<v Speaker 0>up for the yeah. It's we're seeing such

00:19:28.520 --> 00:19:30.520
<v Speaker 0>a crazy adoption of that right now. It

00:19:30.520 --> 00:19:31.960
<v Speaker 0>just seems to be solving a lot of

00:19:31.960 --> 00:19:33.480
<v Speaker 0>these observability

00:19:33.480 --> 00:19:34.280
<v Speaker 0>and performance.

00:19:35.835 --> 00:19:38.554
<v Speaker 0>Not problems, but, you know, questions that people

00:19:38.554 --> 00:19:41.835
<v Speaker 1>have. It it it's it's funny because when

00:19:41.835 --> 00:19:44.154
<v Speaker 1>we when we actually founded Polar Signals,

00:19:44.395 --> 00:19:47.595
<v Speaker 1>we didn't really want to concern ourselves with

00:19:47.755 --> 00:19:50.235
<v Speaker 1>the collection side of the problem. We felt

00:19:50.235 --> 00:19:51.115
<v Speaker 1>like the

00:19:51.409 --> 00:19:54.850
<v Speaker 1>the majority of the value was in storing

00:19:54.850 --> 00:19:56.450
<v Speaker 1>and querying this data

00:19:56.690 --> 00:19:59.809
<v Speaker 1>in a useful way. But we pretty quickly

00:19:59.970 --> 00:20:00.850
<v Speaker 1>realized

00:20:00.850 --> 00:20:02.929
<v Speaker 1>that we were gonna run into kind of

00:20:02.929 --> 00:20:05.090
<v Speaker 1>two problems. The first one was the overhead

00:20:05.090 --> 00:20:07.169
<v Speaker 1>problem, which we kind of already talked about,

00:20:07.625 --> 00:20:10.905
<v Speaker 1>but eBPF kind of adds an additional benefit

00:20:10.905 --> 00:20:13.385
<v Speaker 1>here because everything runs in kernel.

00:20:13.705 --> 00:20:15.945
<v Speaker 1>And because we can collect exactly the amount

00:20:15.945 --> 00:20:18.505
<v Speaker 1>of data that we need and exactly the

00:20:18.505 --> 00:20:21.539
<v Speaker 1>format that we wanted in, it allows us

00:20:21.539 --> 00:20:24.419
<v Speaker 1>to do the profiling at actually an order

00:20:24.419 --> 00:20:26.259
<v Speaker 1>of magnitude less than,

00:20:27.380 --> 00:20:28.979
<v Speaker 1>quote, unquote, traditional

00:20:30.500 --> 00:20:31.539
<v Speaker 1>profiling techniques.

00:20:33.304 --> 00:20:34.985
<v Speaker 1>And there there are a couple of things

00:20:34.985 --> 00:20:37.865
<v Speaker 1>that maybe we can get into later that

00:20:37.865 --> 00:20:40.105
<v Speaker 1>kind of make this make up this strategy.

00:20:40.585 --> 00:20:41.144
<v Speaker 1>But,

00:20:42.025 --> 00:20:44.665
<v Speaker 1>yeah, eBPF has has definitely been a a

00:20:44.665 --> 00:20:47.680
<v Speaker 1>really amazing fit. And just the nature of

00:20:47.680 --> 00:20:50.720
<v Speaker 1>how eBPF works makes it really simple for

00:20:50.720 --> 00:20:51.840
<v Speaker 1>us to attach

00:20:52.240 --> 00:20:54.880
<v Speaker 1>these profilers to every container on a host

00:20:54.880 --> 00:20:55.600
<v Speaker 1>because

00:20:55.680 --> 00:20:57.760
<v Speaker 1>eBPF is literally

00:20:58.000 --> 00:21:01.040
<v Speaker 1>able to do anything or inspect anything on

00:21:01.040 --> 00:21:01.760
<v Speaker 1>the host. Right?

00:21:02.895 --> 00:21:05.135
<v Speaker 0>Yeah. We got that question from Moz, Ray,

00:21:05.135 --> 00:21:07.055
<v Speaker 0>and just as we started talking about eBPF.

00:21:07.055 --> 00:21:08.895
<v Speaker 0>But Moz was curious if it used eBPF,

00:21:08.895 --> 00:21:10.255
<v Speaker 0>and I hope that we've answered that for

00:21:10.255 --> 00:21:11.055
<v Speaker 0>you there, Moz.

00:21:11.535 --> 00:21:12.175
<v Speaker 0>Yeah.

00:21:12.895 --> 00:21:13.855
<v Speaker 0>Sweet. So

00:21:14.179 --> 00:21:16.660
<v Speaker 0>we've deployed the agent. We've deployed the the

00:21:16.660 --> 00:21:19.140
<v Speaker 0>daemon set, the no. The server and the

00:21:19.140 --> 00:21:21.220
<v Speaker 0>daemon set, which is the agent. Like, what

00:21:21.220 --> 00:21:24.100
<v Speaker 0>is the the way that we interact with

00:21:24.100 --> 00:21:25.700
<v Speaker 0>Parca? Should I go back to the docs

00:21:25.700 --> 00:21:28.215
<v Speaker 0>or should I just start guessing? Like

00:21:28.615 --> 00:21:30.135
<v Speaker 1>I mean, you can you can you can

00:21:30.135 --> 00:21:30.934
<v Speaker 1>hit the,

00:21:31.175 --> 00:21:34.615
<v Speaker 1>like, Parca in Kubernetes tutorial five five minutes

00:21:35.735 --> 00:21:37.655
<v Speaker 1>button, and you'll get the entire,

00:21:37.895 --> 00:21:38.615
<v Speaker 1>basically,

00:21:39.095 --> 00:21:41.975
<v Speaker 1>manuscript of what we're what we're doing here.

00:21:42.790 --> 00:21:44.470
<v Speaker 1>But you can check out here, you see

00:21:44.470 --> 00:21:45.350
<v Speaker 1>the,

00:21:45.350 --> 00:21:46.789
<v Speaker 1>like, a port forward.

00:21:47.510 --> 00:21:49.430
<v Speaker 1>We don't make an opinion of we we

00:21:49.430 --> 00:21:51.110
<v Speaker 1>don't wanna take an opinion of how people

00:21:51.110 --> 00:21:52.950
<v Speaker 1>are gonna expose this. You know, you can

00:21:52.950 --> 00:21:55.110
<v Speaker 1>put an ingress here or

00:21:56.054 --> 00:21:58.695
<v Speaker 0>Yeah. I don't know. Whatever your preferred way

00:21:58.695 --> 00:22:01.894
<v Speaker 1>is. Right? So here, we're just telling people

00:22:01.894 --> 00:22:03.174
<v Speaker 1>to do port forward.

00:22:03.495 --> 00:22:05.735
<v Speaker 0>Alright. Well, we have a three node clusters.

00:22:05.735 --> 00:22:07.654
<v Speaker 0>We have three agents. We've got the server.

00:22:08.580 --> 00:22:10.820
<v Speaker 0>We could do a port forward to the

00:22:10.820 --> 00:22:12.899
<v Speaker 0>service on seventy seventy.

00:22:14.419 --> 00:22:15.620
<v Speaker 0>And let's see.

00:22:21.505 --> 00:22:23.345
<v Speaker 0>Hey. We have Parca. It worked.

00:22:24.865 --> 00:22:27.184
<v Speaker 1>The fir first first feature

00:22:27.585 --> 00:22:30.145
<v Speaker 1>that's always had the most important to people

00:22:30.145 --> 00:22:31.744
<v Speaker 1>is, on the,

00:22:32.225 --> 00:22:35.105
<v Speaker 1>top right, you can see the little toggle

00:22:35.105 --> 00:22:35.745
<v Speaker 1>for

00:22:36.160 --> 00:22:37.200
<v Speaker 1>dark mode.

00:22:39.040 --> 00:22:41.360
<v Speaker 1>It was actually one of the first feature

00:22:41.360 --> 00:22:44.720
<v Speaker 1>requests that we got. So, yeah, definitely important.

00:22:45.040 --> 00:22:47.200
<v Speaker 1>But no. It's always nice when you go

00:22:47.200 --> 00:22:48.720
<v Speaker 0>to a blog, though. Right? And you see

00:22:48.720 --> 00:22:50.320
<v Speaker 0>that little sun and moon in the top

00:22:50.320 --> 00:22:52.320
<v Speaker 0>corner, and you're like, oh, good. I can

00:22:51.705 --> 00:22:53.865
<v Speaker 0>set my own preference. Like, I think as

00:22:53.865 --> 00:22:55.544
<v Speaker 0>developers, we get a lot of pleasure from

00:22:55.544 --> 00:22:57.304
<v Speaker 0>the simple things like that. So it's good

00:22:57.304 --> 00:22:57.864
<v Speaker 0>to see.

00:22:58.424 --> 00:22:59.065
<v Speaker 1>Yeah.

00:22:59.304 --> 00:22:59.864
<v Speaker 1>So

00:23:00.505 --> 00:23:02.745
<v Speaker 1>when when you when you start and this

00:23:02.745 --> 00:23:04.664
<v Speaker 1>is actually something that we're actively trying to

00:23:04.664 --> 00:23:06.664
<v Speaker 1>improve that you don't need to know how

00:23:06.664 --> 00:23:09.510
<v Speaker 1>to use this just yet, that you immediately

00:23:09.510 --> 00:23:11.510
<v Speaker 1>see some data. But for now, this is

00:23:11.510 --> 00:23:13.270
<v Speaker 1>how how it works, and you start by

00:23:13.270 --> 00:23:15.750
<v Speaker 1>selecting the type of profile

00:23:15.750 --> 00:23:18.389
<v Speaker 1>that you wanna see. And right now,

00:23:19.350 --> 00:23:19.990
<v Speaker 1>the

00:23:20.235 --> 00:23:22.554
<v Speaker 1>the Parca agent only supports

00:23:22.795 --> 00:23:24.235
<v Speaker 1>CPU profiling.

00:23:24.395 --> 00:23:26.395
<v Speaker 1>We're we're going to be adding more of

00:23:26.395 --> 00:23:27.355
<v Speaker 1>this, but

00:23:28.075 --> 00:23:29.595
<v Speaker 1>the the entire

00:23:29.755 --> 00:23:31.595
<v Speaker 1>Parca project is

00:23:31.755 --> 00:23:32.075
<v Speaker 1>actually

00:23:33.059 --> 00:23:36.019
<v Speaker 1>based around an open standard called pprof. This

00:23:36.019 --> 00:23:39.940
<v Speaker 1>was a format that, Google had originally created

00:23:39.940 --> 00:23:40.579
<v Speaker 1>for,

00:23:41.460 --> 00:23:43.220
<v Speaker 1>representing profiling data, essentially.

00:23:45.255 --> 00:23:48.695
<v Speaker 1>And anything that is p professor formatted can

00:23:48.695 --> 00:23:51.335
<v Speaker 1>be written to the Parca storage.

00:23:51.415 --> 00:23:53.975
<v Speaker 1>And so in this case, we're only sending

00:23:53.975 --> 00:23:56.935
<v Speaker 1>CPU samples, but there are integrations. For example,

00:23:57.799 --> 00:24:00.600
<v Speaker 1>the Go runtime itself has support for various

00:24:00.600 --> 00:24:01.879
<v Speaker 1>types of profiling,

00:24:02.919 --> 00:24:03.960
<v Speaker 1>like memory

00:24:03.960 --> 00:24:04.840
<v Speaker 1>profiling,

00:24:05.720 --> 00:24:07.320
<v Speaker 1>Go routine profiling,

00:24:07.400 --> 00:24:09.239
<v Speaker 1>and you can also ingest

00:24:09.320 --> 00:24:11.960
<v Speaker 1>those profiles into Parca. In this case, we

00:24:11.960 --> 00:24:14.465
<v Speaker 1>are only running the Parca agent, though.

00:24:15.425 --> 00:24:17.665
<v Speaker 0>Okay. So I just select on CPU samples

00:24:17.665 --> 00:24:18.865
<v Speaker 0>here? Yep.

00:24:19.265 --> 00:24:21.985
<v Speaker 0>And then You could already hit hit search

00:24:21.985 --> 00:24:23.745
<v Speaker 1>at this point, and you'll start to see

00:24:23.745 --> 00:24:24.545
<v Speaker 1>some data.

00:24:25.185 --> 00:24:26.865
<v Speaker 0>Yeah. Yeah. Like a graph. Nice.

00:24:29.760 --> 00:24:32.159
<v Speaker 1>So now we can already see some some

00:24:32.159 --> 00:24:34.479
<v Speaker 1>similarities to Prometheus here.

00:24:35.519 --> 00:24:37.279
<v Speaker 1>If you if you hover over a dot,

00:24:37.279 --> 00:24:40.479
<v Speaker 1>for example, you'll see that there there are,

00:24:40.559 --> 00:24:44.534
<v Speaker 1>like, labels attached to this series of profiles.

00:24:44.695 --> 00:24:46.855
<v Speaker 1>So here we have the Parca

00:24:47.415 --> 00:24:48.455
<v Speaker 1>container itself

00:24:48.695 --> 00:24:51.415
<v Speaker 1>and the idea of it, its namespace, the

00:24:51.415 --> 00:24:53.015
<v Speaker 1>node that's running on, and the pod.

00:24:55.240 --> 00:24:57.080
<v Speaker 1>And you can hover over each of them,

00:24:57.080 --> 00:24:59.559
<v Speaker 1>and whenever you're to a closest to a

00:24:59.559 --> 00:25:00.840
<v Speaker 1>point, it'll tell you

00:25:02.600 --> 00:25:04.120
<v Speaker 1>what what container

00:25:04.120 --> 00:25:05.320
<v Speaker 1>we're looking at.

00:25:06.280 --> 00:25:08.919
<v Speaker 1>You can also while you hover over something,

00:25:08.919 --> 00:25:11.035
<v Speaker 1>maybe it's maybe a little small for the

00:25:11.035 --> 00:25:13.355
<v Speaker 1>audience to see, but it says hold shift

00:25:13.355 --> 00:25:15.435
<v Speaker 1>and click a label to add to query.

00:25:15.435 --> 00:25:17.915
<v Speaker 1>So if you hold shift while you're hovering,

00:25:18.235 --> 00:25:19.995
<v Speaker 1>you can now click one of these,

00:25:21.515 --> 00:25:24.475
<v Speaker 1>let's say, the names Parca namespace, for example.

00:25:25.940 --> 00:25:27.940
<v Speaker 1>Then it filters everything

00:25:27.940 --> 00:25:29.700
<v Speaker 1>down, and you can see that our query

00:25:29.700 --> 00:25:30.899
<v Speaker 1>was updated

00:25:30.980 --> 00:25:32.340
<v Speaker 1>in the query bar.

00:25:32.740 --> 00:25:34.419
<v Speaker 1>And now we're only seeing

00:25:36.180 --> 00:25:36.820
<v Speaker 1>processes

00:25:37.060 --> 00:25:38.660
<v Speaker 1>from the Parca namespace.

00:25:40.695 --> 00:25:43.415
<v Speaker 1>Cool. And so so far, we're only seeing

00:25:43.415 --> 00:25:44.294
<v Speaker 1>metrics,

00:25:44.295 --> 00:25:45.335
<v Speaker 1>basically. Right?

00:25:45.655 --> 00:25:47.895
<v Speaker 1>But we actually wanna see profiling data. So

00:25:47.895 --> 00:25:50.055
<v Speaker 1>what we could do now is any of

00:25:50.055 --> 00:25:52.775
<v Speaker 1>the dots that you were hovering over, once

00:25:52.775 --> 00:25:53.495
<v Speaker 1>you click them,

00:25:54.770 --> 00:25:55.809
<v Speaker 1>you'll see

00:25:56.370 --> 00:25:58.049
<v Speaker 1>and you you need to scroll down,

00:25:58.690 --> 00:25:59.809
<v Speaker 1>then we'll see

00:26:00.049 --> 00:26:01.889
<v Speaker 0>Oh, yeah. Clean graph.

00:26:05.649 --> 00:26:07.905
<v Speaker 0>So this is showing me I always I

00:26:07.905 --> 00:26:08.945
<v Speaker 0>should have paid more attention to what I

00:26:08.945 --> 00:26:10.305
<v Speaker 0>was clicking on. I think I clicked on

00:26:10.305 --> 00:26:11.825
<v Speaker 0>this. So this is the

00:26:13.345 --> 00:26:14.865
<v Speaker 0>Parca container.

00:26:16.705 --> 00:26:18.865
<v Speaker 0>So this is actually the Parca server container.

00:26:18.865 --> 00:26:21.105
<v Speaker 0>Okay. And this is all the server itself.

00:26:21.710 --> 00:26:24.750
<v Speaker 0>All the functions being called within the application?

00:26:25.310 --> 00:26:27.710
<v Speaker 1>Yes. Exactly. At that point in time. So

00:26:27.870 --> 00:26:29.310
<v Speaker 1>At that point in time. The the the

00:26:29.310 --> 00:26:32.110
<v Speaker 1>profiles are always taken over a ten second

00:26:32.110 --> 00:26:32.909
<v Speaker 1>interval.

00:26:33.150 --> 00:26:33.950
<v Speaker 1>And so

00:26:35.335 --> 00:26:37.255
<v Speaker 1>within those ten seconds,

00:26:37.575 --> 00:26:38.935
<v Speaker 1>of which the,

00:26:39.255 --> 00:26:41.655
<v Speaker 1>profile of of the profile's time stamp,

00:26:41.815 --> 00:26:43.975
<v Speaker 1>these are the things that were being executed

00:26:43.975 --> 00:26:45.015
<v Speaker 1>during that,

00:26:45.255 --> 00:26:46.135
<v Speaker 1>that time.

00:26:46.455 --> 00:26:49.015
<v Speaker 1>And there's something that I I I've been

00:26:49.510 --> 00:26:50.389
<v Speaker 1>incredibly

00:26:51.030 --> 00:26:54.070
<v Speaker 1>excited about ever since we first implemented this.

00:26:54.150 --> 00:26:55.509
<v Speaker 1>If you scroll up,

00:26:55.750 --> 00:26:58.390
<v Speaker 1>you can see that there's a compare button

00:26:58.390 --> 00:26:59.909
<v Speaker 1>next to the search button

00:27:00.309 --> 00:27:01.910
<v Speaker 1>in the in the bar. Yeah.

00:27:02.684 --> 00:27:04.445
<v Speaker 1>So what this now does

00:27:05.005 --> 00:27:06.764
<v Speaker 1>is it it should open

00:27:07.245 --> 00:27:09.644
<v Speaker 1>maybe oh, yeah. No. There we go. So

00:27:09.644 --> 00:27:12.365
<v Speaker 1>what we can now do is we can

00:27:12.365 --> 00:27:13.244
<v Speaker 1>compare

00:27:13.245 --> 00:27:14.524
<v Speaker 1>two profiles

00:27:15.630 --> 00:27:17.710
<v Speaker 1>in their points points of time. So for

00:27:17.710 --> 00:27:18.350
<v Speaker 1>example,

00:27:19.470 --> 00:27:21.070
<v Speaker 1>on the left hand side,

00:27:22.270 --> 00:27:24.910
<v Speaker 1>select one of the Parca profiles that, you

00:27:24.910 --> 00:27:26.590
<v Speaker 1>know, isn't at the peak,

00:27:28.195 --> 00:27:30.115
<v Speaker 1>Maybe from the green one. Yeah. That that

00:27:30.115 --> 00:27:32.195
<v Speaker 1>one. And then on the other one, select

00:27:32.195 --> 00:27:34.755
<v Speaker 1>the one at the peak just after that

00:27:34.915 --> 00:27:36.915
<v Speaker 1>or that peak. It doesn't really matter. And

00:27:36.915 --> 00:27:39.955
<v Speaker 1>now you can see exactly what was worse

00:27:40.450 --> 00:27:42.690
<v Speaker 1>in the in the comparison of these two

00:27:42.930 --> 00:27:44.370
<v Speaker 1>profiles. In this case,

00:27:44.930 --> 00:27:48.049
<v Speaker 1>the the the comparison was quite drastic,

00:27:48.130 --> 00:27:50.210
<v Speaker 1>so we're seeing a lot of red. Right?

00:27:50.210 --> 00:27:52.530
<v Speaker 1>But if it's if it's more nuanced, we

00:27:52.530 --> 00:27:54.130
<v Speaker 1>can see exactly what was different.

00:27:54.895 --> 00:27:55.534
<v Speaker 1>And,

00:27:56.095 --> 00:27:58.175
<v Speaker 1>again, in this case, it's quite drastic, so

00:27:58.175 --> 00:28:00.014
<v Speaker 1>all of the red is pretty dark,

00:28:00.335 --> 00:28:03.375
<v Speaker 1>but it's actually shades of red

00:28:03.855 --> 00:28:06.335
<v Speaker 1>that are telling you what got how much

00:28:06.335 --> 00:28:06.575
<v Speaker 1>worse.

00:28:07.550 --> 00:28:10.510
<v Speaker 0>So I I'm curious. Like, I'm, you know,

00:28:10.510 --> 00:28:13.630
<v Speaker 0>an application developer. I'm shipping multiple times per

00:28:13.630 --> 00:28:16.910
<v Speaker 0>day. Would this compare feature allow me to

00:28:16.910 --> 00:28:17.549
<v Speaker 0>compare

00:28:17.870 --> 00:28:21.230
<v Speaker 0>a standard profile from one version against the

00:28:21.230 --> 00:28:23.550
<v Speaker 0>profile and the new version I've shipped to

00:28:22.965 --> 00:28:25.605
<v Speaker 0>see if I've got performance gains or or

00:28:25.605 --> 00:28:27.684
<v Speaker 0>or maybe things have gotten worse since I

00:28:27.684 --> 00:28:28.484
<v Speaker 0>went ahead?

00:28:28.965 --> 00:28:30.565
<v Speaker 1>I'm I'm glad you asked.

00:28:32.485 --> 00:28:36.404
<v Speaker 1>For for for for answering that question, let's

00:28:35.820 --> 00:28:38.299
<v Speaker 1>take a step back and talk about one

00:28:38.299 --> 00:28:40.379
<v Speaker 1>more thing that kind of makes

00:28:40.940 --> 00:28:42.859
<v Speaker 1>continuous profiling so great.

00:28:43.500 --> 00:28:46.299
<v Speaker 1>And for that, if you just hit profiles

00:28:46.620 --> 00:28:49.019
<v Speaker 1>at the top, this kind of just resets

00:28:49.019 --> 00:28:50.059
<v Speaker 1>our

00:28:50.205 --> 00:28:52.044
<v Speaker 1>our query. So if you

00:28:52.924 --> 00:28:53.724
<v Speaker 1>select

00:28:53.804 --> 00:28:55.565
<v Speaker 1>CPU profiles again

00:28:56.284 --> 00:28:59.804
<v Speaker 1>and then maybe filter just down to the

00:29:01.245 --> 00:29:03.404
<v Speaker 1>Parca container, if you want, you can hit

00:29:03.404 --> 00:29:06.160
<v Speaker 1>search and and then click the click the

00:29:06.160 --> 00:29:08.000
<v Speaker 1>label, or you can do a,

00:29:08.320 --> 00:29:09.360
<v Speaker 1>label search.

00:29:11.520 --> 00:29:12.240
<v Speaker 1>Yeah.

00:29:12.480 --> 00:29:13.440
<v Speaker 1>So now

00:29:14.720 --> 00:29:15.760
<v Speaker 1>other than,

00:29:16.080 --> 00:29:18.080
<v Speaker 1>compare and search, what we're seeing in the

00:29:18.080 --> 00:29:20.320
<v Speaker 1>in the search bar, there's also merge.

00:29:20.935 --> 00:29:22.375
<v Speaker 1>And what this does

00:29:23.015 --> 00:29:24.615
<v Speaker 1>is it takes

00:29:24.935 --> 00:29:27.575
<v Speaker 1>all the points in time that we've collected

00:29:27.655 --> 00:29:29.895
<v Speaker 1>over the entire time of this process,

00:29:30.215 --> 00:29:32.855
<v Speaker 1>and it compiles everything into a single report.

00:29:33.850 --> 00:29:37.210
<v Speaker 1>And this is really, really cool because not

00:29:37.210 --> 00:29:39.770
<v Speaker 1>only does it tell us where CPU time

00:29:39.770 --> 00:29:42.809
<v Speaker 1>was spent at a single point in time,

00:29:43.370 --> 00:29:45.609
<v Speaker 1>but actually it tells us statistically

00:29:45.850 --> 00:29:49.044
<v Speaker 1>over the entire lifetime of this process where

00:29:49.044 --> 00:29:51.765
<v Speaker 1>CPU was CPU time was being spent. And

00:29:51.765 --> 00:29:52.325
<v Speaker 1>so

00:29:53.365 --> 00:29:56.005
<v Speaker 1>the consequence of that is that once we

00:29:56.005 --> 00:29:57.684
<v Speaker 1>look at that report

00:29:57.684 --> 00:30:00.164
<v Speaker 1>and we can we can optimize something in

00:30:00.164 --> 00:30:03.309
<v Speaker 1>that holistic report of our entire

00:30:03.310 --> 00:30:04.750
<v Speaker 1>process's lifetime,

00:30:05.070 --> 00:30:07.630
<v Speaker 1>if we can optimize something from that, we

00:30:07.630 --> 00:30:08.509
<v Speaker 1>will actually

00:30:08.990 --> 00:30:11.309
<v Speaker 1>reduce CPU time of the entire

00:30:11.390 --> 00:30:13.710
<v Speaker 1>process process's lifetime. Right?

00:30:15.125 --> 00:30:18.084
<v Speaker 1>So that's how we'll actually do significant

00:30:18.164 --> 00:30:19.364
<v Speaker 1>cost savings.

00:30:21.125 --> 00:30:23.524
<v Speaker 0>K. So should I click the merge button?

00:30:23.524 --> 00:30:24.485
<v Speaker 1>Yep. Hit it.

00:30:26.850 --> 00:30:29.809
<v Speaker 1>So now now we we see all of

00:30:29.809 --> 00:30:31.409
<v Speaker 1>the data of the entire

00:30:31.570 --> 00:30:33.889
<v Speaker 1>time that the Parca process has been

00:30:34.530 --> 00:30:35.330
<v Speaker 1>alive,

00:30:35.490 --> 00:30:37.169
<v Speaker 1>and we can we can explore

00:30:38.130 --> 00:30:40.130
<v Speaker 1>where that CPU time was being spent as

00:30:40.130 --> 00:30:43.845
<v Speaker 1>opposed to just a single ten second profiling

00:30:43.845 --> 00:30:44.565
<v Speaker 1>time.

00:30:46.725 --> 00:30:47.284
<v Speaker 0>Cool.

00:30:48.325 --> 00:30:50.164
<v Speaker 0>I like that. That's very interesting.

00:30:50.325 --> 00:30:51.044
<v Speaker 1>And

00:30:51.284 --> 00:30:53.364
<v Speaker 1>now now coming back to

00:30:53.684 --> 00:30:55.284
<v Speaker 1>the question that you had

00:30:55.610 --> 00:30:57.290
<v Speaker 0>Well, can I ask you a and I

00:30:57.290 --> 00:30:57.929
<v Speaker 0>really

00:30:58.570 --> 00:31:00.490
<v Speaker 1>Your your question was

00:31:01.690 --> 00:31:03.530
<v Speaker 1>to to to come back to your question,

00:31:03.530 --> 00:31:05.610
<v Speaker 1>which was, can I essentially

00:31:05.610 --> 00:31:06.410
<v Speaker 1>compare

00:31:06.570 --> 00:31:07.370
<v Speaker 1>two versions

00:31:10.065 --> 00:31:12.385
<v Speaker 1>after I kind of deploy them? Right? Yeah.

00:31:12.385 --> 00:31:14.065
<v Speaker 0>Yeah. Yeah. And the answer the answer to

00:31:14.065 --> 00:31:16.384
<v Speaker 1>that is yes. And but not only

00:31:16.625 --> 00:31:18.465
<v Speaker 1>a single point in time, but you can

00:31:18.465 --> 00:31:19.024
<v Speaker 1>actually

00:31:19.505 --> 00:31:21.105
<v Speaker 1>compare the entirety

00:31:21.265 --> 00:31:23.665
<v Speaker 1>of two versions. So not just

00:31:24.400 --> 00:31:25.120
<v Speaker 1>this

00:31:25.440 --> 00:31:27.520
<v Speaker 1>this process at this time and this process

00:31:27.520 --> 00:31:29.120
<v Speaker 1>at that time, but, no, you can actually

00:31:29.120 --> 00:31:31.600
<v Speaker 1>merge all of the data of a single

00:31:31.600 --> 00:31:33.519
<v Speaker 1>version of a of a program

00:31:33.760 --> 00:31:35.679
<v Speaker 1>and compare those two versions.

00:31:35.920 --> 00:31:38.160
<v Speaker 1>So finally, we'll be able to answer down

00:31:38.160 --> 00:31:39.360
<v Speaker 1>to the line number

00:31:39.885 --> 00:31:42.365
<v Speaker 1>what was different. Why did why is this

00:31:42.365 --> 00:31:45.245
<v Speaker 1>thing using more CPU now after I deployed

00:31:45.245 --> 00:31:47.405
<v Speaker 1>it compared to previously?

00:31:47.805 --> 00:31:50.365
<v Speaker 1>Or why did it get better? Right? All

00:31:50.365 --> 00:31:51.965
<v Speaker 1>of these things that previously,

00:31:52.525 --> 00:31:54.285
<v Speaker 1>as engineers, we were kind of guessing,

00:31:55.039 --> 00:31:57.440
<v Speaker 1>Now we actually have the answers.

00:31:58.799 --> 00:31:59.999
<v Speaker 0>Alright. Awesome.

00:32:03.440 --> 00:32:06.000
<v Speaker 0>This is really cool. I think this is

00:32:06.000 --> 00:32:07.120
<v Speaker 0>absolutely game changer.

00:32:07.745 --> 00:32:08.465
<v Speaker 0>Now

00:32:08.625 --> 00:32:10.545
<v Speaker 0>we've got one question from Russell in the

00:32:10.545 --> 00:32:12.705
<v Speaker 0>chat, which we'll tackle in a minute. But

00:32:12.705 --> 00:32:14.465
<v Speaker 0>I also wanna tackle something,

00:32:15.825 --> 00:32:17.905
<v Speaker 0>like, just one one of the really simple

00:32:17.905 --> 00:32:20.545
<v Speaker 0>things here that not everyone may be familiar

00:32:21.289 --> 00:32:23.049
<v Speaker 0>with this graph and what this is what

00:32:23.049 --> 00:32:24.809
<v Speaker 0>this is displaying and what it means and

00:32:24.809 --> 00:32:26.809
<v Speaker 0>why things are are duplicated.

00:32:27.049 --> 00:32:28.970
<v Speaker 0>Could you give us the the one zero

00:32:28.970 --> 00:32:30.490
<v Speaker 0>one for this flame graph and what that

00:32:30.490 --> 00:32:31.049
<v Speaker 0>means?

00:32:31.929 --> 00:32:35.049
<v Speaker 1>Yeah. So as you already said, this visualization

00:32:35.049 --> 00:32:36.409
<v Speaker 1>is called a flame graph.

00:32:37.195 --> 00:32:39.115
<v Speaker 1>And the way that we read it

00:32:39.515 --> 00:32:41.835
<v Speaker 1>is that from actually, this is called an

00:32:41.835 --> 00:32:43.035
<v Speaker 1>icicle graph,

00:32:43.435 --> 00:32:45.435
<v Speaker 1>which is the upside down version of the

00:32:45.435 --> 00:32:47.275
<v Speaker 1>flame graph. The flame graph is built from

00:32:47.275 --> 00:32:50.110
<v Speaker 1>bottom up like a flame. Right? But the

00:32:50.110 --> 00:32:53.229
<v Speaker 1>icicle graph is icicles hanging from the ceiling

00:32:53.309 --> 00:32:55.149
<v Speaker 1>just like the one that we're seeing here.

00:32:55.149 --> 00:32:56.349
<v Speaker 0>Today, love Yeah.

00:32:57.070 --> 00:32:59.710
<v Speaker 1>I, you know, I I created the brand

00:32:59.710 --> 00:33:02.190
<v Speaker 1>Polar Signals without even knowing this, and then

00:33:02.190 --> 00:33:04.875
<v Speaker 1>afterwards was, like, like,

00:33:04.875 --> 00:33:06.395
<v Speaker 1>a happy little accident.

00:33:08.075 --> 00:33:10.315
<v Speaker 1>But, yeah, coming back to how to read

00:33:10.315 --> 00:33:13.035
<v Speaker 1>this, essentially, the very top bar, the root

00:33:13.675 --> 00:33:14.795
<v Speaker 1>describes all

00:33:15.035 --> 00:33:17.595
<v Speaker 1>CPU time that we're looking at. And then

00:33:17.595 --> 00:33:19.195
<v Speaker 1>every span

00:33:19.870 --> 00:33:21.389
<v Speaker 1>that we're looking at

00:33:21.710 --> 00:33:24.909
<v Speaker 1>underneath it is relative to that total.

00:33:24.990 --> 00:33:25.789
<v Speaker 1>And so

00:33:26.270 --> 00:33:28.509
<v Speaker 1>if there is a span in here

00:33:29.630 --> 00:33:31.789
<v Speaker 1>that we can optimize,

00:33:31.950 --> 00:33:33.630
<v Speaker 1>it means that the

00:33:33.630 --> 00:33:35.554
<v Speaker 1>width of it will,

00:33:36.915 --> 00:33:38.675
<v Speaker 1>that will be the effect that it will

00:33:38.675 --> 00:33:41.155
<v Speaker 1>have on the entirety of our program. So

00:33:41.155 --> 00:33:43.394
<v Speaker 1>let's say one of the larger,

00:33:44.275 --> 00:33:46.275
<v Speaker 1>spans that we see in the middle here,

00:33:46.275 --> 00:33:47.554
<v Speaker 1>if we're able to

00:33:47.875 --> 00:33:48.515
<v Speaker 1>optimize

00:33:49.540 --> 00:33:52.180
<v Speaker 1>that, we can actually and you can hover

00:33:52.180 --> 00:33:53.940
<v Speaker 1>over it. It tells you the percentage as

00:33:53.940 --> 00:33:56.580
<v Speaker 1>well. If we can optimize that away in

00:33:56.580 --> 00:33:58.020
<v Speaker 1>this case, it's 90%,

00:33:58.020 --> 00:34:00.100
<v Speaker 1>but, right, the further we go down, the

00:34:00.100 --> 00:34:02.864
<v Speaker 1>less it gets because it's kind of cumulative.

00:34:03.904 --> 00:34:06.225
<v Speaker 1>But if we can optimize this one away,

00:34:06.225 --> 00:34:08.784
<v Speaker 1>for example, we will be saving 36%

00:34:08.864 --> 00:34:11.585
<v Speaker 1>of our of our entire process.

00:34:12.224 --> 00:34:12.784
<v Speaker 1>And

00:34:13.320 --> 00:34:14.840
<v Speaker 1>the more we do this,

00:34:15.400 --> 00:34:17.480
<v Speaker 1>the more effect we see on on our

00:34:17.480 --> 00:34:18.440
<v Speaker 1>cloud bill.

00:34:18.840 --> 00:34:20.520
<v Speaker 1>But there are actually a couple of other

00:34:20.520 --> 00:34:22.280
<v Speaker 1>use cases that I think are also good

00:34:22.280 --> 00:34:23.080
<v Speaker 1>to talk about

00:34:23.560 --> 00:34:26.200
<v Speaker 1>when we when we think about profiling or

00:34:26.435 --> 00:34:27.955
<v Speaker 1>continuous profiling.

00:34:28.114 --> 00:34:30.355
<v Speaker 1>Obviously, cost savings is one that we've talked

00:34:30.355 --> 00:34:32.755
<v Speaker 1>about several times by now, but I think

00:34:32.755 --> 00:34:35.074
<v Speaker 1>there are kind of two more that a

00:34:35.074 --> 00:34:36.915
<v Speaker 1>lot of people find very compelling.

00:34:38.594 --> 00:34:41.074
<v Speaker 1>The the the

00:34:40.150 --> 00:34:43.110
<v Speaker 1>kind of helping you with latency optimizations

00:34:43.110 --> 00:34:44.710
<v Speaker 1>because latency

00:34:44.790 --> 00:34:46.790
<v Speaker 1>tends to be we we tend to be

00:34:46.790 --> 00:34:48.630
<v Speaker 1>able to if we're this advanced,

00:34:48.710 --> 00:34:50.390
<v Speaker 1>we may be able to detect

00:34:51.350 --> 00:34:54.949
<v Speaker 1>where latency problems exist in our

00:34:55.425 --> 00:34:58.305
<v Speaker 1>in our system with tracing data, but tracing

00:34:58.305 --> 00:35:00.625
<v Speaker 1>data is actually very high level. Right? It

00:35:00.625 --> 00:35:03.105
<v Speaker 1>doesn't tell us anything about the lines of

00:35:03.105 --> 00:35:04.945
<v Speaker 1>code that we need to optimize.

00:35:05.025 --> 00:35:07.905
<v Speaker 1>Yep. Combining that with profiling data

00:35:07.905 --> 00:35:09.585
<v Speaker 1>is actually incredibly powerful,

00:35:10.450 --> 00:35:13.970
<v Speaker 1>and we've worked with, like, ecommerce companies that

00:35:13.970 --> 00:35:16.370
<v Speaker 1>are optimizing their latency

00:35:16.370 --> 00:35:18.130
<v Speaker 1>through this type of data.

00:35:18.370 --> 00:35:18.930
<v Speaker 1>And

00:35:19.410 --> 00:35:20.770
<v Speaker 1>if you might know,

00:35:21.810 --> 00:35:24.290
<v Speaker 1>ecommerce companies have this kind of

00:35:26.395 --> 00:35:29.115
<v Speaker 1>target to have every interaction in their system

00:35:29.115 --> 00:35:32.155
<v Speaker 1>be less than a hundred milliseconds because that

00:35:32.155 --> 00:35:33.355
<v Speaker 1>drives conversion.

00:35:33.355 --> 00:35:35.595
<v Speaker 1>Because we humans like things to feel

00:35:36.475 --> 00:35:37.275
<v Speaker 1>instant,

00:35:37.915 --> 00:35:39.835
<v Speaker 1>and that means that we're more likely to

00:35:39.835 --> 00:35:41.195
<v Speaker 1>purchase something on a website.

00:35:41.960 --> 00:35:43.160
<v Speaker 1>So that's kind of

00:35:44.519 --> 00:35:46.520
<v Speaker 1>in the in the grand scheme, that's

00:35:46.599 --> 00:35:48.359
<v Speaker 1>use case number two, and it tends to

00:35:48.359 --> 00:35:51.000
<v Speaker 1>be actually a much bigger motivator for companies

00:35:51.000 --> 00:35:53.160
<v Speaker 1>to make more money than just to save

00:35:53.160 --> 00:35:54.200
<v Speaker 1>money. Right?

00:35:55.575 --> 00:35:56.375
<v Speaker 1>But go

00:35:57.335 --> 00:35:59.415
<v Speaker 1>ahead. Would it be fair to say you

00:35:59.415 --> 00:36:02.215
<v Speaker 0>know, we're talking about cloud native and microservices.

00:36:02.215 --> 00:36:04.055
<v Speaker 0>You know? Hopefully, the people watching have a

00:36:04.055 --> 00:36:06.055
<v Speaker 0>little bit of experience with distributed tracing. And

00:36:06.055 --> 00:36:08.135
<v Speaker 0>like you said, it gives you the latency

00:36:08.135 --> 00:36:10.830
<v Speaker 0>response time from service to service communication. Is

00:36:10.830 --> 00:36:13.470
<v Speaker 0>it fair to think of profile as tracing

00:36:13.470 --> 00:36:16.750
<v Speaker 0>at the function level, exposing individually within services

00:36:16.750 --> 00:36:19.470
<v Speaker 0>what is actually happening on that call stack?

00:36:19.950 --> 00:36:22.510
<v Speaker 1>Yeah. Yeah. That that is entirely

00:36:22.510 --> 00:36:23.550
<v Speaker 1>accurate.

00:36:24.030 --> 00:36:26.455
<v Speaker 1>The the difference is that it's not across

00:36:26.455 --> 00:36:28.855
<v Speaker 1>services. It's only within a process.

00:36:30.055 --> 00:36:31.975
<v Speaker 1>But we're we're actually working on a couple

00:36:31.975 --> 00:36:33.255
<v Speaker 1>of correlation

00:36:33.255 --> 00:36:35.415
<v Speaker 1>techniques so that we can tell you, for

00:36:35.415 --> 00:36:37.895
<v Speaker 1>example, all of the CPU time that was

00:36:37.895 --> 00:36:38.215
<v Speaker 1>spent

00:36:39.380 --> 00:36:41.940
<v Speaker 1>with a particular trace, for example, so that

00:36:41.940 --> 00:36:44.580
<v Speaker 1>we can jump from a trace to profiling

00:36:44.580 --> 00:36:45.300
<v Speaker 1>data.

00:36:45.620 --> 00:36:47.700
<v Speaker 1>This is not something that works yet, but

00:36:47.700 --> 00:36:49.300
<v Speaker 1>we have a couple of strategies

00:36:49.860 --> 00:36:52.660
<v Speaker 1>that we're exploring to to make something like

00:36:52.660 --> 00:36:53.140
<v Speaker 1>that work.

00:36:53.825 --> 00:36:54.464
<v Speaker 1>Right.

00:36:55.345 --> 00:36:57.424
<v Speaker 1>But yeah. And then then the the last

00:36:57.424 --> 00:36:59.025
<v Speaker 1>use case that I was talking about is

00:36:59.025 --> 00:37:00.944
<v Speaker 1>kind of I I think we sort of

00:37:00.944 --> 00:37:02.224
<v Speaker 1>touched on it already,

00:37:02.385 --> 00:37:04.785
<v Speaker 1>but I think it can be generalized

00:37:04.785 --> 00:37:05.424
<v Speaker 1>as

00:37:07.100 --> 00:37:08.300
<v Speaker 1>incident response.

00:37:08.300 --> 00:37:11.100
<v Speaker 1>Right? Because we have this data of what

00:37:11.500 --> 00:37:14.140
<v Speaker 1>our processes are executing down to the line

00:37:14.140 --> 00:37:14.700
<v Speaker 1>number,

00:37:15.100 --> 00:37:17.500
<v Speaker 1>we can actually answer some of the questions

00:37:17.500 --> 00:37:18.060
<v Speaker 1>that

00:37:19.355 --> 00:37:21.835
<v Speaker 1>we as engineers have kind of or at

00:37:21.835 --> 00:37:24.234
<v Speaker 1>least I myself have been asking myself ever

00:37:24.234 --> 00:37:26.234
<v Speaker 1>since before I I had a tool like

00:37:26.234 --> 00:37:28.954
<v Speaker 1>this, which is, like, why was my process

00:37:28.954 --> 00:37:29.755
<v Speaker 1>spending

00:37:29.835 --> 00:37:32.555
<v Speaker 1>CPU time or, like, a had a CPU

00:37:32.555 --> 00:37:33.914
<v Speaker 1>spike here and not here?

00:37:34.490 --> 00:37:36.490
<v Speaker 1>And almost always, as we as you said

00:37:36.490 --> 00:37:38.410
<v Speaker 1>earlier, it's GC,

00:37:38.410 --> 00:37:39.450
<v Speaker 1>garbage collection.

00:37:39.770 --> 00:37:40.330
<v Speaker 1>But,

00:37:41.290 --> 00:37:43.609
<v Speaker 1>yeah, sometimes it's more it's more surprising than

00:37:43.609 --> 00:37:44.090
<v Speaker 1>that

00:37:44.809 --> 00:37:47.530
<v Speaker 1>or with memory. Right? Like, why did my

00:37:47.530 --> 00:37:49.290
<v Speaker 1>process use more memory at this point in

00:37:49.290 --> 00:37:51.135
<v Speaker 1>time versus this other point in time?

00:37:51.775 --> 00:37:53.215
<v Speaker 0>Yes. Definitely.

00:37:54.735 --> 00:37:57.455
<v Speaker 0>Alright. Let's tackle the questions we have in

00:37:57.455 --> 00:37:58.975
<v Speaker 0>the chat, and then we'll jump back to

00:37:58.975 --> 00:38:00.095
<v Speaker 0>our demo here.

00:38:00.735 --> 00:38:01.615
<v Speaker 0>And

00:38:01.775 --> 00:38:04.170
<v Speaker 0>we got a hello, just done with the

00:38:04.170 --> 00:38:06.330
<v Speaker 0>Parca office hours from Mathias.

00:38:06.410 --> 00:38:07.290
<v Speaker 1>We

00:38:08.890 --> 00:38:11.050
<v Speaker 0>got okay. Question for Russell.

00:38:11.450 --> 00:38:13.609
<v Speaker 0>Did you say it profiles everything,

00:38:13.609 --> 00:38:16.090
<v Speaker 0>I e the API server? And if so,

00:38:16.415 --> 00:38:19.455
<v Speaker 0>does that work on cloud hosted Kubernetes instances

00:38:19.455 --> 00:38:21.615
<v Speaker 0>where the control plane is managed by the

00:38:21.615 --> 00:38:22.495
<v Speaker 0>cloud vendor?

00:38:23.695 --> 00:38:24.255
<v Speaker 1>So

00:38:26.015 --> 00:38:27.855
<v Speaker 1>probably for most of the

00:38:28.575 --> 00:38:30.494
<v Speaker 1>cloud vendors that you're thinking of,

00:38:31.370 --> 00:38:32.170
<v Speaker 1>because

00:38:32.490 --> 00:38:36.010
<v Speaker 1>we can't get the Parca agent to

00:38:36.090 --> 00:38:38.490
<v Speaker 1>to get deployed on the

00:38:39.050 --> 00:38:41.450
<v Speaker 1>wherever the the API server runs.

00:38:41.690 --> 00:38:42.410
<v Speaker 1>Basically,

00:38:43.050 --> 00:38:44.890
<v Speaker 1>as as long as we can get the

00:38:44.890 --> 00:38:47.530
<v Speaker 1>Parca agent to be on the same host

00:38:47.265 --> 00:38:49.265
<v Speaker 1>as something, it will be able to profile

00:38:49.265 --> 00:38:49.825
<v Speaker 1>it.

00:38:50.224 --> 00:38:51.984
<v Speaker 1>As a matter of fact, we're actually thinking

00:38:51.984 --> 00:38:53.825
<v Speaker 1>about a couple of strategies where we can

00:38:53.825 --> 00:38:54.545
<v Speaker 1>expand

00:38:55.505 --> 00:38:57.825
<v Speaker 1>the things that we're profiling to not just

00:38:57.825 --> 00:38:59.105
<v Speaker 1>be the containers

00:38:59.184 --> 00:39:01.505
<v Speaker 1>on a on a system, but actually every

00:39:01.505 --> 00:39:02.704
<v Speaker 1>process on that system.

00:39:03.240 --> 00:39:03.960
<v Speaker 1>Because

00:39:04.280 --> 00:39:06.520
<v Speaker 1>I think I think it's kind of obvious

00:39:06.520 --> 00:39:08.520
<v Speaker 1>once we say it, but there can be

00:39:08.520 --> 00:39:09.720
<v Speaker 1>other interactions

00:39:09.880 --> 00:39:12.119
<v Speaker 1>with processes on a host that are not

00:39:12.119 --> 00:39:15.000
<v Speaker 1>running in containers. Right? Maybe they're system d

00:39:15.000 --> 00:39:17.240
<v Speaker 1>units, or maybe they're not running in c

00:39:17.240 --> 00:39:17.960
<v Speaker 1>groups at all.

00:39:18.734 --> 00:39:19.375
<v Speaker 1>So,

00:39:20.734 --> 00:39:22.734
<v Speaker 1>yeah, hopefully, that answers the question.

00:39:23.055 --> 00:39:25.454
<v Speaker 0>Yeah. I think so. We also got another

00:39:25.454 --> 00:39:26.655
<v Speaker 0>one from Mozz.

00:39:26.894 --> 00:39:27.775
<v Speaker 0>Compare

00:39:28.015 --> 00:39:31.454
<v Speaker 0>the CPU time consumed by a specific function

00:39:31.454 --> 00:39:33.694
<v Speaker 0>run on two different containers or different nodes.

00:39:34.410 --> 00:39:37.690
<v Speaker 1>Yes. Absolutely. That's that's exactly what the compare

00:39:37.690 --> 00:39:38.490
<v Speaker 1>functionality

00:39:38.490 --> 00:39:39.050
<v Speaker 1>does.

00:39:39.690 --> 00:39:41.370
<v Speaker 1>We're also working on

00:39:42.250 --> 00:39:44.330
<v Speaker 1>being able to filter down

00:39:44.569 --> 00:39:48.170
<v Speaker 1>the stack traces to not only compare by

00:39:48.170 --> 00:39:49.770
<v Speaker 1>container or by process,

00:39:50.225 --> 00:39:53.105
<v Speaker 1>but actually down to the stack trace so

00:39:53.105 --> 00:39:55.105
<v Speaker 1>that you can say, I only wanna see

00:39:55.105 --> 00:39:57.585
<v Speaker 1>data about this one function, and then you

00:39:57.585 --> 00:39:59.425
<v Speaker 1>can compare it exactly the way that it

00:39:59.425 --> 00:40:01.585
<v Speaker 1>was phrased in the question. Right now, you

00:40:01.585 --> 00:40:04.540
<v Speaker 1>would compare two whole profiles,

00:40:04.540 --> 00:40:06.940
<v Speaker 1>and you would need to find the specific

00:40:06.940 --> 00:40:09.099
<v Speaker 1>function that you're looking for, but we're absolutely

00:40:09.099 --> 00:40:10.140
<v Speaker 1>working on

00:40:10.460 --> 00:40:13.579
<v Speaker 1>on this specific use case already to support

00:40:13.579 --> 00:40:14.300
<v Speaker 1>it even better.

00:40:15.215 --> 00:40:18.095
<v Speaker 0>Awesome. Thank you. And we'll tackle this last

00:40:18.095 --> 00:40:19.295
<v Speaker 0>one that came in from.

00:40:19.935 --> 00:40:22.175
<v Speaker 0>Do we only get CPU profiles

00:40:22.255 --> 00:40:22.975
<v Speaker 0>there?

00:40:23.695 --> 00:40:26.175
<v Speaker 1>So great great great question. So

00:40:26.575 --> 00:40:29.695
<v Speaker 1>I think I I mentioned it

00:40:28.779 --> 00:40:30.380
<v Speaker 1>earlier very

00:40:30.380 --> 00:40:33.900
<v Speaker 1>briefly, but the entire Parca project is based

00:40:33.900 --> 00:40:37.740
<v Speaker 1>around the open standard p professor. And any

00:40:37.740 --> 00:40:40.859
<v Speaker 1>p professor formatted profile can be written to

00:40:41.260 --> 00:40:43.900
<v Speaker 1>the Parca storage and can be visualized and

00:40:44.085 --> 00:40:45.925
<v Speaker 1>analyzed in the same way as we're doing

00:40:45.925 --> 00:40:47.925
<v Speaker 1>with this data. So as a matter of

00:40:47.925 --> 00:40:48.725
<v Speaker 1>fact, the

00:40:49.045 --> 00:40:53.285
<v Speaker 1>Parca agent also produces pprof compatible profiles

00:40:53.285 --> 00:40:55.125
<v Speaker 1>and then sends those to

00:40:55.285 --> 00:40:57.640
<v Speaker 1>to the Parca storage. And so as long

00:40:57.640 --> 00:41:00.200
<v Speaker 1>as you can produce profiling data in the

00:41:00.200 --> 00:41:01.320
<v Speaker 1>pPRA format,

00:41:01.560 --> 00:41:04.120
<v Speaker 1>you can write it continuously to

00:41:04.680 --> 00:41:06.280
<v Speaker 1>to the Parca storage.

00:41:06.440 --> 00:41:07.000
<v Speaker 1>So

00:41:08.520 --> 00:41:10.680
<v Speaker 1>there there are lots of profilers out there.

00:41:10.680 --> 00:41:11.480
<v Speaker 1>As I said earlier,

00:41:12.145 --> 00:41:12.945
<v Speaker 1>the

00:41:14.225 --> 00:41:17.985
<v Speaker 1>the Go runtime has support for memory profiling,

00:41:18.065 --> 00:41:18.465
<v Speaker 1>for

00:41:20.145 --> 00:41:20.945
<v Speaker 1>allocation

00:41:20.945 --> 00:41:21.825
<v Speaker 1>profiling,

00:41:21.825 --> 00:41:24.305
<v Speaker 1>for threads being created, for Go routines,

00:41:24.750 --> 00:41:26.510
<v Speaker 1>for mutex contention,

00:41:26.510 --> 00:41:27.950
<v Speaker 1>for a whole lot of things.

00:41:28.590 --> 00:41:30.670
<v Speaker 1>And all of those can be written to

00:41:31.230 --> 00:41:33.310
<v Speaker 1>to the Parca storage and can be analyzed

00:41:33.310 --> 00:41:35.310
<v Speaker 1>in the same way. So these are these

00:41:35.310 --> 00:41:37.230
<v Speaker 0>are profiles that you plan to support in

00:41:37.230 --> 00:41:39.790
<v Speaker 0>Parca. They're just not quite there yet?

00:41:40.464 --> 00:41:43.105
<v Speaker 1>So you there there's there there are kind

00:41:43.105 --> 00:41:45.265
<v Speaker 1>of two ways to ingest data today

00:41:45.425 --> 00:41:47.185
<v Speaker 1>into into Parca.

00:41:47.505 --> 00:41:49.585
<v Speaker 1>The first one is pushing the data, and

00:41:49.585 --> 00:41:52.145
<v Speaker 1>that is exactly what the Parca agent does.

00:41:52.224 --> 00:41:54.305
<v Speaker 1>Whenever it has a profile ready, it just

00:41:54.305 --> 00:41:56.145
<v Speaker 1>sends it to the Parca storage.

00:41:58.200 --> 00:42:00.360
<v Speaker 1>And the Parca server

00:42:01.000 --> 00:42:02.520
<v Speaker 1>actually also supports

00:42:02.600 --> 00:42:05.320
<v Speaker 1>scraping profiles in the same way. You can

00:42:05.320 --> 00:42:07.720
<v Speaker 1>think of it very similar to what Prometheus

00:42:07.720 --> 00:42:10.535
<v Speaker 1>does, where Prometheus has its metrics endpoint, and

00:42:10.535 --> 00:42:12.934
<v Speaker 1>it scrapes the metrics from that endpoint every

00:42:12.934 --> 00:42:13.974
<v Speaker 1>fifteen seconds.

00:42:14.295 --> 00:42:16.454
<v Speaker 1>Parca can actually do exactly the same thing

00:42:16.454 --> 00:42:18.535
<v Speaker 1>with p professor formatted profiles.

00:42:18.535 --> 00:42:19.815
<v Speaker 1>Ah. And so

00:42:20.694 --> 00:42:22.694
<v Speaker 1>I think, actually, this might be a a

00:42:22.694 --> 00:42:24.055
<v Speaker 1>great time to have a have a look

00:42:24.055 --> 00:42:24.375
<v Speaker 1>at that.

00:42:25.420 --> 00:42:27.980
<v Speaker 1>What you can do is you could

00:42:28.620 --> 00:42:30.780
<v Speaker 1>go back to the parka.dev

00:42:30.860 --> 00:42:31.820
<v Speaker 1>website,

00:42:31.820 --> 00:42:33.820
<v Speaker 1>and we can switch from the

00:42:34.940 --> 00:42:35.900
<v Speaker 1>Kubernetes

00:42:35.900 --> 00:42:39.065
<v Speaker 1>deployment to the binary because then we can

00:42:39.065 --> 00:42:41.225
<v Speaker 1>just have Parca scrape itself

00:42:41.704 --> 00:42:42.985
<v Speaker 1>because Parca

00:42:43.145 --> 00:42:45.945
<v Speaker 1>is instrumented with a whole lot of profiling,

00:42:46.265 --> 00:42:47.545
<v Speaker 1>and then we can have a look at

00:42:47.545 --> 00:42:48.985
<v Speaker 1>those profiles as well.

00:42:49.385 --> 00:42:51.785
<v Speaker 0>Yeah. I I think that's quick. I don't

00:42:51.785 --> 00:42:52.265
<v Speaker 0>wanna

00:42:52.890 --> 00:42:54.490
<v Speaker 0>make too many assumptions, but I think it's

00:42:54.490 --> 00:42:56.569
<v Speaker 0>quite normal in the goal ecosystem, right, to

00:42:56.569 --> 00:42:58.329
<v Speaker 0>have p professor embedded in your brain. Right?

00:42:58.329 --> 00:42:59.690
<v Speaker 0>I I remember when I was working on

00:42:59.690 --> 00:43:02.250
<v Speaker 0>InfluxDB, we had to debug slash p professor

00:43:02.250 --> 00:43:03.050
<v Speaker 0>endpoint,

00:43:03.210 --> 00:43:05.049
<v Speaker 0>which exposed a whole bunch

00:43:05.285 --> 00:43:07.365
<v Speaker 0>of information. And you're saying that Parca can

00:43:07.365 --> 00:43:09.045
<v Speaker 0>just consume that right away if you tell

00:43:09.045 --> 00:43:12.005
<v Speaker 0>it where it is? Exactly. Yep. Okay.

00:43:12.325 --> 00:43:14.645
<v Speaker 0>Alright. So let's jump back over here. So

00:43:14.645 --> 00:43:16.325
<v Speaker 0>if I go back to the start and

00:43:16.325 --> 00:43:17.685
<v Speaker 0>the binary one

00:43:18.005 --> 00:43:18.405
<v Speaker 0>Yep.

00:43:19.710 --> 00:43:21.310
<v Speaker 0>Just gonna work on a

00:43:21.630 --> 00:43:22.750
<v Speaker 0>m one Mac?

00:43:24.670 --> 00:43:26.590
<v Speaker 1>That is a great question.

00:43:27.950 --> 00:43:29.470
<v Speaker 0>Let's find out is the answer.

00:43:33.835 --> 00:43:35.275
<v Speaker 1>I do not think so.

00:43:40.634 --> 00:43:42.795
<v Speaker 0>I think it is. That that looks like

00:43:42.795 --> 00:43:43.595
<v Speaker 1>it works.

00:43:44.234 --> 00:43:44.555
<v Speaker 1>Amazing.

00:43:46.200 --> 00:43:49.240
<v Speaker 0>Nice. Alright. Great. So now we get the

00:43:49.240 --> 00:43:52.120
<v Speaker 0>basic configuration and just run Yeah. Parca.

00:43:53.080 --> 00:43:54.520
<v Speaker 0>Do mind if I just quickly take a

00:43:54.520 --> 00:43:57.000
<v Speaker 0>look at this? Yeah. Go ahead. Alright.

00:43:57.320 --> 00:43:57.960
<v Speaker 0>So

00:43:59.975 --> 00:44:01.975
<v Speaker 0>It looks like a Prometheus config.

00:44:02.215 --> 00:44:04.135
<v Speaker 0>Yeah. It it literally

00:44:04.135 --> 00:44:06.055
<v Speaker 1>reuses Prometheus code.

00:44:07.095 --> 00:44:09.175
<v Speaker 0>Alright. So you just define the the script

00:44:09.175 --> 00:44:11.815
<v Speaker 0>configs. So I'm assuming these targets could be

00:44:11.815 --> 00:44:14.450
<v Speaker 0>anywhere I know there's a container or a

00:44:14.450 --> 00:44:17.650
<v Speaker 0>pod, an application that exposes p professor endpoints

00:44:17.650 --> 00:44:20.050
<v Speaker 0>and Parca just pulls them in. Right? Okay.

00:44:23.809 --> 00:44:25.890
<v Speaker 0>And assuming I just go to seventy seventy

00:44:25.890 --> 00:44:27.410
<v Speaker 0>local host and Yep.

00:44:28.475 --> 00:44:30.235
<v Speaker 1>You still have that open, so let's just

00:44:30.235 --> 00:44:31.035
<v Speaker 0>refresh.

00:44:38.075 --> 00:44:40.315
<v Speaker 0>Is this my old one? I think maybe.

00:44:50.460 --> 00:44:52.780
<v Speaker 0>Not seeing what I expected to see.

00:44:53.020 --> 00:44:55.500
<v Speaker 1>Yeah. That that still looks like our Cboe

00:44:55.500 --> 00:44:55.900
<v Speaker 1>cluster.

00:44:58.515 --> 00:45:00.355
<v Speaker 1>Yeah. Yeah. This is too much data.

00:45:00.755 --> 00:45:01.155
<v Speaker 1>We we

00:45:03.315 --> 00:45:05.474
<v Speaker 1>that's definitely not But I'm not port forwarding

00:45:05.474 --> 00:45:07.155
<v Speaker 0>anymore. I'm confused.

00:45:08.355 --> 00:45:10.355
<v Speaker 0>Am I? No. Oh, I am.

00:45:12.960 --> 00:45:13.760
<v Speaker 0>So did this

00:45:16.080 --> 00:45:18.240
<v Speaker 1>Is this maybe a virtual machine of some

00:45:18.240 --> 00:45:18.800
<v Speaker 1>sort?

00:45:19.680 --> 00:45:22.000
<v Speaker 0>No. Uh-uh. Well, my port forward was still

00:45:22.000 --> 00:45:24.400
<v Speaker 0>running, and so I actually would have expected

00:45:24.640 --> 00:45:25.840
<v Speaker 0>an error message Yeah.

00:45:26.400 --> 00:45:27.680
<v Speaker 1>I I I did as well.

00:45:29.565 --> 00:45:31.885
<v Speaker 0>Oh, there we go. Okay. Yeah.

00:45:32.205 --> 00:45:33.085
<v Speaker 1>Now it works.

00:45:33.405 --> 00:45:35.485
<v Speaker 1>Yep. So now you can see these are

00:45:35.485 --> 00:45:37.085
<v Speaker 1>all the types of profiles

00:45:37.405 --> 00:45:38.045
<v Speaker 1>that

00:45:38.365 --> 00:45:39.725
<v Speaker 1>Parca scrapes from itself.

00:45:41.170 --> 00:45:43.570
<v Speaker 0>Yeah. So I think, like, memory in use

00:45:43.570 --> 00:45:45.570
<v Speaker 1>is a in use bytes is a nice

00:45:45.570 --> 00:45:46.610
<v Speaker 1>one to look at.

00:45:48.770 --> 00:45:49.730
<v Speaker 0>Search.

00:45:51.090 --> 00:45:53.410
<v Speaker 1>Let's get let's give it a couple of

00:45:53.410 --> 00:45:54.370
<v Speaker 1>seconds because

00:45:54.755 --> 00:45:56.435
<v Speaker 1>it's not writing

00:45:56.755 --> 00:45:58.595
<v Speaker 1>a whole lot of data. Right? Like, it's

00:45:58.595 --> 00:45:59.795
<v Speaker 1>only about itself.

00:46:01.075 --> 00:46:02.995
<v Speaker 0>Yeah. So what what was the do we

00:46:02.995 --> 00:46:04.995
<v Speaker 0>define a scrape interval in that config? I

00:46:04.995 --> 00:46:06.915
<v Speaker 0>wasn't Yes. Yeah. Okay.

00:46:08.100 --> 00:46:10.260
<v Speaker 0>I don't have my history there. So that's

00:46:10.260 --> 00:46:12.580
<v Speaker 0>just I can tell it to scrape profiles

00:46:12.580 --> 00:46:14.660
<v Speaker 0>on a more regular cadence that kinda just

00:46:14.660 --> 00:46:16.740
<v Speaker 0>just start up. Is that worth doing, or

00:46:16.740 --> 00:46:18.180
<v Speaker 0>do you think we just wait ten seconds

00:46:18.180 --> 00:46:18.740
<v Speaker 0>there?

00:46:19.460 --> 00:46:21.060
<v Speaker 1>You can just hit search again, and there

00:46:21.060 --> 00:46:23.244
<v Speaker 1>might already be Yeah. There we go. So

00:46:23.244 --> 00:46:24.925
<v Speaker 1>now you could do the compare,

00:46:25.565 --> 00:46:27.885
<v Speaker 1>and we could figure out exactly why this

00:46:27.885 --> 00:46:29.405
<v Speaker 1>jump happened. Right?

00:46:31.165 --> 00:46:32.365
<v Speaker 1>Yeah. And

00:46:33.085 --> 00:46:35.005
<v Speaker 1>we can see Badger created a bunch of

00:46:35.005 --> 00:46:35.645
<v Speaker 1>skip lists.

00:46:37.850 --> 00:46:39.290
<v Speaker 0>Yep. New skip list.

00:46:46.410 --> 00:46:48.090
<v Speaker 0>Well, I'm not sure why that there.

00:46:49.050 --> 00:46:51.770
<v Speaker 1>This so you're scoping essentially

00:46:52.065 --> 00:46:55.185
<v Speaker 1>the there this is essentially interacting with the

00:46:55.185 --> 00:46:56.625
<v Speaker 1>with the flame graph.

00:46:56.785 --> 00:46:59.185
<v Speaker 1>And once you found something that you're interested

00:46:59.185 --> 00:47:01.265
<v Speaker 1>in, you can see on the left hand

00:47:01.265 --> 00:47:03.105
<v Speaker 1>side, for example, there are a couple of

00:47:03.105 --> 00:47:04.704
<v Speaker 1>spans that are too small to read.

00:47:05.360 --> 00:47:07.120
<v Speaker 1>You may you you can

00:47:07.360 --> 00:47:09.440
<v Speaker 1>click on one of those, and it'll expand,

00:47:09.440 --> 00:47:11.200
<v Speaker 1>and then you'll see Ah. All of the

00:47:11.200 --> 00:47:13.920
<v Speaker 1>rest of of its child nodes.

00:47:14.480 --> 00:47:15.200
<v Speaker 0>Okay.

00:47:16.240 --> 00:47:18.560
<v Speaker 1>And, essentially, everything that's,

00:47:19.280 --> 00:47:22.245
<v Speaker 1>like, faded out is the part that we're

00:47:22.484 --> 00:47:24.805
<v Speaker 1>kind of zooming in on. Right? And from

00:47:24.805 --> 00:47:25.685
<v Speaker 1>there on,

00:47:25.845 --> 00:47:29.765
<v Speaker 1>the root essentially becomes whatever we clicked on.

00:47:31.285 --> 00:47:32.565
<v Speaker 0>Okay. Does

00:47:33.045 --> 00:47:33.605
<v Speaker 0>it

00:47:34.130 --> 00:47:36.930
<v Speaker 0>like, this is a a runtime dot do

00:47:36.930 --> 00:47:37.970
<v Speaker 0>in it function.

00:47:38.450 --> 00:47:39.090
<v Speaker 0>Like,

00:47:39.250 --> 00:47:40.530
<v Speaker 0>can I find out how many times this

00:47:40.530 --> 00:47:42.290
<v Speaker 0>was called? Like, if I had maybe a

00:47:42.290 --> 00:47:44.050
<v Speaker 0>recursive function that was going about wild in

00:47:44.050 --> 00:47:45.170
<v Speaker 0>my application, is Parca

00:47:45.730 --> 00:47:47.090
<v Speaker 0>would I be able to show that in

00:47:47.090 --> 00:47:48.290
<v Speaker 0>some way, or would it just be as

00:47:48.290 --> 00:47:49.815
<v Speaker 0>I would see it called lots on the

00:47:49.815 --> 00:47:51.335
<v Speaker 0>on this on the call graph?

00:47:51.575 --> 00:47:52.535
<v Speaker 1>Yeah. So

00:47:53.974 --> 00:47:56.535
<v Speaker 1>this depends a little bit on the

00:47:57.255 --> 00:48:00.455
<v Speaker 1>on the profiler itself. Typically, profilers have some

00:48:00.455 --> 00:48:01.175
<v Speaker 1>sort of

00:48:01.815 --> 00:48:03.255
<v Speaker 1>limit on the stack depth.

00:48:03.920 --> 00:48:05.280
<v Speaker 1>This tends to be

00:48:05.680 --> 00:48:06.640
<v Speaker 1>sixty four

00:48:07.120 --> 00:48:09.600
<v Speaker 1>sixty four frames, something like that.

00:48:11.200 --> 00:48:11.840
<v Speaker 1>So

00:48:12.320 --> 00:48:14.320
<v Speaker 1>that's that's how often you would see it

00:48:14.320 --> 00:48:16.160
<v Speaker 1>repeated, and then at some point, it would

00:48:16.160 --> 00:48:18.880
<v Speaker 1>stop if it's, like Okay. Endlessly recursive.

00:48:19.985 --> 00:48:20.625
<v Speaker 1>Yeah.

00:48:22.225 --> 00:48:24.945
<v Speaker 0>Okay. So I wanna make sure that

00:48:25.665 --> 00:48:27.985
<v Speaker 0>I understand this right. So we're using a

00:48:27.985 --> 00:48:30.785
<v Speaker 0>different profile because it's been scraped over HTTP.

00:48:31.105 --> 00:48:33.185
<v Speaker 0>We're looking at the memory and just bytes.

00:48:33.150 --> 00:48:34.670
<v Speaker 0>We can see the graph, which has shown

00:48:34.670 --> 00:48:36.349
<v Speaker 0>us how much memory was allocated to two

00:48:36.349 --> 00:48:37.790
<v Speaker 0>different points, which is great.

00:48:38.109 --> 00:48:40.349
<v Speaker 0>We have these red things, which I'm assuming

00:48:40.349 --> 00:48:43.470
<v Speaker 0>is telling me that these functions are consuming

00:48:43.470 --> 00:48:44.430
<v Speaker 0>memory

00:48:44.910 --> 00:48:46.030
<v Speaker 0>Yeah. On the stack.

00:48:46.349 --> 00:48:47.549
<v Speaker 1>Mhmm. Alright. Okay.

00:48:48.605 --> 00:48:50.045
<v Speaker 0>I mean, is there a size?

00:48:50.285 --> 00:48:51.484
<v Speaker 0>Like, I can see we have a figure

00:48:51.484 --> 00:48:53.005
<v Speaker 0>here. I know that we're using a 20

00:48:53.005 --> 00:48:55.565
<v Speaker 0>meg, but does it show me more specifically

00:48:55.805 --> 00:48:57.405
<v Speaker 0>which one of these functions is the the

00:48:57.405 --> 00:48:59.885
<v Speaker 0>bad actor here if that was, again, a

00:48:59.885 --> 00:49:02.390
<v Speaker 0>memory leak or something else? Yeah. So you

00:49:02.390 --> 00:49:04.390
<v Speaker 1>you always wanna look at the

00:49:06.150 --> 00:49:07.110
<v Speaker 1>deepest

00:49:07.110 --> 00:49:07.990
<v Speaker 1>span

00:49:08.150 --> 00:49:08.870
<v Speaker 1>that

00:49:09.110 --> 00:49:11.350
<v Speaker 1>doesn't have any children anymore.

00:49:11.430 --> 00:49:14.115
<v Speaker 1>So we can actually tell here that new

00:49:14.115 --> 00:49:16.755
<v Speaker 1>skip list is actually the thing that allocated

00:49:16.755 --> 00:49:20.835
<v Speaker 1>the memory here. So if we optimize new

00:49:20.835 --> 00:49:21.795
<v Speaker 1>skip list

00:49:21.955 --> 00:49:24.835
<v Speaker 1>in this case, we're intentionally preallocating memory, so

00:49:24.835 --> 00:49:26.755
<v Speaker 1>it's not actually a bad thing. But let's

00:49:26.755 --> 00:49:27.315
<v Speaker 1>say it was.

00:49:27.880 --> 00:49:30.520
<v Speaker 1>If we optimize new skip list to

00:49:30.920 --> 00:49:33.080
<v Speaker 1>if we if it was truly possible

00:49:33.160 --> 00:49:35.320
<v Speaker 1>to just not do this at all, we

00:49:35.320 --> 00:49:36.600
<v Speaker 1>would actually save

00:49:36.760 --> 00:49:37.640
<v Speaker 1>70%

00:49:37.640 --> 00:49:38.760
<v Speaker 1>of our memory

00:49:39.160 --> 00:49:42.715
<v Speaker 1>almost or 67667.81%

00:49:42.715 --> 00:49:44.795
<v Speaker 1>of our memory. Right? Okay.

00:49:45.835 --> 00:49:47.675
<v Speaker 1>So yeah. And

00:49:48.075 --> 00:49:49.035
<v Speaker 1>I think

00:49:49.275 --> 00:49:51.995
<v Speaker 1>maybe this is a bug, or we need

00:49:51.995 --> 00:49:53.355
<v Speaker 1>to update the version.

00:49:54.555 --> 00:49:55.035
<v Speaker 1>But

00:49:55.450 --> 00:49:58.330
<v Speaker 1>we see the cumulative and the difference number

00:49:58.330 --> 00:49:58.890
<v Speaker 1>here.

00:49:59.530 --> 00:50:01.530
<v Speaker 1>We know actually that this,

00:50:01.850 --> 00:50:03.930
<v Speaker 1>data that we're looking at is

00:50:04.090 --> 00:50:04.970
<v Speaker 1>bytes,

00:50:05.050 --> 00:50:06.170
<v Speaker 1>so it would,

00:50:06.970 --> 00:50:08.090
<v Speaker 1>it should be,

00:50:08.650 --> 00:50:11.505
<v Speaker 1>formatting this as, I I wanna say this

00:50:11.505 --> 00:50:14.464
<v Speaker 1>is, like, 87 megabytes or something, but maybe

00:50:14.464 --> 00:50:16.545
<v Speaker 1>I'm wrong. No. I think that's right based

00:50:16.545 --> 00:50:18.545
<v Speaker 0>on what we've seen here. 40 to a

00:50:18.545 --> 00:50:20.625
<v Speaker 0>20. So, yeah, you're pretty much spot on.

00:50:20.944 --> 00:50:22.385
<v Speaker 1>So, yeah, it it looks like in the

00:50:22.385 --> 00:50:24.224
<v Speaker 1>in the graph, it's working. Maybe we have

00:50:24.224 --> 00:50:25.265
<v Speaker 1>some bug in the

00:50:26.010 --> 00:50:28.170
<v Speaker 1>in the front end about the

00:50:28.650 --> 00:50:29.770
<v Speaker 1>hover state.

00:50:30.570 --> 00:50:31.290
<v Speaker 0>Okay.

00:50:32.170 --> 00:50:33.850
<v Speaker 0>Don't mean to put you on the spot,

00:50:34.010 --> 00:50:35.770
<v Speaker 0>but would you wanna give us, like, the

00:50:35.770 --> 00:50:38.090
<v Speaker 0>TLDR for these different profiles and and maybe

00:50:38.090 --> 00:50:39.370
<v Speaker 0>what they're useful for to people?

00:50:40.244 --> 00:50:42.005
<v Speaker 1>Yeah. Absolutely. So

00:50:43.525 --> 00:50:45.765
<v Speaker 1>these are these are very specific to Go.

00:50:45.765 --> 00:50:46.724
<v Speaker 1>Right? These are

00:50:47.125 --> 00:50:49.845
<v Speaker 1>profilers that are built directly into the Go

00:50:49.845 --> 00:50:52.964
<v Speaker 1>runtime. So these are definitely going to differ

00:50:52.964 --> 00:50:54.819
<v Speaker 1>for different languages,

00:50:54.819 --> 00:50:56.020
<v Speaker 1>different run times,

00:50:56.260 --> 00:50:59.140
<v Speaker 1>but I think they're still really useful and

00:50:59.140 --> 00:51:00.580
<v Speaker 1>interesting to know. So

00:51:01.140 --> 00:51:02.340
<v Speaker 1>block contention,

00:51:02.980 --> 00:51:06.420
<v Speaker 1>basically, hopefully, the descriptions of of each of

00:51:06.420 --> 00:51:08.295
<v Speaker 1>the profiles underneath

00:51:08.455 --> 00:51:10.375
<v Speaker 1>are descriptive enough. But,

00:51:11.175 --> 00:51:13.815
<v Speaker 1>essentially, whenever we have a

00:51:15.335 --> 00:51:16.135
<v Speaker 1>blocking

00:51:16.615 --> 00:51:17.494
<v Speaker 1>primitive

00:51:17.494 --> 00:51:18.695
<v Speaker 1>being called,

00:51:19.255 --> 00:51:22.630
<v Speaker 1>that's when we record that stack trace that

00:51:22.630 --> 00:51:23.590
<v Speaker 1>we understand

00:51:23.590 --> 00:51:26.230
<v Speaker 1>where does our where in in what paths

00:51:26.230 --> 00:51:27.350
<v Speaker 1>of our program

00:51:27.750 --> 00:51:30.869
<v Speaker 1>is our program being stopped and can can

00:51:30.869 --> 00:51:33.430
<v Speaker 1>no longer do something. And in the Go

00:51:33.510 --> 00:51:35.750
<v Speaker 1>case, this is actually particularly

00:51:35.750 --> 00:51:37.750
<v Speaker 1>interesting because the Go runtime

00:51:38.015 --> 00:51:39.135
<v Speaker 1>tries to

00:51:39.455 --> 00:51:40.255
<v Speaker 1>move

00:51:40.255 --> 00:51:42.335
<v Speaker 1>Go run Go routines around

00:51:42.415 --> 00:51:43.135
<v Speaker 1>to

00:51:43.935 --> 00:51:44.735
<v Speaker 1>prevent

00:51:45.615 --> 00:51:47.935
<v Speaker 1>Go routines from actually or threads from actually

00:51:47.935 --> 00:51:48.735
<v Speaker 1>blocking.

00:51:49.055 --> 00:51:51.215
<v Speaker 1>So this is a really useful one to

00:51:51.215 --> 00:51:53.135
<v Speaker 1>know if for what for some reason,

00:51:54.860 --> 00:51:57.740
<v Speaker 1>go routines keep being scheduled onto different threads

00:51:57.740 --> 00:51:58.860
<v Speaker 1>all of the time,

00:51:59.900 --> 00:52:02.060
<v Speaker 1>which would create a performance problem.

00:52:03.340 --> 00:52:05.900
<v Speaker 1>Go routines being created, definitely

00:52:06.815 --> 00:52:07.695
<v Speaker 1>a very

00:52:08.095 --> 00:52:10.894
<v Speaker 1>easy mistake to make. And, certainly, in the

00:52:10.894 --> 00:52:12.575
<v Speaker 1>Prometheus project, we've

00:52:13.135 --> 00:52:14.015
<v Speaker 1>we've,

00:52:14.494 --> 00:52:17.695
<v Speaker 1>like, fallen into that trap many times where

00:52:17.855 --> 00:52:20.095
<v Speaker 1>we leak Go routines. We just keep creating

00:52:20.095 --> 00:52:21.135
<v Speaker 1>them. They never end.

00:52:21.640 --> 00:52:23.640
<v Speaker 1>And a go routine means

00:52:24.040 --> 00:52:26.280
<v Speaker 1>we create a new stack every time,

00:52:26.600 --> 00:52:28.680
<v Speaker 1>which ends up costing memory,

00:52:29.080 --> 00:52:31.800
<v Speaker 1>and then we'll we'll we'll eventually see it

00:52:31.800 --> 00:52:34.200
<v Speaker 1>in both our go routine profile as well

00:52:34.200 --> 00:52:36.520
<v Speaker 1>as our memory

00:52:37.005 --> 00:52:40.444
<v Speaker 1>in use bytes profile that something is using

00:52:40.444 --> 00:52:41.964
<v Speaker 1>a bunch of memory and ends up

00:52:42.765 --> 00:52:45.164
<v Speaker 1>could end up being the go routines being

00:52:45.164 --> 00:52:45.805
<v Speaker 1>created.

00:52:48.125 --> 00:52:51.050
<v Speaker 1>The next one is memory allocations.

00:52:51.210 --> 00:52:53.290
<v Speaker 1>So we need to differentiate here. The one

00:52:53.290 --> 00:52:55.130
<v Speaker 1>that we were looking at previously was the

00:52:55.130 --> 00:52:58.170
<v Speaker 1>heap size. So how much memory

00:52:58.490 --> 00:52:59.450
<v Speaker 1>is currently

00:53:01.290 --> 00:53:03.530
<v Speaker 1>in use. Right? Like, how much when we

00:53:03.530 --> 00:53:06.305
<v Speaker 1>look at top or something, how much of

00:53:06.305 --> 00:53:06.944
<v Speaker 1>that

00:53:07.425 --> 00:53:09.505
<v Speaker 1>how much memory are we using currently?

00:53:09.665 --> 00:53:10.944
<v Speaker 1>And then allocations

00:53:10.944 --> 00:53:11.585
<v Speaker 1>are

00:53:11.905 --> 00:53:14.944
<v Speaker 1>how much l memory has been allocated

00:53:14.944 --> 00:53:15.984
<v Speaker 1>over the entire

00:53:16.520 --> 00:53:18.440
<v Speaker 1>lifetime of our process.

00:53:19.000 --> 00:53:21.480
<v Speaker 1>And, again, this is a really useful thing

00:53:21.480 --> 00:53:22.360
<v Speaker 1>to understand

00:53:22.520 --> 00:53:23.720
<v Speaker 1>because allocations

00:53:23.720 --> 00:53:25.480
<v Speaker 1>tend to be where we spend a lot

00:53:25.480 --> 00:53:26.920
<v Speaker 1>of our CPU time.

00:53:27.800 --> 00:53:30.280
<v Speaker 1>I I it's definitely a generalization,

00:53:30.440 --> 00:53:32.815
<v Speaker 1>but a lot a lot a lot of

00:53:32.815 --> 00:53:33.455
<v Speaker 1>the

00:53:34.015 --> 00:53:34.815
<v Speaker 1>optimizations

00:53:34.815 --> 00:53:35.855
<v Speaker 1>that we see

00:53:36.335 --> 00:53:37.935
<v Speaker 1>are simply preallocating

00:53:37.935 --> 00:53:39.855
<v Speaker 1>some memory instead of

00:53:40.255 --> 00:53:42.575
<v Speaker 1>allocating them in small bytes,

00:53:45.295 --> 00:53:46.415
<v Speaker 1>like, one after another.

00:53:48.310 --> 00:53:50.630
<v Speaker 1>Then memory and use, we kind of looked

00:53:50.630 --> 00:53:52.390
<v Speaker 1>at already, and I I talked about just

00:53:52.390 --> 00:53:54.950
<v Speaker 1>now as well. Yep. Mutex contention is definitely

00:53:54.950 --> 00:53:56.470
<v Speaker 1>an interesting one as well.

00:53:58.550 --> 00:54:01.015
<v Speaker 1>In in case it's not well known, I

00:54:01.015 --> 00:54:03.815
<v Speaker 1>think, like, outside of the go go community,

00:54:04.055 --> 00:54:06.455
<v Speaker 1>maybe c plus plus engineers understand

00:54:06.455 --> 00:54:08.295
<v Speaker 1>this, but, like, single threaded

00:54:09.735 --> 00:54:11.495
<v Speaker 1>environments like Node. Js

00:54:11.895 --> 00:54:14.375
<v Speaker 1>or often in Ruby, these things aren't used

00:54:14.375 --> 00:54:16.130
<v Speaker 1>either, maybe in Python.

00:54:16.370 --> 00:54:16.930
<v Speaker 1>But

00:54:17.410 --> 00:54:20.370
<v Speaker 1>mutexes are essentially a synchronization primitive

00:54:20.370 --> 00:54:23.330
<v Speaker 1>where we can say someone has the exclusive

00:54:23.330 --> 00:54:25.730
<v Speaker 1>right to some piece of memory.

00:54:27.250 --> 00:54:27.730
<v Speaker 1>And

00:54:28.085 --> 00:54:30.805
<v Speaker 1>this is great in terms of writing safe

00:54:30.805 --> 00:54:31.445
<v Speaker 1>code,

00:54:31.605 --> 00:54:33.605
<v Speaker 1>but it can also lead to con contention

00:54:33.605 --> 00:54:34.885
<v Speaker 1>when multiple

00:54:35.204 --> 00:54:37.365
<v Speaker 1>threads want to or go routines in the

00:54:37.365 --> 00:54:39.285
<v Speaker 1>go case want to write to the same

00:54:39.285 --> 00:54:39.845
<v Speaker 1>thing,

00:54:40.085 --> 00:54:42.085
<v Speaker 1>and that means that they're blocking each other

00:54:42.789 --> 00:54:45.430
<v Speaker 1>and, you know, creating latency potentially in the

00:54:45.430 --> 00:54:46.630
<v Speaker 1>system or worse,

00:54:47.029 --> 00:54:49.589
<v Speaker 1>maybe even deadlocks if if it never gets

00:54:49.750 --> 00:54:51.670
<v Speaker 1>freed, the the mutex.

00:54:51.829 --> 00:54:53.750
<v Speaker 1>And then the last one that we see

00:54:53.750 --> 00:54:55.910
<v Speaker 1>is CPU time, which is something that we

00:54:55.910 --> 00:54:58.475
<v Speaker 1>already looked at earlier. So, literally, where was

00:54:58.475 --> 00:55:00.715
<v Speaker 1>CPU time being spent in that process?

00:55:01.275 --> 00:55:03.355
<v Speaker 0>Awesome. Thank you for that. You are a

00:55:03.355 --> 00:55:04.555
<v Speaker 0>wealth of knowledge.

00:55:05.995 --> 00:55:08.955
<v Speaker 0>Alright. So, Matthew, in the comments, has double

00:55:08.955 --> 00:55:11.995
<v Speaker 0>checked the release for 07/01 and confirmed that

00:55:11.995 --> 00:55:14.910
<v Speaker 0>the accumulative value for formatting is indeed broken

00:55:14.910 --> 00:55:16.830
<v Speaker 0>and will open an issue. There you go.

00:55:16.830 --> 00:55:17.550
<v Speaker 1>Great.

00:55:18.670 --> 00:55:19.390
<v Speaker 0>Alright.

00:55:20.190 --> 00:55:21.390
<v Speaker 0>Is there anything else that you want to

00:55:21.390 --> 00:55:23.950
<v Speaker 0>look at before we deploy the microservice

00:55:23.950 --> 00:55:24.910
<v Speaker 0>demo thing?

00:55:25.310 --> 00:55:26.910
<v Speaker 0>Is there anything we've missed from the from

00:55:26.910 --> 00:55:28.990
<v Speaker 0>the UI or functionality from Parca that you

00:55:28.990 --> 00:55:31.245
<v Speaker 0>wanna show off before we do that?

00:55:32.204 --> 00:55:34.845
<v Speaker 1>I think the only thing that we we

00:55:34.845 --> 00:55:35.805
<v Speaker 1>kind of

00:55:36.845 --> 00:55:39.405
<v Speaker 1>glass just glanced over, but something that I

00:55:39.405 --> 00:55:41.565
<v Speaker 1>was quite excited about because this was something

00:55:41.565 --> 00:55:43.405
<v Speaker 1>that we didn't have in Prometheus for the

00:55:43.405 --> 00:55:44.285
<v Speaker 1>very longest time,

00:55:44.920 --> 00:55:47.000
<v Speaker 1>which is autocomplete of the

00:55:47.320 --> 00:55:49.320
<v Speaker 1>of the queries. So if you go back

00:55:49.320 --> 00:55:50.920
<v Speaker 1>and click on profiles again,

00:55:51.320 --> 00:55:53.720
<v Speaker 1>we can see that we have autocompletion for

00:55:53.720 --> 00:55:55.160
<v Speaker 1>the label names.

00:55:55.480 --> 00:55:56.360
<v Speaker 1>And, actually,

00:55:56.840 --> 00:55:58.920
<v Speaker 1>behind all of this is an entire

00:55:59.080 --> 00:55:59.960
<v Speaker 1>language

00:56:01.255 --> 00:56:02.615
<v Speaker 1>of writing these

00:56:02.935 --> 00:56:03.655
<v Speaker 1>queries,

00:56:03.815 --> 00:56:06.215
<v Speaker 1>and it's very similar to the Prometheus

00:56:07.335 --> 00:56:09.015
<v Speaker 1>Prometheus query language.

00:56:09.175 --> 00:56:11.095
<v Speaker 1>But we kind of have a real parser

00:56:11.095 --> 00:56:13.175
<v Speaker 1>in the front end here that takes the

00:56:13.175 --> 00:56:15.415
<v Speaker 1>query apart and does suggestions

00:56:15.920 --> 00:56:18.400
<v Speaker 1>based on where your where your cursor is.

00:56:18.480 --> 00:56:20.880
<v Speaker 1>Right now, it actually only the the suggestions

00:56:20.880 --> 00:56:22.160
<v Speaker 1>only work for

00:56:23.520 --> 00:56:25.440
<v Speaker 1>label names as well as,

00:56:26.320 --> 00:56:27.600
<v Speaker 1>like, constants,

00:56:27.600 --> 00:56:29.280
<v Speaker 1>and you you'll you'll see what I mean

00:56:29.280 --> 00:56:31.360
<v Speaker 1>by constants. If you, let's say,

00:56:32.375 --> 00:56:33.735
<v Speaker 1>choose instance

00:56:34.535 --> 00:56:35.495
<v Speaker 1>and then

00:56:35.815 --> 00:56:38.775
<v Speaker 1>equals or what whatever, really, and then you

00:56:38.775 --> 00:56:39.335
<v Speaker 1>do

00:56:41.015 --> 00:56:42.375
<v Speaker 1>two quotes

00:56:43.255 --> 00:56:44.375
<v Speaker 1>after the equals.

00:56:45.060 --> 00:56:47.060
<v Speaker 1>And, yeah, now you can see that that

00:56:47.060 --> 00:56:49.620
<v Speaker 1>comma was being suggested, right, because that is

00:56:49.620 --> 00:56:51.940
<v Speaker 1>logically the next thing that should follow after

00:56:51.940 --> 00:56:52.500
<v Speaker 1>this.

00:56:53.220 --> 00:56:55.380
<v Speaker 1>So, yeah, I I I was pretty excited

00:56:55.380 --> 00:56:56.900
<v Speaker 1>about this primarily

00:56:56.900 --> 00:56:58.900
<v Speaker 1>because I haven't written a parser,

00:56:59.220 --> 00:57:00.260
<v Speaker 1>since, like, my

00:57:00.924 --> 00:57:03.325
<v Speaker 1>compiler's class in university, I think.

00:57:04.285 --> 00:57:05.644
<v Speaker 1>But, yeah, I think this is pretty cool.

00:57:05.644 --> 00:57:07.484
<v Speaker 1>And, obviously, the next thing that we're building

00:57:07.484 --> 00:57:10.125
<v Speaker 1>here is that we have labeled value completion

00:57:10.125 --> 00:57:12.045
<v Speaker 1>as well. Yeah. That would be awesome. I

00:57:12.045 --> 00:57:14.365
<v Speaker 0>just appreciate the auto complete when we started

00:57:14.365 --> 00:57:15.805
<v Speaker 0>clicking onto the boxes and stuff.

00:57:16.520 --> 00:57:17.880
<v Speaker 0>Yeah. Been able to do that on the

00:57:17.880 --> 00:57:20.200
<v Speaker 0>values themselves would be a really, really nice

00:57:20.200 --> 00:57:21.320
<v Speaker 0>touch. Yep.

00:57:22.359 --> 00:57:24.040
<v Speaker 1>Yep. It's in progress.

00:57:24.520 --> 00:57:26.840
<v Speaker 1>A lot of the plumbing actually already exists.

00:57:27.320 --> 00:57:27.720
<v Speaker 0>Nice.

00:57:29.285 --> 00:57:30.085
<v Speaker 0>Alright.

00:57:30.085 --> 00:57:30.725
<v Speaker 0>So

00:57:31.285 --> 00:57:34.245
<v Speaker 0>I prepared a small kind of microservice thing

00:57:34.245 --> 00:57:37.365
<v Speaker 0>in Go that I I found on GitHub.

00:57:37.365 --> 00:57:39.925
<v Speaker 0>So this is by the user Harlow,

00:57:40.085 --> 00:57:42.965
<v Speaker 0>and it's just, like, for Go based microservices

00:57:44.210 --> 00:57:47.089
<v Speaker 0>that display some hotels on a map. They

00:57:47.089 --> 00:57:49.329
<v Speaker 0>use gRPC to do communication and I thought

00:57:49.329 --> 00:57:51.570
<v Speaker 0>it'd be good to see profiles across that.

00:57:52.049 --> 00:57:52.850
<v Speaker 0>Before

00:57:53.569 --> 00:57:55.730
<v Speaker 0>I knew anything about Parca, in fact, well,

00:57:55.730 --> 00:57:58.130
<v Speaker 0>I was even pronouncing Parca wrong, a whole

00:57:58.130 --> 00:58:00.135
<v Speaker 0>hour ago, is that

00:58:01.095 --> 00:58:03.575
<v Speaker 0>I didn't know the compare feature existed.

00:58:03.895 --> 00:58:05.655
<v Speaker 0>And now I'm kicking myself because we missed

00:58:05.655 --> 00:58:07.895
<v Speaker 0>an opportunity to actually use it as part

00:58:07.895 --> 00:58:10.215
<v Speaker 0>of the demo that I wanted to show.

00:58:10.935 --> 00:58:12.855
<v Speaker 0>But I'm thinking that we're trying to be

00:58:12.855 --> 00:58:13.415
<v Speaker 0>brave here,

00:58:16.000 --> 00:58:18.319
<v Speaker 0>which never works out well for me. So

00:58:18.319 --> 00:58:20.000
<v Speaker 0>the only thing I added to this project

00:58:20.000 --> 00:58:22.160
<v Speaker 0>was a whole bunch of YAML to do

00:58:22.160 --> 00:58:23.680
<v Speaker 0>the deployment here.

00:58:24.000 --> 00:58:25.440
<v Speaker 0>I really I

00:58:26.880 --> 00:58:29.359
<v Speaker 0>really naively used the latest tag,

00:58:30.695 --> 00:58:33.095
<v Speaker 0>but I'm hoping if I do an image

00:58:33.815 --> 00:58:34.615
<v Speaker 0>list,

00:58:36.455 --> 00:58:38.695
<v Speaker 0>is that we'll still have the content addressable

00:58:38.695 --> 00:58:40.375
<v Speaker 0>one that I pushed earlier.

00:58:41.895 --> 00:58:42.695
<v Speaker 0>So

00:58:44.775 --> 00:58:46.940
<v Speaker 0>I think I'm gonna update as Yowl to

00:58:46.940 --> 00:58:49.020
<v Speaker 0>deploy the old one before I added the

00:58:49.020 --> 00:58:50.619
<v Speaker 0>bug for you to find, to see if

00:58:50.619 --> 00:58:52.940
<v Speaker 0>that can help us do Yeah. Okay. So

00:58:52.940 --> 00:58:55.180
<v Speaker 0>I've injected like a little bit of CPU

00:58:55.180 --> 00:58:57.180
<v Speaker 0>intensive code into one of the services and

00:58:57.180 --> 00:58:58.700
<v Speaker 0>we wanna see if we can debug and

00:58:58.700 --> 00:58:59.339
<v Speaker 0>discover that.

00:59:00.535 --> 00:59:02.295
<v Speaker 0>So this is the fun bet though. The

00:59:02.295 --> 00:59:03.655
<v Speaker 0>first time I built this, I built up

00:59:03.655 --> 00:59:06.055
<v Speaker 0>the platform argument. So this should be the

00:59:06.055 --> 00:59:07.575
<v Speaker 0>one that won't work at all.

00:59:09.415 --> 00:59:11.255
<v Speaker 0>Then because it's an M1 Mac, it doesn't

00:59:11.255 --> 00:59:13.015
<v Speaker 0>deploy my Kubernetes cluster, which is not

00:59:13.560 --> 00:59:15.320
<v Speaker 0>Arm 64. So I think we need to

00:59:15.320 --> 00:59:16.600
<v Speaker 0>deploy this one.

00:59:18.840 --> 00:59:20.280
<v Speaker 0>How do I get

00:59:20.520 --> 00:59:23.080
<v Speaker 0>the actual shaft from that?

00:59:24.520 --> 00:59:26.680
<v Speaker 1>You might be able to check out the

00:59:26.680 --> 00:59:28.755
<v Speaker 1>registry where you pushed it to, and we

00:59:28.755 --> 00:59:29.875
<v Speaker 1>might be able to

00:59:30.755 --> 00:59:32.675
<v Speaker 1>find just enough of the SHA.

00:59:35.395 --> 00:59:36.994
<v Speaker 1>I think if you click on the tag,

00:59:36.994 --> 00:59:38.035
<v Speaker 1>there's a, like,

00:59:38.355 --> 00:59:40.115
<v Speaker 1>a history or something sometimes.

00:59:41.120 --> 00:59:42.720
<v Speaker 1>Maybe that maybe only

00:59:42.800 --> 00:59:44.000
<v Speaker 1>does that.

00:59:45.600 --> 00:59:47.920
<v Speaker 0>Alright. Well, let's there must be a way

00:59:47.920 --> 00:59:49.600
<v Speaker 0>to show this chat here.

00:59:50.160 --> 00:59:51.520
<v Speaker 0>Yeah. Digest. There we go.

00:59:53.495 --> 00:59:55.895
<v Speaker 0>And we'll make sure this matches up. So

00:59:55.895 --> 00:59:58.855
<v Speaker 0>the current one is 944,

00:59:58.855 --> 01:00:00.055
<v Speaker 0>which is this one,

01:00:01.335 --> 01:00:04.695
<v Speaker 0>which means this one here should be my,

01:00:04.695 --> 01:00:06.215
<v Speaker 0>before I broke the code.

01:00:08.900 --> 01:00:11.619
<v Speaker 0>So if I go into my Kubernetes folder,

01:00:13.380 --> 01:00:14.740
<v Speaker 0>replace latest

01:00:14.740 --> 01:00:15.300
<v Speaker 0>with

01:00:15.780 --> 01:00:16.900
<v Speaker 0>the SHA,

01:00:17.700 --> 01:00:19.220
<v Speaker 0>do you need the at symbol? I can't

01:00:19.220 --> 01:00:21.380
<v Speaker 0>remember. Yes. You need the the at symbol,

01:00:21.380 --> 01:00:24.075
<v Speaker 1>and you actually need to write sha two

01:00:24.075 --> 01:00:24.875
<v Speaker 1>sixty

01:00:24.875 --> 01:00:27.515
<v Speaker 1>five colon as well. Yeah. Okay.

01:00:27.835 --> 01:00:29.435
<v Speaker 0>And we wanna do that in the start

01:00:29.435 --> 01:00:30.555
<v Speaker 0>of the ML.

01:00:33.275 --> 01:00:33.755
<v Speaker 0>I guess.

01:00:39.170 --> 01:00:40.850
<v Speaker 0>I'm I'm I'm feeling how to say it

01:00:40.850 --> 01:00:43.490
<v Speaker 0>now. That dash I s search replace. Yeah.

01:00:43.490 --> 01:00:45.090
<v Speaker 0>It should just be filename. Right? Let's just

01:00:45.090 --> 01:00:46.530
<v Speaker 0>front end on its own.

01:00:50.130 --> 01:00:52.210
<v Speaker 1>I I think I think there might be

01:00:52.210 --> 01:00:53.250
<v Speaker 1>a thing where,

01:00:53.964 --> 01:00:56.365
<v Speaker 1>you know, maybe the at symbol or the

01:00:56.365 --> 01:00:58.525
<v Speaker 1>colon does something with the

01:01:00.605 --> 01:01:03.005
<v Speaker 1>with the regex. I I I'm never too

01:01:03.005 --> 01:01:03.805
<v Speaker 1>sure either.

01:01:05.885 --> 01:01:06.204
<v Speaker 0>No.

01:01:07.000 --> 01:01:09.000
<v Speaker 0>Not in the replacement side. If it was

01:01:09.000 --> 01:01:11.400
<v Speaker 0>on the matching side, definitely. I see. Yeah.

01:01:11.400 --> 01:01:13.080
<v Speaker 1>Yeah. You're right. But there, I think it's

01:01:13.080 --> 01:01:14.520
<v Speaker 0>alright. So this is just me

01:01:14.920 --> 01:01:16.200
<v Speaker 0>not remembering

01:01:16.840 --> 01:01:17.480
<v Speaker 0>that which

01:01:18.600 --> 01:01:19.400
<v Speaker 0>just put the failure.

01:01:21.925 --> 01:01:22.965
<v Speaker 0>So

01:01:24.165 --> 01:01:26.725
<v Speaker 0>I is unlined. Maybe we need the e.

01:01:27.445 --> 01:01:28.645
<v Speaker 0>There's the I e.

01:01:29.525 --> 01:01:30.565
<v Speaker 0>There we go.

01:01:32.085 --> 01:01:34.645
<v Speaker 0>Welcome to the said beginner's guide for idiot.

01:01:35.120 --> 01:01:36.800
<v Speaker 0>I'm the idiot. But now we have the

01:01:36.800 --> 01:01:38.320
<v Speaker 1>colon for the app.

01:01:41.360 --> 01:01:43.040
<v Speaker 0>Alright. I'm gonna open it if you ask.

01:01:43.040 --> 01:01:44.720
<v Speaker 0>Good. Okay. So

01:01:45.840 --> 01:01:47.600
<v Speaker 0>we just need that. Right?

01:01:47.920 --> 01:01:48.560
<v Speaker 0>Yeah.

01:01:49.040 --> 01:01:50.960
<v Speaker 0>Yeah. I don't need to

01:01:52.025 --> 01:01:52.665
<v Speaker 0>do

01:01:55.065 --> 01:01:56.105
<v Speaker 0>said failure.

01:01:56.105 --> 01:01:56.825
<v Speaker 0>Alright.

01:01:58.345 --> 01:01:59.465
<v Speaker 0>At this

01:01:59.865 --> 01:02:01.385
<v Speaker 0>profile service.

01:02:02.345 --> 01:02:02.985
<v Speaker 0>At this.

01:02:04.380 --> 01:02:05.980
<v Speaker 0>I'm waiting for someone in the chat to

01:02:05.980 --> 01:02:09.580
<v Speaker 0>tell me what my my mistake was. Sometimes

01:02:09.980 --> 01:02:11.500
<v Speaker 0>it's just quicker to do it

01:02:12.299 --> 01:02:13.740
<v Speaker 0>the boring way.

01:02:14.700 --> 01:02:17.339
<v Speaker 0>So let's do a cube control apply

01:02:17.420 --> 01:02:18.380
<v Speaker 0>star.

01:02:24.865 --> 01:02:25.585
<v Speaker 0>What?

01:02:27.905 --> 01:02:28.705
<v Speaker 0>Okay.

01:02:28.785 --> 01:02:29.505
<v Speaker 0>Dot.

01:02:31.585 --> 01:02:33.800
<v Speaker 0>There we go. No. I can't even remember

01:02:33.800 --> 01:02:34.840
<v Speaker 0>cube control.

01:02:35.080 --> 01:02:35.480
<v Speaker 0>Okay.

01:02:41.560 --> 01:02:42.840
<v Speaker 1>Maybe I got that wrong.

01:02:43.560 --> 01:02:45.865
<v Speaker 0>Well, it works for front end. Oh, no.

01:02:45.865 --> 01:02:47.305
<v Speaker 0>Because I alright.

01:02:47.305 --> 01:02:49.385
<v Speaker 0>See, I told you whenever anything goes wrong,

01:02:49.385 --> 01:02:51.945
<v Speaker 0>just blame me. Always me. I forgot the

01:02:51.945 --> 01:02:53.865
<v Speaker 0>five six on the other ones.

01:02:55.465 --> 01:02:56.025
<v Speaker 1>I see.

01:03:00.290 --> 01:03:01.090
<v Speaker 0>Alright.

01:03:01.570 --> 01:03:03.330
<v Speaker 0>I wish I had just deployed that straight

01:03:03.330 --> 01:03:04.530
<v Speaker 0>up now. But

01:03:04.850 --> 01:03:07.170
<v Speaker 0>if this works and we see the difference,

01:03:07.170 --> 01:03:08.930
<v Speaker 0>I'll be very excited

01:03:13.795 --> 01:03:14.755
<v Speaker 0>and apply.

01:03:16.595 --> 01:03:18.835
<v Speaker 0>Okay. That is going to work.

01:03:19.475 --> 01:03:21.235
<v Speaker 0>Yeah. We can already see them starting to

01:03:21.235 --> 01:03:23.315
<v Speaker 0>run. Yeah. Nice. Now because we have the

01:03:23.315 --> 01:03:25.155
<v Speaker 0>server and the agent already deployed,

01:03:26.200 --> 01:03:28.600
<v Speaker 0>if I do a port forward, we should

01:03:28.600 --> 01:03:29.480
<v Speaker 0>be able

01:03:30.120 --> 01:03:31.240
<v Speaker 0>to see

01:03:33.480 --> 01:03:35.000
<v Speaker 0>k. Port. There we go.

01:03:35.560 --> 01:03:37.240
<v Speaker 0>I'm not that the front end.

01:03:37.560 --> 01:03:38.600
<v Speaker 0>Well, I guess we probably

01:03:39.240 --> 01:03:40.760
<v Speaker 0>no. We don't need traffic yet. We can

01:03:40.760 --> 01:03:41.320
<v Speaker 0>just

01:03:44.494 --> 01:03:45.375
<v Speaker 0>Parca.

01:03:45.454 --> 01:03:47.055
<v Speaker 0>We could just go to here and we

01:03:47.055 --> 01:03:48.494
<v Speaker 0>should see data already.

01:03:49.694 --> 01:03:51.295
<v Speaker 0>Wonder if I need to shut down the

01:03:51.295 --> 01:03:52.175
<v Speaker 0>other one.

01:03:52.655 --> 01:03:53.615
<v Speaker 0>Cool.

01:03:53.855 --> 01:03:54.494
<v Speaker 1>Looks good.

01:03:55.670 --> 01:03:57.670
<v Speaker 0>So let's take a look at the default

01:03:57.670 --> 01:03:58.790
<v Speaker 0>namespace.

01:04:02.870 --> 01:04:04.550
<v Speaker 0>I got a new keyboard and I can't

01:04:04.550 --> 01:04:05.110
<v Speaker 0>type.

01:04:07.110 --> 01:04:07.430
<v Speaker 0>Cool.

01:04:10.285 --> 01:04:13.085
<v Speaker 0>Is that right? Yeah. Yeah. That looks right.

01:04:13.325 --> 01:04:15.165
<v Speaker 0>Yeah. So we can see Jager in front

01:04:15.165 --> 01:04:17.245
<v Speaker 0>end. I expected to see a few more

01:04:18.045 --> 01:04:18.605
<v Speaker 0>containers.

01:04:24.579 --> 01:04:26.260
<v Speaker 0>Now it could just be that this

01:04:26.660 --> 01:04:28.260
<v Speaker 0>oh, no. I'm on the wrong cluster.

01:04:32.339 --> 01:04:33.220
<v Speaker 0>There we go.

01:04:33.619 --> 01:04:35.300
<v Speaker 0>There we go. So it could just be

01:04:35.300 --> 01:04:37.220
<v Speaker 0>the sampling hasn't kicked in for the the

01:04:37.220 --> 01:04:38.819
<v Speaker 0>other ones which started a little bit late.

01:04:38.865 --> 01:04:40.945
<v Speaker 0>So if we hit search again, we get

01:04:40.945 --> 01:04:41.825
<v Speaker 0>more colors.

01:04:42.225 --> 01:04:43.105
<v Speaker 1>Yeah. Cool.

01:04:43.425 --> 01:04:45.425
<v Speaker 0>This application is

01:04:46.545 --> 01:04:47.905
<v Speaker 0>nice and simple.

01:04:48.305 --> 01:04:50.545
<v Speaker 0>We could browse to local host on port

01:04:50.545 --> 01:04:51.185
<v Speaker 0>8080.

01:04:52.440 --> 01:04:55.320
<v Speaker 1>It could also be so if if there's

01:04:55.320 --> 01:04:57.240
<v Speaker 1>absolutely no CPU

01:04:57.240 --> 01:05:00.120
<v Speaker 1>time being spent, obviously, there's nothing to measure.

01:05:00.440 --> 01:05:01.880
<v Speaker 1>So that could be

01:05:02.840 --> 01:05:05.000
<v Speaker 1>what we're seeing as well. It depends on

01:05:05.345 --> 01:05:06.865
<v Speaker 1>what these services do.

01:05:07.744 --> 01:05:08.785
<v Speaker 0>Ah, okay.

01:05:09.025 --> 01:05:11.025
<v Speaker 0>Well, every time I zoom around, this is

01:05:11.025 --> 01:05:12.785
<v Speaker 0>the the back end of this application is

01:05:12.785 --> 01:05:15.105
<v Speaker 0>talking to each other and checking and searching

01:05:15.105 --> 01:05:16.944
<v Speaker 0>for new spaces. When I click on these,

01:05:16.944 --> 01:05:18.545
<v Speaker 0>that's the profile service.

01:05:18.944 --> 01:05:19.904
<v Speaker 0>So we should see

01:05:21.240 --> 01:05:22.840
<v Speaker 0>in a little bit of time that we're

01:05:22.840 --> 01:05:23.960
<v Speaker 0>gonna get more information.

01:05:24.520 --> 01:05:25.320
<v Speaker 0>However,

01:05:25.320 --> 01:05:26.920
<v Speaker 0>I think if we just go straight ahead

01:05:26.920 --> 01:05:29.240
<v Speaker 0>and deploy the broken one now and interact

01:05:29.240 --> 01:05:31.080
<v Speaker 0>with it, we should see a,

01:05:31.320 --> 01:05:32.040
<v Speaker 0>hopefully,

01:05:32.280 --> 01:05:34.120
<v Speaker 0>spike in the CPU.

01:05:35.165 --> 01:05:36.285
<v Speaker 0>Yep. So

01:05:38.845 --> 01:05:41.885
<v Speaker 0>try and keep those two running just now

01:05:42.365 --> 01:05:43.885
<v Speaker 0>and go back to here

01:05:45.965 --> 01:05:46.765
<v Speaker 0>and undo.

01:06:01.424 --> 01:06:02.145
<v Speaker 0>Cool.

01:06:07.744 --> 01:06:09.585
<v Speaker 0>I dash f go.

01:06:15.120 --> 01:06:16.800
<v Speaker 1>Is that the wrong cluster again?

01:06:17.760 --> 01:06:18.480
<v Speaker 1>Yeah.

01:06:21.600 --> 01:06:23.280
<v Speaker 0>I swear I know what I'm doing. I

01:06:23.280 --> 01:06:23.600
<v Speaker 0>promise.

01:06:26.454 --> 01:06:28.935
<v Speaker 0>Alright. So we got some new containers coming

01:06:28.935 --> 01:06:31.494
<v Speaker 0>up. We'll let that switch over. We'll let

01:06:31.494 --> 01:06:34.055
<v Speaker 0>Parca do it saying, get some profiles and

01:06:34.055 --> 01:06:35.895
<v Speaker 0>and then we'll see if you can just

01:06:35.895 --> 01:06:37.895
<v Speaker 0>guide me through the process of debugging which

01:06:37.895 --> 01:06:38.375
<v Speaker 0>service

01:06:39.480 --> 01:06:41.720
<v Speaker 0>has given us some problems. And hopefully,

01:06:41.880 --> 01:06:43.080
<v Speaker 0>hopefully it works.

01:06:44.520 --> 01:06:45.160
<v Speaker 0>Cool.

01:06:45.720 --> 01:06:47.880
<v Speaker 0>Alright. So we got a comment from Mattias.

01:06:47.880 --> 01:06:49.320
<v Speaker 0>This is where the fun begins.

01:06:49.720 --> 01:06:52.680
<v Speaker 0>I certainly wasn't finding my skills are particularly

01:06:52.680 --> 01:06:55.035
<v Speaker 0>fun, but hopefully, this works.

01:06:55.435 --> 01:06:57.595
<v Speaker 0>Moz is telling me to use the hash

01:06:57.595 --> 01:06:59.435
<v Speaker 0>symbol to escape the at char.

01:07:00.075 --> 01:07:01.515
<v Speaker 0>I still don't think we have to skip

01:07:01.515 --> 01:07:02.795
<v Speaker 0>the at char because it was in a

01:07:02.795 --> 01:07:05.195
<v Speaker 0>replace state, but then I've just shown them

01:07:05.195 --> 01:07:06.955
<v Speaker 0>my set skills are not exactly up to

01:07:06.955 --> 01:07:08.860
<v Speaker 0>date. So we'll see.

01:07:09.260 --> 01:07:10.460
<v Speaker 1>It might be that

01:07:10.940 --> 01:07:11.740
<v Speaker 1>at

01:07:11.740 --> 01:07:12.780
<v Speaker 1>can be used

01:07:13.500 --> 01:07:16.140
<v Speaker 1>for selecting a grouping or something

01:07:16.940 --> 01:07:18.060
<v Speaker 1>of the first

01:07:22.224 --> 01:07:23.984
<v Speaker 0>Yeah. I mean, you could be right. I

01:07:23.984 --> 01:07:24.865
<v Speaker 0>can't remember.

01:07:25.185 --> 01:07:26.704
<v Speaker 1>There there are a lot of different I

01:07:26.704 --> 01:07:28.945
<v Speaker 1>know dollar sign allows me to pull things

01:07:28.945 --> 01:07:30.625
<v Speaker 0>from the match, but,

01:07:31.105 --> 01:07:33.105
<v Speaker 0>yeah, maybe you you could be right.

01:07:35.025 --> 01:07:35.425
<v Speaker 0>Okay.

01:07:36.960 --> 01:07:37.760
<v Speaker 0>Let's

01:07:38.400 --> 01:07:39.520
<v Speaker 0>click search.

01:07:40.320 --> 01:07:43.120
<v Speaker 0>Okay, we're getting more data. So let's,

01:07:44.000 --> 01:07:46.320
<v Speaker 0>I need to report forward again.

01:07:46.960 --> 01:07:48.720
<v Speaker 0>So this is the new version.

01:07:49.725 --> 01:07:51.885
<v Speaker 0>If I zoom in a few times, click

01:07:51.885 --> 01:07:53.005
<v Speaker 0>a few buttons,

01:07:57.165 --> 01:07:57.965
<v Speaker 0>and

01:07:58.845 --> 01:08:00.925
<v Speaker 0>we I guess we just cannot oh, there

01:08:00.925 --> 01:08:01.565
<v Speaker 0>we go.

01:08:02.605 --> 01:08:04.285
<v Speaker 0>That may be related potentially.

01:08:05.730 --> 01:08:07.890
<v Speaker 0>I think we should get a refresh every

01:08:07.890 --> 01:08:10.130
<v Speaker 0>ten seconds button. Is that is that a

01:08:10.130 --> 01:08:11.170
<v Speaker 0>good feature request?

01:08:11.490 --> 01:08:13.490
<v Speaker 1>Yeah. Actually, it's already in progress.

01:08:15.170 --> 01:08:15.970
<v Speaker 1>Nice.

01:08:16.850 --> 01:08:17.330
<v Speaker 0>Okay.

01:08:18.185 --> 01:08:18.905
<v Speaker 0>So

01:08:19.465 --> 01:08:22.185
<v Speaker 0>we potentially have enough information to debug here.

01:08:22.185 --> 01:08:23.705
<v Speaker 0>Do you wanna kinda guide us what you

01:08:23.705 --> 01:08:25.225
<v Speaker 0>would do if you were actually trying to

01:08:25.225 --> 01:08:26.984
<v Speaker 0>work out what was wrong in this system?

01:08:27.305 --> 01:08:29.785
<v Speaker 1>So in in this case, I wanna say

01:08:29.785 --> 01:08:30.745
<v Speaker 1>we're probably

01:08:32.200 --> 01:08:34.200
<v Speaker 1>like, we see this spike that we didn't

01:08:34.200 --> 01:08:37.080
<v Speaker 1>see before. Right? And I I think I

01:08:37.080 --> 01:08:40.120
<v Speaker 1>saw that the profile container is what was

01:08:40.120 --> 01:08:43.159
<v Speaker 1>the contender here. Mhmm. So let's

01:08:43.560 --> 01:08:46.200
<v Speaker 1>filter down by that container. So if you

01:08:46.200 --> 01:08:47.080
<v Speaker 1>hit shift again,

01:08:49.295 --> 01:08:50.175
<v Speaker 1>you can

01:08:50.655 --> 01:08:54.495
<v Speaker 1>click that label again. Yep. So now, basically,

01:08:54.495 --> 01:08:55.295
<v Speaker 1>you can

01:08:55.615 --> 01:08:58.015
<v Speaker 1>do you can go to your compare view.

01:08:58.895 --> 01:09:00.814
<v Speaker 0>This is and I just wanna point this

01:09:00.814 --> 01:09:02.869
<v Speaker 0>out because if this is are these colors

01:09:02.869 --> 01:09:05.109
<v Speaker 0>to show different deployments of the same

01:09:05.510 --> 01:09:06.389
<v Speaker 0>container?

01:09:06.710 --> 01:09:09.670
<v Speaker 1>Yes. Exactly. Sweet. So I can actually already

01:09:09.670 --> 01:09:13.029
<v Speaker 0>see exactly when that's swapped over and then

01:09:13.029 --> 01:09:15.510
<v Speaker 0>the contention happened on the CPU. So that's

01:09:15.510 --> 01:09:16.149
<v Speaker 0>cool. Yeah.

01:09:16.765 --> 01:09:17.484
<v Speaker 1>And

01:09:17.725 --> 01:09:18.365
<v Speaker 1>if

01:09:18.765 --> 01:09:20.125
<v Speaker 1>if there was a

01:09:20.765 --> 01:09:23.725
<v Speaker 1>particular label that also kind of

01:09:24.445 --> 01:09:25.325
<v Speaker 1>distinguished

01:09:25.405 --> 01:09:27.005
<v Speaker 1>the two deployments,

01:09:27.005 --> 01:09:28.925
<v Speaker 1>in this case, we don't really have that.

01:09:28.925 --> 01:09:29.885
<v Speaker 1>We have the

01:09:30.229 --> 01:09:33.350
<v Speaker 1>container ID, which we could, you know, abuse

01:09:33.350 --> 01:09:35.909
<v Speaker 1>for the same purpose. But, ideally, we would

01:09:35.909 --> 01:09:36.949
<v Speaker 1>have a

01:09:37.350 --> 01:09:38.390
<v Speaker 1>or

01:09:38.390 --> 01:09:41.029
<v Speaker 1>something that is means something to us as

01:09:41.029 --> 01:09:41.909
<v Speaker 1>the developer.

01:09:42.310 --> 01:09:43.029
<v Speaker 1>Then we could,

01:09:44.055 --> 01:09:46.694
<v Speaker 1>once we go into our compare view, we

01:09:46.694 --> 01:09:50.854
<v Speaker 1>could actually filter down to to seeing only

01:09:50.854 --> 01:09:51.494
<v Speaker 1>those,

01:09:52.295 --> 01:09:53.654
<v Speaker 1>points of data.

01:09:54.215 --> 01:09:55.015
<v Speaker 1>But in this case,

01:09:55.960 --> 01:09:58.200
<v Speaker 1>the the the just selecting a point in

01:09:58.200 --> 01:09:59.560
<v Speaker 1>time will do the same

01:09:59.960 --> 01:10:01.400
<v Speaker 1>will have the same effect.

01:10:01.720 --> 01:10:04.360
<v Speaker 1>So what you can do is you can,

01:10:04.680 --> 01:10:06.520
<v Speaker 1>on the left hand side,

01:10:07.160 --> 01:10:09.320
<v Speaker 1>select one of the profiles,

01:10:09.955 --> 01:10:12.114
<v Speaker 1>maybe the one that has a couple of

01:10:13.395 --> 01:10:14.515
<v Speaker 0>I'm just I'm just trying to see how

01:10:14.515 --> 01:10:15.954
<v Speaker 0>back I can get the graph.

01:10:18.195 --> 01:10:18.835
<v Speaker 0>Okay.

01:10:20.435 --> 01:10:22.355
<v Speaker 0>Give that ten seconds or something. Sorry. What

01:10:22.355 --> 01:10:23.475
<v Speaker 0>would you like me to click on there?

01:10:24.100 --> 01:10:25.940
<v Speaker 1>On the on the left hand side, let's

01:10:25.940 --> 01:10:28.180
<v Speaker 1>click where wherever that what that spike was

01:10:28.180 --> 01:10:29.700
<v Speaker 1>in the on the blue line,

01:10:30.580 --> 01:10:32.580
<v Speaker 1>and then we can compare that to a

01:10:32.580 --> 01:10:35.140
<v Speaker 1>spike on the the right hand side.

01:10:36.260 --> 01:10:37.940
<v Speaker 0>Alright. We'll use what we have just now.

01:10:42.114 --> 01:10:43.235
<v Speaker 1>Interesting.

01:10:44.114 --> 01:10:46.675
<v Speaker 1>Okay. So in this case, we're actually seeing

01:10:46.675 --> 01:10:47.715
<v Speaker 1>something interesting.

01:10:48.355 --> 01:10:50.435
<v Speaker 1>We can pause here for a second. We're

01:10:50.435 --> 01:10:52.915
<v Speaker 1>seeing a bunch of memory addresses. Right? And

01:10:53.620 --> 01:10:56.739
<v Speaker 1>what we've just caught here is that Parca

01:10:56.739 --> 01:10:58.739
<v Speaker 1>hasn't actually been able to keep up with

01:10:58.739 --> 01:11:00.340
<v Speaker 1>all of the new data that we've been

01:11:00.340 --> 01:11:01.380
<v Speaker 1>sending to it,

01:11:02.100 --> 01:11:04.820
<v Speaker 1>and it does a process called symbolization.

01:11:04.900 --> 01:11:05.220
<v Speaker 1>And

01:11:06.784 --> 01:11:09.344
<v Speaker 1>one one of the employees at Polar Signals

01:11:09.344 --> 01:11:11.425
<v Speaker 1>came out. He just wrote a fantastic

01:11:12.065 --> 01:11:14.304
<v Speaker 1>blog post about what's happening

01:11:15.264 --> 01:11:16.544
<v Speaker 1>deep down

01:11:16.545 --> 01:11:18.145
<v Speaker 1>in in in this process.

01:11:18.880 --> 01:11:21.120
<v Speaker 1>But, essentially, the way that you can think

01:11:21.120 --> 01:11:21.679
<v Speaker 1>of

01:11:22.000 --> 01:11:24.880
<v Speaker 1>symbolization on a very high level is all

01:11:24.880 --> 01:11:27.040
<v Speaker 1>of these memory addresses is what we actually

01:11:27.040 --> 01:11:28.720
<v Speaker 1>captured from eBPF.

01:11:28.720 --> 01:11:29.280
<v Speaker 1>Right?

01:11:29.600 --> 01:11:30.880
<v Speaker 1>So eBPF

01:11:30.880 --> 01:11:31.760
<v Speaker 1>or the kernel

01:11:32.405 --> 01:11:34.965
<v Speaker 1>really only sees a stack being built.

01:11:35.445 --> 01:11:38.485
<v Speaker 1>And with eBPF, we're reading that entire stack.

01:11:38.645 --> 01:11:41.765
<v Speaker 1>But we're from from that kind of perspective,

01:11:41.765 --> 01:11:43.925
<v Speaker 1>we're not actually reading the function names or

01:11:43.925 --> 01:11:46.245
<v Speaker 1>something. We're only reading the offsets

01:11:47.360 --> 01:11:50.239
<v Speaker 1>of that code in our binary, and that's

01:11:50.239 --> 01:11:52.800
<v Speaker 1>basically what we're looking at here. And so,

01:11:52.800 --> 01:11:54.639
<v Speaker 1>hopefully, once we refresh,

01:11:56.000 --> 01:11:57.919
<v Speaker 1>Parca has had enough time

01:11:58.239 --> 01:11:58.960
<v Speaker 1>to

01:11:59.175 --> 01:12:01.735
<v Speaker 1>to get to to these memory addresses that

01:12:01.735 --> 01:12:04.374
<v Speaker 1>have not been symbolized yet and

01:12:05.494 --> 01:12:08.534
<v Speaker 1>can put some meaningful names for us humans

01:12:08.534 --> 01:12:09.574
<v Speaker 1>behind that.

01:12:10.215 --> 01:12:12.775
<v Speaker 1>Okay. Looks like something's wrong. I I I

01:12:12.775 --> 01:12:15.579
<v Speaker 1>can't can't say yet what. Maybe we can

01:12:16.219 --> 01:12:17.579
<v Speaker 1>jump over to

01:12:17.980 --> 01:12:19.659
<v Speaker 1>not doing the comparison,

01:12:20.460 --> 01:12:21.980
<v Speaker 1>and we can see if we can find

01:12:21.980 --> 01:12:23.099
<v Speaker 1>any of the

01:12:25.660 --> 01:12:27.820
<v Speaker 1>if we can find any any

01:12:28.380 --> 01:12:29.900
<v Speaker 1>symbols

01:12:29.295 --> 01:12:30.974
<v Speaker 1>for the new container.

01:12:31.775 --> 01:12:32.735
<v Speaker 0>Okay.

01:12:32.735 --> 01:12:34.815
<v Speaker 0>So if I just do this

01:12:39.295 --> 01:12:40.975
<v Speaker 1>That's just the Parca one, I think. Quite

01:12:40.975 --> 01:12:44.895
<v Speaker 0>hard. Yeah. You you you probably wanna

01:12:43.980 --> 01:12:45.340
<v Speaker 1>filter it down to

01:12:45.580 --> 01:12:47.260
<v Speaker 0>Name. The default namespace.

01:13:00.195 --> 01:13:02.835
<v Speaker 1>Yeah. Looks like looks like something about symbolization

01:13:02.835 --> 01:13:04.835
<v Speaker 1>is wrong. Maybe we can check out the

01:13:04.835 --> 01:13:07.635
<v Speaker 1>the logs of the Parca server to figure

01:13:07.635 --> 01:13:10.675
<v Speaker 1>out what's going on. Yeah. Some things appear

01:13:10.675 --> 01:13:13.070
<v Speaker 1>to be working. We could see that the

01:13:13.070 --> 01:13:15.149
<v Speaker 1>kernel space was actually correctly

01:13:15.949 --> 01:13:16.829
<v Speaker 1>symbolized.

01:13:17.630 --> 01:13:19.150
<v Speaker 1>If you I scroll down to here. We

01:13:19.150 --> 01:13:21.309
<v Speaker 0>can Yeah. We can see this is actually

01:13:21.309 --> 01:13:24.190
<v Speaker 1>something that also is incredibly cool about using

01:13:24.190 --> 01:13:26.925
<v Speaker 1>eBPF for this. If we're using a user

01:13:26.925 --> 01:13:29.085
<v Speaker 1>space profiler only like the ones that are

01:13:29.085 --> 01:13:30.604
<v Speaker 1>built into the Go runtime,

01:13:30.844 --> 01:13:32.605
<v Speaker 1>we would never be able to have this

01:13:32.605 --> 01:13:33.804
<v Speaker 1>depth of

01:13:34.125 --> 01:13:35.005
<v Speaker 1>detail.

01:13:35.725 --> 01:13:37.485
<v Speaker 1>Because from user space, we would never be

01:13:37.485 --> 01:13:39.085
<v Speaker 1>able to tell the kernel stack

01:13:39.670 --> 01:13:43.430
<v Speaker 1>that we we're currently in. But eBPF gives

01:13:43.430 --> 01:13:45.270
<v Speaker 1>us that kind of insight, which I think

01:13:45.270 --> 01:13:46.070
<v Speaker 1>is really,

01:13:47.030 --> 01:13:50.230
<v Speaker 1>really exciting because sometimes it is things that

01:13:50.230 --> 01:13:53.350
<v Speaker 1>are that far deep in in our

01:13:55.125 --> 01:13:57.525
<v Speaker 1>in our infrastructure that we need to understand

01:13:57.525 --> 01:14:00.005
<v Speaker 1>that there's some sort of maybe you know,

01:14:00.005 --> 01:14:01.925
<v Speaker 1>one of the most expensive things

01:14:02.325 --> 01:14:05.285
<v Speaker 1>on Linux machines is this context switch from

01:14:05.285 --> 01:14:07.685
<v Speaker 1>user space to kernel space or vice versa.

01:14:08.450 --> 01:14:10.770
<v Speaker 1>And if we can detect that this is

01:14:10.770 --> 01:14:11.890
<v Speaker 1>happening a lot,

01:14:12.210 --> 01:14:14.210
<v Speaker 1>then that's also incredibly

01:14:14.290 --> 01:14:16.370
<v Speaker 1>valuable performance information.

01:14:16.770 --> 01:14:17.330
<v Speaker 1>So

01:14:17.730 --> 01:14:19.570
<v Speaker 1>we were very excited when we got that

01:14:19.570 --> 01:14:22.130
<v Speaker 1>kind of detail of knowledge for the first

01:14:22.130 --> 01:14:22.290
<v Speaker 1>time.

01:14:24.015 --> 01:14:24.655
<v Speaker 0>Okay.

01:14:24.975 --> 01:14:27.934
<v Speaker 0>There's no logs on the Parca server.

01:14:27.935 --> 01:14:29.535
<v Speaker 0>Do we wanna look at the agent, or

01:14:29.535 --> 01:14:31.455
<v Speaker 0>do we wanna get Yeah. Yeah. We could

01:14:31.455 --> 01:14:33.375
<v Speaker 1>have a look at at the agent.

01:14:36.175 --> 01:14:37.215
<v Speaker 0>Is this gonna work?

01:14:39.880 --> 01:14:42.920
<v Speaker 1>I think it's the, like, canonical Kubernetes app

01:14:42.920 --> 01:14:46.360
<v Speaker 1>labeled, so it should be app.Kubernetes.io.

01:14:53.195 --> 01:14:55.434
<v Speaker 1>Okay. Alright. I'll just do a bot.

01:14:58.875 --> 01:14:59.594
<v Speaker 0>No.

01:14:59.915 --> 01:15:01.355
<v Speaker 0>Alright. I don't think we're gonna get anything

01:15:01.355 --> 01:15:01.915
<v Speaker 0>from there.

01:15:03.580 --> 01:15:05.100
<v Speaker 0>May as well do the last ones since

01:15:05.100 --> 01:15:06.619
<v Speaker 0>we've done two and three. Yep.

01:15:08.940 --> 01:15:12.699
<v Speaker 0>Okay. So the what happens here then is

01:15:13.340 --> 01:15:15.179
<v Speaker 0>when we do the search, we're trying to

01:15:15.179 --> 01:15:17.020
<v Speaker 0>look at this, is that what we get

01:15:17.020 --> 01:15:20.215
<v Speaker 0>by default is this object notation for something

01:15:20.215 --> 01:15:22.375
<v Speaker 0>that happened, and then Parca has to resolve

01:15:22.375 --> 01:15:24.535
<v Speaker 0>that to a name or a symbol, and

01:15:24.535 --> 01:15:26.454
<v Speaker 0>that process isn't happening here.

01:15:27.015 --> 01:15:29.335
<v Speaker 1>Yeah. So this is something that happens asynchronously

01:15:29.335 --> 01:15:30.055
<v Speaker 1>in the background.

01:15:30.560 --> 01:15:33.679
<v Speaker 1>When we when we upload the profiling data,

01:15:33.840 --> 01:15:36.320
<v Speaker 1>we actually all we're uploading are these memory

01:15:36.320 --> 01:15:37.040
<v Speaker 1>addresses,

01:15:37.200 --> 01:15:40.320
<v Speaker 1>and then Parca tries to symbolize them with

01:15:40.320 --> 01:15:42.000
<v Speaker 1>all of the new data that we're seeing.

01:15:42.895 --> 01:15:44.735
<v Speaker 1>And it seems like, for some reason, this

01:15:44.735 --> 01:15:47.535
<v Speaker 1>is stuck or it doesn't have the appropriate

01:15:47.535 --> 01:15:50.335
<v Speaker 1>information that it needs for this. Again, I

01:15:50.335 --> 01:15:53.135
<v Speaker 1>think this this format would probably we can

01:15:53.135 --> 01:15:55.855
<v Speaker 1>talk probably for six hours about how the

01:15:55.855 --> 01:15:57.215
<v Speaker 1>civilization stuff works.

01:15:58.330 --> 01:16:00.490
<v Speaker 1>Here here, this it appears to work. Not

01:16:00.490 --> 01:16:01.210
<v Speaker 1>sure why.

01:16:01.610 --> 01:16:04.170
<v Speaker 0>It could be the container image I've built.

01:16:04.170 --> 01:16:05.850
<v Speaker 0>This is the gigger one, and the the

01:16:05.850 --> 01:16:08.090
<v Speaker 0>symbols are definitely coming through okay.

01:16:08.730 --> 01:16:10.970
<v Speaker 0>But if we go to the container images

01:16:10.970 --> 01:16:12.895
<v Speaker 0>that I built, now is that is there

01:16:12.895 --> 01:16:14.094
<v Speaker 0>a way when I do a go build

01:16:14.094 --> 01:16:15.534
<v Speaker 0>that I am disabling?

01:16:15.614 --> 01:16:18.255
<v Speaker 0>And they say There there are there are

01:16:18.255 --> 01:16:21.695
<v Speaker 1>ways where you could potentially disable something like

01:16:21.695 --> 01:16:24.735
<v Speaker 1>this, and that that's very closely related to

01:16:24.735 --> 01:16:27.760
<v Speaker 1>how how this process works. So on a

01:16:27.760 --> 01:16:29.360
<v Speaker 1>on a on a high level, if we

01:16:29.360 --> 01:16:30.159
<v Speaker 1>think about,

01:16:31.040 --> 01:16:33.840
<v Speaker 1>what our binaries are made up of,

01:16:34.400 --> 01:16:37.119
<v Speaker 1>they're they're in a format called called ELF.

01:16:38.639 --> 01:16:41.840
<v Speaker 1>And an an ELF binary has various sections

01:16:41.840 --> 01:16:44.534
<v Speaker 1>that describe parts of the binary, basically.

01:16:45.655 --> 01:16:49.014
<v Speaker 1>Obviously, parts of it are are executable code,

01:16:49.415 --> 01:16:51.574
<v Speaker 1>but there are various other sections,

01:16:51.575 --> 01:16:54.215
<v Speaker 1>and one of them contains something that's called

01:16:54.215 --> 01:16:56.215
<v Speaker 1>DWARF debugging information.

01:16:57.255 --> 01:16:57.735
<v Speaker 1>And

01:16:58.710 --> 01:17:00.150
<v Speaker 1>this section,

01:17:00.230 --> 01:17:03.110
<v Speaker 1>sometimes people strip out of their binaries in

01:17:03.110 --> 01:17:05.110
<v Speaker 1>order to save space

01:17:07.430 --> 01:17:09.510
<v Speaker 1>of the size of the binary because the

01:17:09.510 --> 01:17:13.094
<v Speaker 1>executable code will still execute fine without dwarf

01:17:13.094 --> 01:17:13.894
<v Speaker 1>information,

01:17:14.454 --> 01:17:15.894
<v Speaker 1>but you may be,

01:17:18.054 --> 01:17:20.135
<v Speaker 1>you may be missing out on the ability

01:17:20.135 --> 01:17:23.494
<v Speaker 1>to debug. And there there are various

01:17:24.949 --> 01:17:27.909
<v Speaker 1>various case studies that all of the hyperscalers

01:17:27.909 --> 01:17:31.190
<v Speaker 1>essentially have done, and they always ended up

01:17:31.989 --> 01:17:34.070
<v Speaker 1>coming to the conclusion that it's not worth

01:17:34.070 --> 01:17:37.350
<v Speaker 1>throwing away this this information because Yeah. Being

01:17:37.350 --> 01:17:39.994
<v Speaker 1>able to debug is just always going to

01:17:39.994 --> 01:17:40.874
<v Speaker 1>be worth it.

01:17:42.395 --> 01:17:43.994
<v Speaker 1>I see you you did add a couple

01:17:43.994 --> 01:17:44.554
<v Speaker 1>of

01:17:45.594 --> 01:17:48.554
<v Speaker 1>compiler flags, so this might be the culprit,

01:17:48.554 --> 01:17:49.275
<v Speaker 1>but I I'm not

01:17:49.915 --> 01:17:51.195
<v Speaker 1>I don't know off the top of my

01:17:51.195 --> 01:17:53.114
<v Speaker 1>head what dash s and dash dash w

01:17:53.114 --> 01:17:55.510
<v Speaker 1>do. Yeah. These just came with the Dockerfile

01:17:55.510 --> 01:17:56.630
<v Speaker 0>for the project.

01:17:58.150 --> 01:18:00.310
<v Speaker 0>In fact, if I just go here may

01:18:00.310 --> 01:18:02.150
<v Speaker 0>as well just do the spoiler now and

01:18:02.150 --> 01:18:04.310
<v Speaker 0>show you. I haven't modified the Dockerfile. I

01:18:04.310 --> 01:18:05.910
<v Speaker 0>don't know what those flags do either. They

01:18:05.910 --> 01:18:07.670
<v Speaker 0>could very well that dash s being a

01:18:07.670 --> 01:18:09.764
<v Speaker 0>strip could be what's happening there.

01:18:10.885 --> 01:18:11.925
<v Speaker 0>But I just

01:18:12.325 --> 01:18:14.485
<v Speaker 0>decided it's a logical routine that that a

01:18:14.485 --> 01:18:16.805
<v Speaker 0>nice big blip. So that's why I've ever

01:18:16.805 --> 01:18:17.844
<v Speaker 0>seen that thing.

01:18:19.364 --> 01:18:21.605
<v Speaker 1>Yeah. Oh, wow. Nice. So I think we've

01:18:21.605 --> 01:18:22.005
<v Speaker 0>seen

01:18:22.550 --> 01:18:24.710
<v Speaker 0>a lot from Parca. I think we can

01:18:24.710 --> 01:18:26.390
<v Speaker 0>all see the value that it brings to

01:18:26.390 --> 01:18:28.870
<v Speaker 0>our infrastructure. I definitely do believe

01:18:29.030 --> 01:18:31.110
<v Speaker 0>that if you have a Kubernetes cluster in

01:18:31.110 --> 01:18:32.790
<v Speaker 0>production, that Parca should be part of that

01:18:32.790 --> 01:18:35.110
<v Speaker 0>stack because you just don't want to lose

01:18:35.785 --> 01:18:38.025
<v Speaker 0>the type of information that we're getting here,

01:18:38.025 --> 01:18:39.465
<v Speaker 0>especially when things go wrong and you need

01:18:39.465 --> 01:18:41.224
<v Speaker 0>as much information as possible.

01:18:41.545 --> 01:18:43.625
<v Speaker 0>And as you're deploying on a cloud native

01:18:43.625 --> 01:18:44.825
<v Speaker 0>way frequently,

01:18:44.825 --> 01:18:47.385
<v Speaker 0>multiple times per day, that compare feature is

01:18:47.385 --> 01:18:48.585
<v Speaker 0>just golden.

01:18:48.905 --> 01:18:50.345
<v Speaker 0>I had no idea we were gonna see

01:18:50.345 --> 01:18:52.440
<v Speaker 0>that and I'm so impressed and so excited

01:18:52.440 --> 01:18:54.120
<v Speaker 0>to get that running on my own customers

01:18:54.120 --> 01:18:56.280
<v Speaker 0>now. So thank you for that.

01:18:56.760 --> 01:18:58.360
<v Speaker 1>Yeah. My pleasure. I I think the first

01:18:58.360 --> 01:19:00.920
<v Speaker 1>time maybe Matthias remembers

01:19:01.000 --> 01:19:03.080
<v Speaker 1>this. He's he's in the in the comments.

01:19:03.720 --> 01:19:05.880
<v Speaker 1>The first time we were we, like, implemented

01:19:05.880 --> 01:19:08.535
<v Speaker 1>this, we were so mesmerized by this. We'd

01:19:08.695 --> 01:19:10.455
<v Speaker 1>like, I I think we spent, like, an

01:19:10.455 --> 01:19:11.975
<v Speaker 1>hour just clicking around

01:19:12.215 --> 01:19:14.935
<v Speaker 1>understanding just Parca itself. You know? Like, what

01:19:14.935 --> 01:19:16.855
<v Speaker 1>was what was the memory difference here and

01:19:16.855 --> 01:19:19.095
<v Speaker 1>why? Why why was this what's the CPU

01:19:19.095 --> 01:19:19.815
<v Speaker 1>spike?

01:19:19.975 --> 01:19:22.460
<v Speaker 1>And just, like, understanding that depth down to

01:19:22.460 --> 01:19:24.699
<v Speaker 1>the line number is just some not something

01:19:24.699 --> 01:19:25.979
<v Speaker 1>we've never seen before.

01:19:26.380 --> 01:19:28.619
<v Speaker 1>Yeah. So, yeah, I share the enthusiasm.

01:19:28.860 --> 01:19:29.579
<v Speaker 0>Sweet.

01:19:30.140 --> 01:19:32.380
<v Speaker 0>Matthias is in the comments saying that dash

01:19:32.380 --> 01:19:34.060
<v Speaker 0>s is probably the culprit. So

01:19:34.755 --> 01:19:35.635
<v Speaker 0>I will

01:19:36.114 --> 01:19:37.795
<v Speaker 0>I'm sure we'll do more demos. And if

01:19:37.795 --> 01:19:38.915
<v Speaker 0>you turn, we can take a look at

01:19:38.915 --> 01:19:40.275
<v Speaker 0>that. I'm

01:19:40.275 --> 01:19:42.114
<v Speaker 0>curious. You know, we'll we'll finish up now

01:19:42.114 --> 01:19:43.554
<v Speaker 0>in the next few minutes, but

01:19:44.195 --> 01:19:46.514
<v Speaker 0>kinda what your thoughts are on what's coming

01:19:46.514 --> 01:19:49.110
<v Speaker 0>next for Parca, what it takes for Parca

01:19:49.110 --> 01:19:51.110
<v Speaker 0>to to reach this next milestone,

01:19:51.270 --> 01:19:52.950
<v Speaker 0>whether that be, like, a one point o

01:19:52.950 --> 01:19:53.910
<v Speaker 0>or something else,

01:19:54.310 --> 01:19:54.950
<v Speaker 0>and

01:19:55.590 --> 01:19:57.990
<v Speaker 0>other crazy ideas that you've maybe got. So

01:19:57.990 --> 01:20:00.150
<v Speaker 0>let let's start with what's next for Parca.

01:20:00.870 --> 01:20:01.830
<v Speaker 1>Yeah. So

01:20:02.390 --> 01:20:03.270
<v Speaker 1>I think the

01:20:04.665 --> 01:20:05.465
<v Speaker 1>the

01:20:05.945 --> 01:20:08.905
<v Speaker 1>most important thing for the community that

01:20:08.905 --> 01:20:11.784
<v Speaker 1>we're working on with Parca is actually

01:20:12.185 --> 01:20:14.104
<v Speaker 1>the on the storage side.

01:20:15.145 --> 01:20:17.625
<v Speaker 1>As you can imagine, we're dealing with a

01:20:17.625 --> 01:20:18.505
<v Speaker 1>whole lot of data,

01:20:19.460 --> 01:20:21.860
<v Speaker 1>and it's it's not easy to deal with

01:20:21.860 --> 01:20:23.300
<v Speaker 1>that amount of data,

01:20:23.460 --> 01:20:24.979
<v Speaker 1>making it queryable,

01:20:25.460 --> 01:20:28.659
<v Speaker 1>as dynamically as we do with with Parca.

01:20:29.219 --> 01:20:31.540
<v Speaker 1>And, of course, the larger the scale, the

01:20:31.540 --> 01:20:32.340
<v Speaker 1>harder the steps.

01:20:33.094 --> 01:20:33.974
<v Speaker 1>And so

01:20:35.015 --> 01:20:37.335
<v Speaker 1>we're working on kind of a new storage

01:20:37.335 --> 01:20:38.215
<v Speaker 1>iteration

01:20:38.455 --> 01:20:40.935
<v Speaker 1>that's going to allow us to to scale

01:20:40.935 --> 01:20:43.255
<v Speaker 1>this to the to the size that we

01:20:43.255 --> 01:20:46.614
<v Speaker 1>intend at the query latency that we want.

01:20:47.975 --> 01:20:50.780
<v Speaker 1>So as we saw the the the demo

01:20:50.940 --> 01:20:52.860
<v Speaker 1>that the demo worked great, but if once

01:20:52.860 --> 01:20:54.460
<v Speaker 1>we go into the hundreds or thousands of

01:20:54.460 --> 01:20:55.100
<v Speaker 1>nodes,

01:20:55.420 --> 01:20:56.139
<v Speaker 1>with

01:20:56.220 --> 01:20:57.659
<v Speaker 1>thousands of containers,

01:20:58.860 --> 01:21:01.180
<v Speaker 1>it gets more difficult to to query that

01:21:01.180 --> 01:21:01.820
<v Speaker 1>data,

01:21:02.060 --> 01:21:02.540
<v Speaker 1>efficiently.

01:21:03.005 --> 01:21:06.445
<v Speaker 1>And so we're actually building an entirely custom

01:21:07.244 --> 01:21:08.604
<v Speaker 1>columnar store

01:21:08.605 --> 01:21:10.524
<v Speaker 1>just to solve this problem.

01:21:11.965 --> 01:21:13.885
<v Speaker 1>So that's something that I think is really

01:21:13.885 --> 01:21:16.284
<v Speaker 1>important to the success of this project

01:21:17.790 --> 01:21:20.190
<v Speaker 1>so that we can kind of scale the

01:21:20.190 --> 01:21:21.310
<v Speaker 1>entire idea.

01:21:23.150 --> 01:21:25.070
<v Speaker 1>So, yeah, that that's something that I'm also

01:21:25.070 --> 01:21:27.230
<v Speaker 1>personally very excited about because I think the

01:21:27.230 --> 01:21:29.150
<v Speaker 1>design and the design is open. You can

01:21:29.150 --> 01:21:29.550
<v Speaker 1>find

01:21:31.755 --> 01:21:33.755
<v Speaker 1>the the design on the

01:21:35.035 --> 01:21:35.515
<v Speaker 1>on the

01:21:36.235 --> 01:21:37.835
<v Speaker 1>I think it might have only been discussed

01:21:37.835 --> 01:21:39.835
<v Speaker 1>in the Parca office hours so far, but

01:21:39.835 --> 01:21:40.715
<v Speaker 1>it's open.

01:21:41.515 --> 01:21:41.835
<v Speaker 0>Nice.

01:21:42.890 --> 01:21:45.690
<v Speaker 0>Do you see a future where Parca integrates

01:21:45.690 --> 01:21:46.409
<v Speaker 0>with,

01:21:46.810 --> 01:21:47.449
<v Speaker 0>you know,

01:21:48.410 --> 01:21:50.970
<v Speaker 0>auto scalers on Kubernetes to be able to

01:21:51.050 --> 01:21:52.570
<v Speaker 0>you know, I can see, like, the vertical

01:21:52.570 --> 01:21:54.650
<v Speaker 0>pod auto scaler and been able to modify

01:21:54.650 --> 01:21:56.810
<v Speaker 0>those limits based on what Parca sees

01:21:57.035 --> 01:21:59.275
<v Speaker 0>and for that to evolve over time across

01:21:59.275 --> 01:22:01.515
<v Speaker 0>versions, even maybe to the point of hooking

01:22:01.515 --> 01:22:05.115
<v Speaker 0>into remediation systems, the captain, and actually reverting

01:22:05.115 --> 01:22:07.755
<v Speaker 0>a deploy based on bad behaviors or performance.

01:22:08.635 --> 01:22:09.275
<v Speaker 1>Yeah.

01:22:09.515 --> 01:22:10.795
<v Speaker 1>A %. So

01:22:12.200 --> 01:22:14.840
<v Speaker 1>as I said, the hyperscalers have been doing

01:22:15.320 --> 01:22:18.280
<v Speaker 1>methodologies like this for for almost a decade.

01:22:18.280 --> 01:22:20.840
<v Speaker 1>And, actually, eBPF is kind of the reason

01:22:20.840 --> 01:22:23.800
<v Speaker 1>why this is accessible to us now. Hyperscalers

01:22:23.800 --> 01:22:25.239
<v Speaker 1>have been maintaining

01:22:25.400 --> 01:22:27.960
<v Speaker 1>their operating system versions

01:22:27.505 --> 01:22:28.305
<v Speaker 1>themselves

01:22:29.025 --> 01:22:30.865
<v Speaker 1>for a long time, and that's why they

01:22:30.865 --> 01:22:33.505
<v Speaker 1>were able to do integrations like this at

01:22:33.505 --> 01:22:35.745
<v Speaker 1>a very low level that just the rest

01:22:35.745 --> 01:22:37.505
<v Speaker 1>of the world wasn't able to do. So,

01:22:37.505 --> 01:22:38.705
<v Speaker 1>like, was

01:22:38.705 --> 01:22:40.545
<v Speaker 1>really kind of a godsend for this.

01:22:42.840 --> 01:22:43.479
<v Speaker 1>But

01:22:45.560 --> 01:22:47.239
<v Speaker 1>what I was get trying to get to,

01:22:47.239 --> 01:22:49.239
<v Speaker 1>Google has actually written a couple of papers

01:22:49.239 --> 01:22:51.320
<v Speaker 1>where they described exactly what you just said

01:22:51.320 --> 01:22:54.199
<v Speaker 1>that they they use this type of data

01:22:54.199 --> 01:22:57.560
<v Speaker 1>for scheduling decisions in their orchestration system board.

01:22:59.105 --> 01:23:01.505
<v Speaker 1>And they they do various other

01:23:01.905 --> 01:23:03.505
<v Speaker 1>optimization techniques.

01:23:03.745 --> 01:23:06.065
<v Speaker 1>One that I'm particularly excited

01:23:06.065 --> 01:23:09.025
<v Speaker 1>about is something called profile guided optimizations.

01:23:09.345 --> 01:23:10.465
<v Speaker 1>And this is kind of a

01:23:11.390 --> 01:23:13.710
<v Speaker 1>technique that has existed, I believe, in my

01:23:13.710 --> 01:23:14.750
<v Speaker 1>in my research.

01:23:15.550 --> 01:23:17.470
<v Speaker 1>I I found it found found the first

01:23:17.470 --> 01:23:19.310
<v Speaker 1>kind of mentions in the in the nineteen

01:23:19.310 --> 01:23:20.110
<v Speaker 1>seventies.

01:23:20.430 --> 01:23:23.230
<v Speaker 1>And the premise is really simple because we

01:23:23.230 --> 01:23:23.710
<v Speaker 1>understand

01:23:24.724 --> 01:23:27.525
<v Speaker 1>how our programs are going to be executed

01:23:27.525 --> 01:23:30.804
<v Speaker 1>in real life, we can make opinionated compiler

01:23:30.804 --> 01:23:31.684
<v Speaker 1>optimizations

01:23:31.684 --> 01:23:34.164
<v Speaker 1>for exactly the those situations.

01:23:34.485 --> 01:23:37.284
<v Speaker 1>Optimizations that may not generally be a good

01:23:37.284 --> 01:23:39.970
<v Speaker 1>idea, but because we know how the this

01:23:39.970 --> 01:23:41.650
<v Speaker 1>code is going to be executed, we can

01:23:41.650 --> 01:23:43.570
<v Speaker 1>make opinionated optimizations.

01:23:45.330 --> 01:23:47.890
<v Speaker 1>And the the great news kind of is

01:23:48.210 --> 01:23:51.170
<v Speaker 1>these things do already exist in all major

01:23:51.410 --> 01:23:53.895
<v Speaker 1>compiler tool chains. And as a matter of

01:23:53.895 --> 01:23:55.895
<v Speaker 1>fact, the very next version of Go is

01:23:55.895 --> 01:23:58.614
<v Speaker 1>going to ship with profile guided optimizations,

01:23:59.415 --> 01:24:00.854
<v Speaker 1>possibilities as well.

01:24:01.335 --> 01:24:03.255
<v Speaker 1>So the the the great news for the

01:24:03.255 --> 01:24:06.079
<v Speaker 1>Parca project is kind of we don't even

01:24:06.079 --> 01:24:08.880
<v Speaker 1>need to build these mechanisms into compilers. They

01:24:08.880 --> 01:24:09.840
<v Speaker 1>already exist.

01:24:10.960 --> 01:24:12.800
<v Speaker 1>We just need to be able to export

01:24:12.800 --> 01:24:15.760
<v Speaker 1>this data in the format that these compilers

01:24:15.760 --> 01:24:16.800
<v Speaker 1>expect.

01:24:16.880 --> 01:24:19.145
<v Speaker 1>And then the the hope that we have

01:24:19.145 --> 01:24:20.585
<v Speaker 1>from all of this is that,

01:24:20.825 --> 01:24:23.225
<v Speaker 1>magically, just by giving your compiler some of

01:24:23.225 --> 01:24:26.185
<v Speaker 1>this data that you're collecting, hopefully, anyways now,

01:24:26.425 --> 01:24:30.185
<v Speaker 1>your programs just magically get faster, better, less

01:24:30.185 --> 01:24:30.665
<v Speaker 1>resources.

01:24:32.220 --> 01:24:35.260
<v Speaker 0>Awesome. That is all extremely exciting, and I

01:24:35.260 --> 01:24:37.100
<v Speaker 0>can't wait to follow along with the Parca

01:24:37.100 --> 01:24:38.940
<v Speaker 0>journey and just see what cool things come

01:24:38.940 --> 01:24:40.220
<v Speaker 0>out of this over the next six months

01:24:40.220 --> 01:24:42.620
<v Speaker 0>and longer. So thank you so much for

01:24:42.620 --> 01:24:44.300
<v Speaker 0>for joining us and guiding us through this.

01:24:44.300 --> 01:24:46.925
<v Speaker 0>It's been really cool. I think it's awesome

01:24:46.925 --> 01:24:48.684
<v Speaker 0>to be able to see these new techniques

01:24:48.684 --> 01:24:51.244
<v Speaker 0>and tools come out and make every hopefully,

01:24:51.244 --> 01:24:52.605
<v Speaker 0>make all of our lives that little bit

01:24:52.605 --> 01:24:53.324
<v Speaker 0>easier.

01:24:53.965 --> 01:24:56.684
<v Speaker 0>Any final words before we say goodbye for

01:24:56.684 --> 01:24:56.925
<v Speaker 0>today?

01:24:59.010 --> 01:25:01.250
<v Speaker 1>Just my my final words are please try

01:25:01.250 --> 01:25:02.770
<v Speaker 1>out Parca and

01:25:03.570 --> 01:25:05.330
<v Speaker 1>join us on our Discord server. If you

01:25:05.330 --> 01:25:08.050
<v Speaker 1>have any issues or any questions, feedback, anything,

01:25:08.050 --> 01:25:09.330
<v Speaker 1>we're more than happy

01:25:09.490 --> 01:25:11.250
<v Speaker 1>to, you know, help you through it. If

01:25:11.250 --> 01:25:13.934
<v Speaker 1>you have any issues or work through

01:25:14.735 --> 01:25:17.614
<v Speaker 1>feedback. We're always happy to to have any

01:25:17.614 --> 01:25:18.574
<v Speaker 1>kind of feedback

01:25:19.054 --> 01:25:21.935
<v Speaker 1>and and, you know, hope to improve Parca

01:25:21.935 --> 01:25:23.374
<v Speaker 1>together with the community.

01:25:24.094 --> 01:25:24.574
<v Speaker 0>Awesome.

01:25:25.010 --> 01:25:27.010
<v Speaker 0>Well, thanks again for joining me, Frederic. Have

01:25:27.010 --> 01:25:28.450
<v Speaker 0>a wonderful day, and I'll speak to you

01:25:28.450 --> 01:25:30.930
<v Speaker 0>again soon. My pleasure. Thank you for having

01:25:30.930 --> 01:25:31.090
<v Speaker 1>me.
