WEBVTT

NOTE
Transcription provided by Deepgram
Request Id: c294ed52-96e5-482d-a55a-cef5d456aa95
Created: 2025-04-29T19:27:08.482Z
Duration: 7820.1157
Channels: 1

00:00:55.320 --> 00:00:57.880
<v Speaker 0>Hello, and welcome to today's episode of Rawkode

00:00:57.880 --> 00:00:59.960
<v Speaker 0>live. I am your host, Rawkode.

00:01:00.200 --> 00:01:02.360
<v Speaker 0>Now before we get started, I just wanna

00:01:02.360 --> 00:01:04.040
<v Speaker 0>cover a little bit of housekeeping.

00:01:04.680 --> 00:01:06.705
<v Speaker 0>First, please subscribe

00:01:06.865 --> 00:01:08.785
<v Speaker 0>to the YouTube channel. This helps other people

00:01:08.785 --> 00:01:11.265
<v Speaker 0>find this content. My goal is to produce

00:01:11.345 --> 00:01:13.425
<v Speaker 0>valuable learning materials for us all on the

00:01:13.425 --> 00:01:15.345
<v Speaker 0>cloud native landscape, and I hope that you

00:01:15.345 --> 00:01:17.825
<v Speaker 0>can subscribe and share that knowledge with us.

00:01:18.409 --> 00:01:20.570
<v Speaker 0>Also, I wanna encourage you to join our

00:01:20.570 --> 00:01:22.890
<v Speaker 0>Discord channel where, you know, if you have

00:01:22.890 --> 00:01:24.490
<v Speaker 0>questions or you want to experiment or even

00:01:24.490 --> 00:01:26.409
<v Speaker 0>suggest new technologies that we should cover, the

00:01:26.409 --> 00:01:28.009
<v Speaker 0>Discord channel is the best place to do

00:01:28.009 --> 00:01:29.369
<v Speaker 0>that. We've got a few hundred people in

00:01:29.369 --> 00:01:31.609
<v Speaker 0>there now talking about cloud native Kubernetes and

00:01:31.609 --> 00:01:33.835
<v Speaker 0>everything in between. Again, come and join us

00:01:33.835 --> 00:01:34.314
<v Speaker 0>there.

00:01:34.795 --> 00:01:37.195
<v Speaker 0>And I also want to thank my employer,

00:01:37.195 --> 00:01:39.755
<v Speaker 0>Equinix Metal, who provide the time, resources, and

00:01:39.755 --> 00:01:41.674
<v Speaker 0>everything else that allows me to do this

00:01:42.155 --> 00:01:43.515
<v Speaker 0>as part of my job. So thank you

00:01:43.515 --> 00:01:45.720
<v Speaker 0>Equinix Metal. Feel free check out that platform

00:01:45.720 --> 00:01:47.880
<v Speaker 0>by using the code Rawkode live. This will

00:01:47.880 --> 00:01:50.200
<v Speaker 0>get you $50 in credit. That is roughly

00:01:50.200 --> 00:01:52.120
<v Speaker 0>around one hundred hours of compute on a

00:01:52.120 --> 00:01:54.600
<v Speaker 0>modest instance. So take it, enjoy it, play

00:01:54.600 --> 00:01:55.720
<v Speaker 0>with it. Alright.

00:01:57.235 --> 00:01:59.314
<v Speaker 0>Now, today we're gonna be taking a look

00:01:59.314 --> 00:02:00.354
<v Speaker 0>at Kubeflow,

00:02:00.354 --> 00:02:03.155
<v Speaker 0>a open source program and technology that allows

00:02:03.155 --> 00:02:05.715
<v Speaker 0>you to run machine learning workloads on Kubernetes.

00:02:06.435 --> 00:02:08.514
<v Speaker 0>I am by no means an expert in

00:02:08.514 --> 00:02:11.155
<v Speaker 0>machine learning. However, I am joined by

00:02:12.020 --> 00:02:13.060
<v Speaker 0>Michael

00:02:13.060 --> 00:02:13.940
<v Speaker 0>Tannenbaum,

00:02:13.940 --> 00:02:15.140
<v Speaker 0>Kubeflow

00:02:15.300 --> 00:02:16.340
<v Speaker 0>maintainer,

00:02:16.900 --> 00:02:18.420
<v Speaker 0>who's gonna guide us through everything that we

00:02:18.420 --> 00:02:20.420
<v Speaker 0>need to know to get started today. Hey,

00:02:20.420 --> 00:02:21.140
<v Speaker 0>Michael. How are you?

00:02:24.915 --> 00:02:26.035
<v Speaker 0>You there? Hello.

00:02:26.275 --> 00:02:28.275
<v Speaker 1>Yes. I am indeed here. I'm I am

00:02:28.275 --> 00:02:30.995
<v Speaker 1>both getting the live and the slightly delayed

00:02:30.995 --> 00:02:33.474
<v Speaker 1>audio, so it's a little confusing for me.

00:02:33.474 --> 00:02:36.034
<v Speaker 0>I have done that so many times. So

00:02:36.034 --> 00:02:36.515
<v Speaker 0>many times.

00:02:38.400 --> 00:02:40.400
<v Speaker 1>Yeah. So let

00:02:41.200 --> 00:02:41.920
<v Speaker 1>me think.

00:02:42.319 --> 00:02:42.959
<v Speaker 1>Perhaps I

00:02:48.799 --> 00:02:50.319
<v Speaker 1>I think I think if I if I

00:02:50.319 --> 00:02:51.920
<v Speaker 1>resolve to use a single

00:02:54.355 --> 00:02:55.235
<v Speaker 1>perhaps not.

00:02:55.475 --> 00:02:57.635
<v Speaker 1>What's what's your suggestion, David? Do you have

00:02:57.635 --> 00:02:59.635
<v Speaker 0>another tab open with the YouTube page?

00:03:00.835 --> 00:03:02.035
<v Speaker 1>Oh my goodness.

00:03:03.795 --> 00:03:05.555
<v Speaker 0>What is okay.

00:03:05.635 --> 00:03:07.315
<v Speaker 0>Don't worry. Like I said, I've done it

00:03:07.315 --> 00:03:07.555
<v Speaker 0>before.

00:03:09.270 --> 00:03:10.390
<v Speaker 1>Well

00:03:10.390 --> 00:03:11.190
<v Speaker 1>well

00:03:11.190 --> 00:03:14.390
<v Speaker 1>said. We we resolved it. Thank you. Alright.

00:03:14.390 --> 00:03:17.270
<v Speaker 1>Welcome to or thank you for welcoming me.

00:03:17.270 --> 00:03:18.390
<v Speaker 1>Hello. Greetings.

00:03:18.710 --> 00:03:21.430
<v Speaker 1>I'm here. Awesome. That's the that's the first

00:03:21.430 --> 00:03:22.925
<v Speaker 0>tech up done. Right? That that's done, we

00:03:22.925 --> 00:03:24.925
<v Speaker 0>can move on with nothing but glorious successful

00:03:24.925 --> 00:03:26.925
<v Speaker 0>demos here on end. And that's the way.

00:03:27.245 --> 00:03:29.725
<v Speaker 1>That's that's how we that's that's the only

00:03:29.725 --> 00:03:31.565
<v Speaker 1>only way I like to do business, David.

00:03:31.565 --> 00:03:32.125
<v Speaker 1>Thanks.

00:03:34.205 --> 00:03:36.445
<v Speaker 1>I presume you asked me to introduce myself

00:03:36.445 --> 00:03:38.980
<v Speaker 1>or or Yeah. Please feel free to tell

00:03:38.980 --> 00:03:40.420
<v Speaker 0>us a little bit about you, and then

00:03:40.420 --> 00:03:42.100
<v Speaker 0>we'll we'll start talking about Kubeflow.

00:03:42.420 --> 00:03:45.620
<v Speaker 1>Sounds good. Okay. My name is Michael Tanenbaum.

00:03:46.099 --> 00:03:48.980
<v Speaker 1>I am a principal solutions engineer in my

00:03:48.980 --> 00:03:51.220
<v Speaker 1>day job at a company called Aricto.

00:03:51.615 --> 00:03:53.775
<v Speaker 1>We are one of the biggest contributors to

00:03:53.775 --> 00:03:55.775
<v Speaker 1>open source Kubeflow, and and,

00:03:57.135 --> 00:03:57.935
<v Speaker 1>my

00:03:57.935 --> 00:04:01.215
<v Speaker 1>community participation is around the, special interest group

00:04:01.215 --> 00:04:02.495
<v Speaker 1>for on premises,

00:04:03.375 --> 00:04:03.855
<v Speaker 1>deployments,

00:04:04.575 --> 00:04:06.335
<v Speaker 1>where we are working to help make it

00:04:06.335 --> 00:04:08.730
<v Speaker 1>easier for folks to deploy in their own

00:04:08.730 --> 00:04:10.090
<v Speaker 1>data centers and,

00:04:10.329 --> 00:04:12.250
<v Speaker 1>providing reference architectures

00:04:12.329 --> 00:04:13.050
<v Speaker 1>and,

00:04:13.769 --> 00:04:16.009
<v Speaker 1>particularly bare metal because,

00:04:16.250 --> 00:04:17.529
<v Speaker 1>ML workflows

00:04:17.529 --> 00:04:20.490
<v Speaker 1>are very workloads are are performance,

00:04:20.729 --> 00:04:21.289
<v Speaker 1>sensitive.

00:04:21.714 --> 00:04:24.435
<v Speaker 1>And, bare metal, no hypervisor, get it on

00:04:24.435 --> 00:04:25.155
<v Speaker 1>out of there,

00:04:25.715 --> 00:04:28.035
<v Speaker 1>is, is sort of a a mantra that

00:04:28.035 --> 00:04:30.035
<v Speaker 1>we're we're trying to encourage. And certainly for

00:04:30.115 --> 00:04:31.715
<v Speaker 1>there's lots of good reasons to do that

00:04:31.715 --> 00:04:33.875
<v Speaker 1>security cost. We can talk more about that

00:04:33.875 --> 00:04:36.310
<v Speaker 1>if you're interested. But I

00:04:36.630 --> 00:04:38.150
<v Speaker 1>live in New York City, so I'm speaking

00:04:38.150 --> 00:04:40.470
<v Speaker 1>you to you today from Red Hook, Brooklyn.

00:04:40.789 --> 00:04:41.430
<v Speaker 1>And

00:04:42.870 --> 00:04:45.270
<v Speaker 1>what else? And previously, I've I've been in

00:04:45.270 --> 00:04:48.305
<v Speaker 1>the Kubernetes space for a long time. Before

00:04:48.305 --> 00:04:50.625
<v Speaker 1>that, I was in the Mesos space for

00:04:50.625 --> 00:04:53.105
<v Speaker 1>any cloud native dinosaurs in the in the

00:04:53.105 --> 00:04:55.665
<v Speaker 1>audience. I worked at Mesosphere for a couple

00:04:55.665 --> 00:04:59.585
<v Speaker 1>years as well. And I started my career

00:04:59.585 --> 00:05:01.265
<v Speaker 1>as a

00:05:01.600 --> 00:05:04.880
<v Speaker 1>as a junior developer working on analytics tools

00:05:04.880 --> 00:05:06.880
<v Speaker 1>at the World Bank, and since then have

00:05:06.880 --> 00:05:09.280
<v Speaker 1>done a million different things all around the

00:05:09.280 --> 00:05:11.840
<v Speaker 1>software world. So I love software

00:05:12.480 --> 00:05:14.400
<v Speaker 1>and have ever since I was a little

00:05:14.400 --> 00:05:16.205
<v Speaker 1>kid, and that's that's sort of what got

00:05:16.205 --> 00:05:18.444
<v Speaker 1>me into it. I have no formal education.

00:05:18.444 --> 00:05:20.444
<v Speaker 1>It should be noted in anything related to

00:05:20.444 --> 00:05:22.764
<v Speaker 1>computer science. I studied Chinese in college.

00:05:24.044 --> 00:05:24.525
<v Speaker 1>But

00:05:25.085 --> 00:05:26.444
<v Speaker 1>but, yeah, self taught. It's one of the

00:05:26.444 --> 00:05:28.365
<v Speaker 1>things I love about our our industry, right,

00:05:28.365 --> 00:05:30.729
<v Speaker 1>is people don't really care what's on your

00:05:30.729 --> 00:05:33.210
<v Speaker 1>what's on your what your diploma is, you

00:05:33.210 --> 00:05:34.570
<v Speaker 1>know, what's hanging on the wall. It's just

00:05:34.570 --> 00:05:36.570
<v Speaker 1>can you do the job that, we need

00:05:36.570 --> 00:05:38.970
<v Speaker 1>done today? And, even if you can't, can

00:05:38.970 --> 00:05:40.169
<v Speaker 1>you Google effectively? So

00:05:41.545 --> 00:05:43.865
<v Speaker 0>I couldn't agree more. I have no formal

00:05:43.865 --> 00:05:46.745
<v Speaker 0>education in computer science or computer engineering either.

00:05:46.745 --> 00:05:48.985
<v Speaker 0>I am a complete that managed to faint

00:05:48.985 --> 00:05:50.505
<v Speaker 0>his way into his first role and has

00:05:50.505 --> 00:05:52.025
<v Speaker 0>just kept learning ever since.

00:05:52.425 --> 00:05:53.945
<v Speaker 0>If it wasn't for Google, I probably wouldn't

00:05:53.945 --> 00:05:54.665
<v Speaker 0>have this

00:05:56.320 --> 00:05:57.680
<v Speaker 0>It definitely keeps me Well

00:05:59.280 --> 00:06:01.440
<v Speaker 0>Keeps me from getting fired, I'm sure.

00:06:02.080 --> 00:06:02.880
<v Speaker 0>Alright.

00:06:04.320 --> 00:06:07.040
<v Speaker 0>Cool. Why don't we thank you for sharing

00:06:07.040 --> 00:06:08.720
<v Speaker 0>all that. It's really

00:06:08.445 --> 00:06:10.125
<v Speaker 0>nice to get a little bit of personal

00:06:10.125 --> 00:06:12.605
<v Speaker 0>information as well. It's just a general overview

00:06:12.605 --> 00:06:13.965
<v Speaker 0>of you. So that's awesome.

00:06:14.205 --> 00:06:15.885
<v Speaker 0>Do you wanna then tell us a little

00:06:15.885 --> 00:06:17.965
<v Speaker 0>bit of of Kubeflow? We can go straight

00:06:17.965 --> 00:06:19.245
<v Speaker 0>into Slice if you wanna do that, or

00:06:19.245 --> 00:06:21.005
<v Speaker 0>you can maybe give us a Sure. Yeah.

00:06:21.005 --> 00:06:22.205
<v Speaker 1>Yeah. That that sounds good.

00:06:23.100 --> 00:06:25.660
<v Speaker 1>So speaking today, not from, you know, the

00:06:25.660 --> 00:06:27.260
<v Speaker 1>position of my not from my

00:06:27.580 --> 00:06:29.660
<v Speaker 1>day job, but speaking about it, from the

00:06:29.660 --> 00:06:32.140
<v Speaker 1>perspective of being a community men member. So

00:06:32.140 --> 00:06:34.700
<v Speaker 1>everything you'll see today is open source and,

00:06:35.100 --> 00:06:37.255
<v Speaker 1>available for for folks to to play around

00:06:37.255 --> 00:06:38.855
<v Speaker 1>with. So, yeah, I do have some slides.

00:06:38.855 --> 00:06:40.695
<v Speaker 1>I think that might help, illustrate

00:06:40.695 --> 00:06:42.375
<v Speaker 1>a little bit about Kubeflow for folks who

00:06:42.375 --> 00:06:43.655
<v Speaker 1>are new to the project.

00:06:45.495 --> 00:06:47.975
<v Speaker 1>So there we go. Perfect. Alright.

00:06:48.935 --> 00:06:49.255
<v Speaker 1>So

00:06:52.120 --> 00:06:55.640
<v Speaker 1>the the Kubeflow project is approximately,

00:06:55.800 --> 00:06:57.720
<v Speaker 1>you know, in a formal way, about two

00:06:57.720 --> 00:06:59.480
<v Speaker 1>years old, three years old at this point,

00:06:59.480 --> 00:07:00.680
<v Speaker 1>2018.

00:07:01.400 --> 00:07:03.400
<v Speaker 1>We are just coming up to

00:07:03.640 --> 00:07:06.195
<v Speaker 1>the one dot three release. And by just

00:07:06.195 --> 00:07:07.635
<v Speaker 1>coming up to, I really mean just coming

00:07:07.635 --> 00:07:10.195
<v Speaker 1>up to. I think, the RC is being

00:07:10.195 --> 00:07:11.315
<v Speaker 1>cut today.

00:07:11.715 --> 00:07:13.475
<v Speaker 1>I should know one of my colleagues here

00:07:13.475 --> 00:07:15.715
<v Speaker 1>at is the release manager.

00:07:16.515 --> 00:07:18.115
<v Speaker 1>But, I don't wanna put him on the

00:07:18.115 --> 00:07:19.555
<v Speaker 1>spot, right, as, you know, I said on

00:07:19.555 --> 00:07:21.315
<v Speaker 1>the air that we were gonna release RC.

00:07:21.450 --> 00:07:22.890
<v Speaker 1>But yeah. Anyways,

00:07:23.210 --> 00:07:23.770
<v Speaker 1>so,

00:07:24.410 --> 00:07:26.090
<v Speaker 1>Kubeflow one zero one, just as a a

00:07:26.090 --> 00:07:28.570
<v Speaker 1>broad intro, you know, speaking from the perspective.

00:07:28.570 --> 00:07:30.810
<v Speaker 1>I know your audience is, is well versed

00:07:30.810 --> 00:07:32.570
<v Speaker 1>in the world of cloud native, so,

00:07:33.210 --> 00:07:36.090
<v Speaker 1>speaking to an educated audience, about these sorts

00:07:36.090 --> 00:07:36.730
<v Speaker 1>of tools here.

00:07:38.775 --> 00:07:41.575
<v Speaker 1>So why why q why was Kubeflow

00:07:41.815 --> 00:07:42.615
<v Speaker 1>founded?

00:07:42.775 --> 00:07:44.055
<v Speaker 1>Well, the

00:07:44.215 --> 00:07:45.575
<v Speaker 1>reality is that

00:07:45.895 --> 00:07:46.695
<v Speaker 1>today,

00:07:46.935 --> 00:07:48.695
<v Speaker 1>we don't really

00:07:48.695 --> 00:07:49.255
<v Speaker 1>have

00:07:50.135 --> 00:07:50.855
<v Speaker 1>great

00:07:52.310 --> 00:07:53.190
<v Speaker 1>DevOps,

00:07:53.350 --> 00:07:57.270
<v Speaker 1>SRE sorts of practices around machine learning workloads.

00:07:57.270 --> 00:07:58.950
<v Speaker 1>They tend to be very snowflakey.

00:07:58.950 --> 00:08:00.550
<v Speaker 1>They tend to be pets.

00:08:00.630 --> 00:08:02.710
<v Speaker 1>They tend to have

00:08:04.065 --> 00:08:07.265
<v Speaker 1>tremendous operations bottlenecks. After all, machine learning is

00:08:07.265 --> 00:08:10.145
<v Speaker 1>a relatively new field. I'm in in my

00:08:10.145 --> 00:08:12.305
<v Speaker 1>practice and in my day job, I see

00:08:12.305 --> 00:08:14.545
<v Speaker 1>lots of folks who are coming to

00:08:14.945 --> 00:08:18.305
<v Speaker 1>the machine learning world from a more operations

00:08:18.860 --> 00:08:20.780
<v Speaker 1>background, and then we see people who are

00:08:20.780 --> 00:08:24.139
<v Speaker 1>coming from a data science, data engineering background

00:08:24.300 --> 00:08:27.740
<v Speaker 1>now being tasked with, you know, really bringing

00:08:27.740 --> 00:08:30.060
<v Speaker 1>this into production, bringing this into

00:08:32.885 --> 00:08:35.125
<v Speaker 1>a format where we can leverage,

00:08:35.445 --> 00:08:37.525
<v Speaker 1>the benefits of of ML,

00:08:38.404 --> 00:08:39.765
<v Speaker 1>as opposed to,

00:08:40.325 --> 00:08:42.325
<v Speaker 1>at a at scale, right, at the at

00:08:42.325 --> 00:08:44.805
<v Speaker 1>enterprise scale or or organizational

00:08:44.805 --> 00:08:47.205
<v Speaker 1>scale, you know, for for nonprofits and public

00:08:47.070 --> 00:08:48.670
<v Speaker 1>sector folks who would who would like to

00:08:48.670 --> 00:08:51.950
<v Speaker 1>use it. So the Kubeflow project was started

00:08:51.950 --> 00:08:53.550
<v Speaker 1>to facilitate that,

00:08:53.950 --> 00:08:55.710
<v Speaker 1>and it is, as we'll see in a

00:08:55.710 --> 00:08:58.030
<v Speaker 1>minute, a collection of many different services,

00:08:58.190 --> 00:08:59.950
<v Speaker 1>many different pieces of software.

00:09:00.830 --> 00:09:03.464
<v Speaker 1>But the standardization

00:09:03.464 --> 00:09:04.105
<v Speaker 1>around,

00:09:04.265 --> 00:09:06.745
<v Speaker 1>Kubernetes, which I've, you know, have described I

00:09:06.745 --> 00:09:08.745
<v Speaker 1>would describe as an operating system for cloud

00:09:08.745 --> 00:09:10.904
<v Speaker 1>native, really. I mean, it's it's what we

00:09:10.904 --> 00:09:13.545
<v Speaker 1>deploy distributed software onto, and you can be

00:09:13.545 --> 00:09:16.505
<v Speaker 1>fairly, certain at this point that, anyone you

00:09:16.505 --> 00:09:18.800
<v Speaker 1>need to move, any any of your clients,

00:09:18.800 --> 00:09:21.760
<v Speaker 1>any of your collaborators will also have, Kubernetes.

00:09:22.400 --> 00:09:24.560
<v Speaker 1>Anyone else in the in the ecosystem will

00:09:24.560 --> 00:09:27.600
<v Speaker 1>have at least some Kubernetes in their, available

00:09:27.600 --> 00:09:29.920
<v Speaker 1>to them. It makes sense to, put it

00:09:29.920 --> 00:09:31.360
<v Speaker 1>on top of, Kubernetes.

00:09:31.505 --> 00:09:34.305
<v Speaker 1>So the project was started at Google. Obviously,

00:09:34.545 --> 00:09:36.625
<v Speaker 1>Kubernetes will will would be would be the

00:09:36.625 --> 00:09:37.825
<v Speaker 1>preference for

00:09:38.144 --> 00:09:39.265
<v Speaker 1>for them as well.

00:09:39.825 --> 00:09:40.385
<v Speaker 1>And,

00:09:40.865 --> 00:09:42.625
<v Speaker 1>and the Kubernetes scheduler,

00:09:42.945 --> 00:09:45.505
<v Speaker 1>is is great at at scheduling,

00:09:45.985 --> 00:09:48.840
<v Speaker 1>diverse workloads. So why not take advantage of

00:09:48.840 --> 00:09:51.000
<v Speaker 1>it? Right? So we've got the we've got

00:09:51.000 --> 00:09:52.040
<v Speaker 1>the the

00:09:52.600 --> 00:09:55.960
<v Speaker 1>environment portability sorted. We've got the scheduling

00:09:56.440 --> 00:09:57.320
<v Speaker 1>sorted,

00:09:58.280 --> 00:10:00.885
<v Speaker 1>and we've got the scaling sorted. Right? So

00:10:00.885 --> 00:10:04.405
<v Speaker 1>leveraging containers and and, that that

00:10:06.485 --> 00:10:09.365
<v Speaker 1>or, you know, that paradigm for for delivering

00:10:09.365 --> 00:10:11.125
<v Speaker 1>a scalable software.

00:10:11.125 --> 00:10:12.565
<v Speaker 1>So that's the mission. Alright?

00:10:13.300 --> 00:10:16.340
<v Speaker 1>How do we help people get their their

00:10:16.340 --> 00:10:18.980
<v Speaker 1>hard work developing machine learning models to a

00:10:18.980 --> 00:10:20.660
<v Speaker 1>place where we can,

00:10:21.700 --> 00:10:23.700
<v Speaker 1>provide a scalable and repeatable,

00:10:24.020 --> 00:10:25.700
<v Speaker 1>pathway to, production?

00:10:26.485 --> 00:10:28.405
<v Speaker 1>And maybe it makes sense to take just

00:10:28.405 --> 00:10:30.165
<v Speaker 1>one second to talk about what we mean

00:10:30.165 --> 00:10:31.365
<v Speaker 1>by production

00:10:31.605 --> 00:10:34.245
<v Speaker 1>for our machine learning model. David, would you

00:10:34.245 --> 00:10:37.045
<v Speaker 1>agree? Yeah. Go for it. Okay.

00:10:37.605 --> 00:10:41.045
<v Speaker 1>So what we mean by putting an ML

00:10:41.045 --> 00:10:41.445
<v Speaker 1>model

00:10:41.870 --> 00:10:42.910
<v Speaker 1>into production,

00:10:43.470 --> 00:10:44.190
<v Speaker 1>is,

00:10:44.430 --> 00:10:45.870
<v Speaker 1>going to sound very

00:10:47.070 --> 00:10:49.950
<v Speaker 1>simplistic probably to a lot of your, listeners,

00:10:50.190 --> 00:10:51.870
<v Speaker 1>in the sense that it's just an endpoint.

00:10:51.950 --> 00:10:54.350
<v Speaker 1>It's just a service that we can send

00:10:54.350 --> 00:10:56.830
<v Speaker 1>it some payload of information and get back

00:10:56.830 --> 00:10:59.095
<v Speaker 1>another piece of information. That's that's all we

00:10:59.095 --> 00:11:01.415
<v Speaker 1>need to do. The issue is how do

00:11:01.415 --> 00:11:03.654
<v Speaker 1>we automate as much of that process as

00:11:03.654 --> 00:11:05.735
<v Speaker 1>possible while ensuring security,

00:11:05.815 --> 00:11:06.695
<v Speaker 1>isolation,

00:11:07.495 --> 00:11:09.654
<v Speaker 1>and so on. Does that make sense? I

00:11:09.654 --> 00:11:11.015
<v Speaker 0>do. Yeah. Yeah. That's so so.

00:11:11.720 --> 00:11:13.080
<v Speaker 1>An ML model at the end of the

00:11:13.080 --> 00:11:14.680
<v Speaker 1>day is just a is just a formula.

00:11:14.680 --> 00:11:16.920
<v Speaker 1>It says, you give me, you know, the

00:11:16.920 --> 00:11:19.000
<v Speaker 1>the pieces of information that I need, and

00:11:19.000 --> 00:11:21.240
<v Speaker 1>I will give you back a guess. Could

00:11:21.240 --> 00:11:23.640
<v Speaker 1>be a guess about is the,

00:11:24.120 --> 00:11:25.880
<v Speaker 1>are we coming up to a stoplight? If

00:11:25.880 --> 00:11:28.015
<v Speaker 1>you're a self driving car, could be, does

00:11:28.015 --> 00:11:30.495
<v Speaker 1>this person have a a medical condition, which

00:11:30.495 --> 00:11:32.015
<v Speaker 1>is the example we'll be looking at.

00:11:33.455 --> 00:11:34.095
<v Speaker 1>So

00:11:34.415 --> 00:11:36.095
<v Speaker 1>why Kubeflow? What was sort of the the

00:11:36.095 --> 00:11:38.975
<v Speaker 1>genesis of of the reason you know, the

00:11:38.975 --> 00:11:41.320
<v Speaker 1>genesis behind it? There are a lot of

00:11:41.320 --> 00:11:43.320
<v Speaker 1>tools that that can help in

00:11:44.280 --> 00:11:45.800
<v Speaker 1>cloud native workflows.

00:11:46.280 --> 00:11:49.480
<v Speaker 1>And the issue is that there's not really

00:11:49.480 --> 00:11:51.160
<v Speaker 1>a a good way to stitch them all

00:11:51.160 --> 00:11:53.985
<v Speaker 1>together. So you can think of Kubeflow as

00:11:53.985 --> 00:11:55.985
<v Speaker 1>an open ecosystem where you can put in

00:11:55.985 --> 00:11:57.584
<v Speaker 1>the tools you want, take out the tools

00:11:57.584 --> 00:11:59.985
<v Speaker 1>you don't, but you're guaranteed a degree of

00:11:59.985 --> 00:12:03.105
<v Speaker 1>interoperability between all of the all of the

00:12:03.185 --> 00:12:04.545
<v Speaker 1>tools, and the base

00:12:04.865 --> 00:12:07.490
<v Speaker 1>set of tools will always

00:12:07.650 --> 00:12:11.090
<v Speaker 1>work together and cover really most use cases.

00:12:13.490 --> 00:12:15.010
<v Speaker 1>Any questions on that?

00:12:15.890 --> 00:12:17.970
<v Speaker 1>Make sense? Yeah. I think I'm I'm still

00:12:17.970 --> 00:12:19.650
<v Speaker 0>with you. You have not lost me yet.

00:12:20.130 --> 00:12:20.850
<v Speaker 1>Okay. Good.

00:12:22.265 --> 00:12:25.385
<v Speaker 1>And the this is from the the Kubeflow1.0

00:12:25.385 --> 00:12:26.425
<v Speaker 1>user survey

00:12:26.584 --> 00:12:28.745
<v Speaker 1>from last year. The the newest one, the

00:12:28.745 --> 00:12:31.225
<v Speaker 1>2021 version, will be coming out very shortly.

00:12:32.185 --> 00:12:33.945
<v Speaker 1>Some of the issues around

00:12:34.584 --> 00:12:35.945
<v Speaker 1>getting a model to production

00:12:36.810 --> 00:12:39.450
<v Speaker 1>are, of course, the bottlenecks associated with, you

00:12:39.450 --> 00:12:41.690
<v Speaker 1>know, finding, you know, the right operations people

00:12:41.690 --> 00:12:43.930
<v Speaker 1>who can take the the data scientist work

00:12:43.930 --> 00:12:46.090
<v Speaker 1>output and then deploy it to production. But

00:12:46.090 --> 00:12:47.690
<v Speaker 1>there's lots of other stuff too. You know?

00:12:47.690 --> 00:12:48.810
<v Speaker 1>Machine

00:12:49.610 --> 00:12:53.345
<v Speaker 1>learning models are being used to enhance decision

00:12:53.345 --> 00:12:55.345
<v Speaker 1>processes, some of which may have legal or

00:12:55.345 --> 00:12:58.785
<v Speaker 1>compliance implications. Making a loan decision, for example,

00:12:59.105 --> 00:13:00.785
<v Speaker 1>would be one of those. Making a hiring

00:13:00.785 --> 00:13:02.545
<v Speaker 1>decision would be would be another.

00:13:03.105 --> 00:13:05.505
<v Speaker 1>And so the more automation that we can

00:13:05.505 --> 00:13:08.465
<v Speaker 1>get around documenting

00:13:07.290 --> 00:13:09.370
<v Speaker 1>what the model is doing, why why it

00:13:09.370 --> 00:13:11.610
<v Speaker 1>was it it produced a a certain thing

00:13:11.610 --> 00:13:13.290
<v Speaker 1>and bringing that cost down

00:13:13.850 --> 00:13:15.930
<v Speaker 1>as well as time is

00:13:16.089 --> 00:13:19.050
<v Speaker 1>is of great value because there's lots more

00:13:19.050 --> 00:13:19.930
<v Speaker 1>models that

00:13:20.585 --> 00:13:23.385
<v Speaker 1>folks want to put in into production, and

00:13:23.385 --> 00:13:25.865
<v Speaker 1>90% of them never get there. I saw

00:13:25.865 --> 00:13:28.025
<v Speaker 1>a statistic fairly recently that said

00:13:28.825 --> 00:13:32.105
<v Speaker 1>that for the average American bank, it's over

00:13:32.105 --> 00:13:34.105
<v Speaker 1>half a million dollars just in compliance cost

00:13:34.105 --> 00:13:36.350
<v Speaker 1>to get a model into production. So Yeah.

00:13:36.430 --> 00:13:40.190
<v Speaker 1>Lots of, yeah, lots of lots of headache

00:13:40.190 --> 00:13:41.230
<v Speaker 1>and costs there.

00:13:42.269 --> 00:13:44.270
<v Speaker 1>And, you know, the general

00:13:44.430 --> 00:13:45.870
<v Speaker 1>practice is

00:13:46.190 --> 00:13:48.910
<v Speaker 1>that it takes, you know, a good six

00:13:48.910 --> 00:13:51.095
<v Speaker 1>to nine months to get a model production.

00:13:51.175 --> 00:13:51.735
<v Speaker 1>And

00:13:52.295 --> 00:13:53.255
<v Speaker 1>for example,

00:13:53.575 --> 00:13:54.774
<v Speaker 1>if you're if you're

00:13:55.495 --> 00:13:58.055
<v Speaker 1>let's pick us an example. If you're a,

00:13:58.535 --> 00:14:00.615
<v Speaker 1>oh, I don't know, a streaming video player

00:14:00.774 --> 00:14:01.975
<v Speaker 1>and content producer,

00:14:03.029 --> 00:14:03.430
<v Speaker 1>A

00:14:03.830 --> 00:14:05.990
<v Speaker 1>I certainly remember when Tiger King was all

00:14:05.990 --> 00:14:08.310
<v Speaker 1>the rage. It is no longer the rage.

00:14:08.310 --> 00:14:10.150
<v Speaker 1>So if I'm developing a

00:14:10.630 --> 00:14:11.110
<v Speaker 1>recommendation

00:14:12.230 --> 00:14:16.070
<v Speaker 1>engine using machine learning that helps

00:14:15.574 --> 00:14:17.735
<v Speaker 1>viewers identify other shows that they might like

00:14:17.735 --> 00:14:19.334
<v Speaker 1>to watch, other programming they might like to

00:14:19.334 --> 00:14:19.894
<v Speaker 1>watch.

00:14:20.855 --> 00:14:22.935
<v Speaker 1>It doesn't help me very much if my

00:14:22.935 --> 00:14:23.574
<v Speaker 1>model

00:14:23.975 --> 00:14:26.214
<v Speaker 1>that was trained six months ago gets, you

00:14:26.214 --> 00:14:27.894
<v Speaker 1>know, deployed after

00:14:27.894 --> 00:14:30.380
<v Speaker 1>everything is after that data is stale. Right?

00:14:30.380 --> 00:14:32.380
<v Speaker 1>So there's a notion of currency in machine

00:14:32.380 --> 00:14:35.660
<v Speaker 1>learning models that doesn't exist beside you know,

00:14:35.660 --> 00:14:38.700
<v Speaker 1>outside of revving libraries and other other stuff,

00:14:38.860 --> 00:14:40.940
<v Speaker 1>for for software development,

00:14:41.180 --> 00:14:41.740
<v Speaker 1>more broadly.

00:14:43.295 --> 00:14:45.295
<v Speaker 1>The data needs to be needs to be

00:14:45.295 --> 00:14:46.975
<v Speaker 1>current. There's a a declining,

00:14:47.295 --> 00:14:49.695
<v Speaker 1>there's a declining return to the value of

00:14:49.695 --> 00:14:50.335
<v Speaker 1>data,

00:14:50.654 --> 00:14:52.495
<v Speaker 1>as, as time goes on.

00:14:54.015 --> 00:14:55.935
<v Speaker 1>So what's in the box?

00:14:56.255 --> 00:14:57.855
<v Speaker 1>You're welcome for not including the meme.

00:15:00.170 --> 00:15:01.530
<v Speaker 1>As I mentioned before,

00:15:02.010 --> 00:15:04.730
<v Speaker 1>Kubeflow has a ton of different stuff in

00:15:04.730 --> 00:15:05.210
<v Speaker 1>it.

00:15:06.330 --> 00:15:07.610
<v Speaker 1>The the

00:15:08.250 --> 00:15:11.210
<v Speaker 1>data scientist or machine learning engineer or data

00:15:11.210 --> 00:15:11.930
<v Speaker 1>engineer

00:15:12.425 --> 00:15:14.745
<v Speaker 1>will be familiar with certain

00:15:15.865 --> 00:15:16.904
<v Speaker 1>frameworks.

00:15:17.545 --> 00:15:19.064
<v Speaker 1>Excuse me. TensorFlow,

00:15:19.064 --> 00:15:19.865
<v Speaker 1>PyTorch,

00:15:19.865 --> 00:15:20.904
<v Speaker 1>MXNet.

00:15:21.144 --> 00:15:23.384
<v Speaker 1>Those will be those will be familiar. They,

00:15:23.384 --> 00:15:26.024
<v Speaker 1>of course, also have their fans and detractors

00:15:26.024 --> 00:15:28.690
<v Speaker 1>and their lineage. PyTorch was developed by,

00:15:29.170 --> 00:15:31.250
<v Speaker 1>came out of Facebook. If I'm not mistaken,

00:15:31.250 --> 00:15:34.850
<v Speaker 1>TensorFlow is from Google. MXNet is is developed

00:15:34.850 --> 00:15:36.050
<v Speaker 1>and promoted by,

00:15:36.290 --> 00:15:38.210
<v Speaker 1>AWS as an example.

00:15:38.850 --> 00:15:40.450
<v Speaker 1>But they're all they're all open source. And

00:15:40.450 --> 00:15:41.650
<v Speaker 1>so this you can think of the top

00:15:41.650 --> 00:15:43.965
<v Speaker 1>of this diagram here as as the interaction

00:15:43.965 --> 00:15:45.805
<v Speaker 1>with the the end user will interact with

00:15:45.805 --> 00:15:47.245
<v Speaker 1>with these libraries

00:15:47.325 --> 00:15:48.125
<v Speaker 1>via

00:15:48.285 --> 00:15:49.965
<v Speaker 1>some containerized

00:15:49.965 --> 00:15:50.845
<v Speaker 1>environment.

00:15:50.925 --> 00:15:53.645
<v Speaker 1>It could be a Jupyter Notebook as an

00:15:53.645 --> 00:15:56.925
<v Speaker 1>example. It could be a Versus Code. It

00:15:56.925 --> 00:15:58.205
<v Speaker 1>could be RStudio.

00:15:58.980 --> 00:16:02.339
<v Speaker 1>Lots of different ways to to interact with

00:16:02.339 --> 00:16:03.540
<v Speaker 1>the software

00:16:03.700 --> 00:16:05.940
<v Speaker 1>with the software stack proper.

00:16:06.339 --> 00:16:09.220
<v Speaker 1>And the beauty of containers is that not

00:16:09.220 --> 00:16:10.740
<v Speaker 1>only they they come up very quickly,

00:16:11.635 --> 00:16:13.875
<v Speaker 1>but also that, you know, we can standardize

00:16:13.875 --> 00:16:15.714
<v Speaker 1>on a set of common libraries. And then

00:16:15.714 --> 00:16:17.395
<v Speaker 1>as we need to make adjustments, of course,

00:16:17.395 --> 00:16:18.675
<v Speaker 1>layer on top of them.

00:16:19.795 --> 00:16:22.835
<v Speaker 1>Under the covers, what we're what we're also

00:16:22.835 --> 00:16:25.714
<v Speaker 1>delivering as part of Kubeflow is a set

00:16:25.714 --> 00:16:26.275
<v Speaker 1>of

00:16:26.779 --> 00:16:29.500
<v Speaker 1>operators that relate. I'll focus down here to

00:16:29.500 --> 00:16:32.379
<v Speaker 1>start. A set of operators that relate to

00:16:32.379 --> 00:16:33.019
<v Speaker 1>the

00:16:33.660 --> 00:16:34.699
<v Speaker 1>specific

00:16:35.980 --> 00:16:37.500
<v Speaker 1>machine learning libraries.

00:16:37.500 --> 00:16:40.379
<v Speaker 1>So what let's take TF job operator as

00:16:40.379 --> 00:16:42.715
<v Speaker 1>an example. So one of the the

00:16:42.955 --> 00:16:45.834
<v Speaker 1>great advantages of distributed computing is that,

00:16:46.235 --> 00:16:48.235
<v Speaker 1>things that would take forever on a single

00:16:48.235 --> 00:16:51.515
<v Speaker 1>machine take longer when we're able to effectively

00:16:51.515 --> 00:16:53.274
<v Speaker 1>chunk up that work and distribute it among

00:16:53.274 --> 00:16:55.810
<v Speaker 1>many machines. Right? The we can't make the

00:16:55.810 --> 00:16:58.290
<v Speaker 1>computers any bigger nor would we necessarily,

00:16:58.610 --> 00:16:59.490
<v Speaker 1>want to.

00:17:00.050 --> 00:17:00.930
<v Speaker 1>And there,

00:17:01.170 --> 00:17:01.730
<v Speaker 1>to,

00:17:02.290 --> 00:17:04.609
<v Speaker 1>Waleed's point, thanks for the the comment.

00:17:05.089 --> 00:17:06.769
<v Speaker 1>There are actually quite a few more,

00:17:07.170 --> 00:17:09.410
<v Speaker 1>that are are very close to being

00:17:10.905 --> 00:17:13.385
<v Speaker 1>ready for prime time. So stay tuned. If

00:17:13.385 --> 00:17:14.505
<v Speaker 1>you're interested in that,

00:17:15.305 --> 00:17:17.304
<v Speaker 1>definitely definitely check that out.

00:17:18.825 --> 00:17:21.305
<v Speaker 1>But how how do these what are these

00:17:21.305 --> 00:17:23.945
<v Speaker 1>operators? Well, to quote my my dear friend

00:17:23.945 --> 00:17:26.529
<v Speaker 1>Jared Dillon, an operator is just a piece

00:17:26.529 --> 00:17:29.009
<v Speaker 1>of software, deployed with its own runbook for

00:17:29.009 --> 00:17:30.609
<v Speaker 1>for managing that software.

00:17:31.169 --> 00:17:33.490
<v Speaker 1>In other words, a custom scheduler, you could

00:17:33.490 --> 00:17:34.769
<v Speaker 1>think of it that way in some ways

00:17:34.769 --> 00:17:37.009
<v Speaker 1>for for these operators that you have here.

00:17:37.615 --> 00:17:39.215
<v Speaker 1>And so what we're able to do is

00:17:39.215 --> 00:17:41.294
<v Speaker 1>take our standard our standard code that we

00:17:41.294 --> 00:17:42.575
<v Speaker 1>would use TensorFlow

00:17:42.575 --> 00:17:45.695
<v Speaker 1>or something like that and very effectively using

00:17:45.695 --> 00:17:46.254
<v Speaker 1>the

00:17:46.575 --> 00:17:48.734
<v Speaker 1>operator along with the Kubernetes

00:17:49.135 --> 00:17:50.894
<v Speaker 1>API, Kubernetes scheduler,

00:17:51.520 --> 00:17:54.399
<v Speaker 1>distribute that across all of our resources. So

00:17:54.480 --> 00:17:55.279
<v Speaker 1>if

00:17:55.520 --> 00:17:57.600
<v Speaker 1>if you're if you're doing

00:17:58.400 --> 00:18:01.040
<v Speaker 1>machine learning on on on huge

00:18:01.040 --> 00:18:02.159
<v Speaker 1>amounts of data,

00:18:02.400 --> 00:18:04.735
<v Speaker 1>you can take something that would take a

00:18:04.735 --> 00:18:06.575
<v Speaker 1>a week to train on a single machine.

00:18:06.575 --> 00:18:08.255
<v Speaker 1>You can bring it down to half an

00:18:08.255 --> 00:18:10.415
<v Speaker 1>hour. Right? Just depends on the resources that

00:18:10.415 --> 00:18:11.695
<v Speaker 1>you have available to you.

00:18:12.015 --> 00:18:14.335
<v Speaker 1>So that's that's really where we see some

00:18:14.335 --> 00:18:16.015
<v Speaker 1>of the the efficiencies,

00:18:16.335 --> 00:18:17.990
<v Speaker 1>for folks and and one of the most

00:18:17.990 --> 00:18:18.950
<v Speaker 1>exciting elements,

00:18:19.190 --> 00:18:19.989
<v Speaker 1>of the,

00:18:20.630 --> 00:18:21.989
<v Speaker 1>of the software stack.

00:18:22.549 --> 00:18:23.830
<v Speaker 1>We have a a,

00:18:24.070 --> 00:18:24.630
<v Speaker 1>Jupyter

00:18:25.110 --> 00:18:26.870
<v Speaker 1>it's it's a little bit of a misnomer.

00:18:26.870 --> 00:18:28.710
<v Speaker 1>I think they're actually the notebooks working group

00:18:28.710 --> 00:18:30.630
<v Speaker 1>is contemplating changing the the name of it,

00:18:30.630 --> 00:18:34.534
<v Speaker 1>but essentially a a notebook or coding environment,

00:18:34.775 --> 00:18:36.455
<v Speaker 1>web app, and controller. We'll see that in

00:18:36.455 --> 00:18:38.934
<v Speaker 1>a second. It's all self-service,

00:18:39.255 --> 00:18:40.455
<v Speaker 1>and supports,

00:18:40.695 --> 00:18:43.975
<v Speaker 1>in you know, securely injecting secrets into the

00:18:43.975 --> 00:18:45.895
<v Speaker 1>environment so you don't have plain text secrets

00:18:45.895 --> 00:18:46.455
<v Speaker 1>floating around.

00:18:47.810 --> 00:18:49.090
<v Speaker 1>Resource dependencies,

00:18:49.090 --> 00:18:51.410
<v Speaker 1>you know, does this does this coding environment

00:18:51.410 --> 00:18:53.410
<v Speaker 1>need to be need to have access to

00:18:53.410 --> 00:18:55.409
<v Speaker 1>a GPU or some kind of special

00:18:56.290 --> 00:18:58.610
<v Speaker 1>resource, some extended resource in Kubernetes,

00:18:58.690 --> 00:18:59.090
<v Speaker 1>etcetera.

00:19:00.375 --> 00:19:01.415
<v Speaker 1>We also

00:19:01.575 --> 00:19:05.175
<v Speaker 1>have quite a few attendant core services that

00:19:05.175 --> 00:19:05.815
<v Speaker 1>are

00:19:05.975 --> 00:19:06.935
<v Speaker 1>necessary

00:19:06.935 --> 00:19:10.215
<v Speaker 1>for productionizing machine workload machine learning workloads.

00:19:10.295 --> 00:19:11.335
<v Speaker 1>Pipelines, for example,

00:19:12.570 --> 00:19:14.490
<v Speaker 1>folks may be familiar with tools such as

00:19:14.490 --> 00:19:15.450
<v Speaker 1>Airflow

00:19:16.090 --> 00:19:18.249
<v Speaker 1>or others that that provide

00:19:19.530 --> 00:19:23.690
<v Speaker 1>directed acyclical graphs, DAGs as they're known, functionality

00:19:23.770 --> 00:19:27.664
<v Speaker 1>so that we can have retry logic, branching,

00:19:27.664 --> 00:19:29.825
<v Speaker 1>all of that kind of stuff. Kubeflow Pipelines

00:19:29.825 --> 00:19:31.984
<v Speaker 1>is built on top of

00:19:32.705 --> 00:19:34.384
<v Speaker 1>Argo, you can see here,

00:19:35.265 --> 00:19:38.225
<v Speaker 1>and interacts natively. So so the the the

00:19:38.225 --> 00:19:40.720
<v Speaker 1>beauty of of the system working together is

00:19:40.720 --> 00:19:42.160
<v Speaker 1>that all of these bits and pieces know

00:19:42.160 --> 00:19:43.680
<v Speaker 1>how to talk to each other. There's a

00:19:43.680 --> 00:19:46.960
<v Speaker 1>metadata store. So what did we do? There's,

00:19:47.280 --> 00:19:49.520
<v Speaker 1>a Kubeflow serving, which is built on top

00:19:49.520 --> 00:19:50.320
<v Speaker 1>of Knative

00:19:52.264 --> 00:19:54.024
<v Speaker 1>that provides

00:19:54.024 --> 00:19:56.345
<v Speaker 1>the ability to publish a model as an

00:19:56.345 --> 00:19:58.184
<v Speaker 1>endpoint. Right? So you you know, if I'm

00:19:58.184 --> 00:19:59.945
<v Speaker 1>a data scientist, I I don't really know

00:19:59.945 --> 00:20:02.264
<v Speaker 1>that much about, you know, operations.

00:20:02.264 --> 00:20:04.105
<v Speaker 1>I don't know really anything about Kubernetes,

00:20:04.510 --> 00:20:07.230
<v Speaker 1>perhaps. And I still wanna be able to

00:20:07.230 --> 00:20:09.549
<v Speaker 1>start doing model deployments

00:20:09.950 --> 00:20:12.590
<v Speaker 1>in a in a safe way. And so

00:20:12.590 --> 00:20:15.470
<v Speaker 1>Kubeflow serving is built on top of Knative,

00:20:15.470 --> 00:20:16.830
<v Speaker 1>as I mentioned, and leverages

00:20:17.395 --> 00:20:18.434
<v Speaker 1>Istio's

00:20:18.434 --> 00:20:21.155
<v Speaker 1>ability to segment traffic as well as do

00:20:21.155 --> 00:20:23.475
<v Speaker 1>things like canary deployments, blue green, all of

00:20:23.475 --> 00:20:25.075
<v Speaker 1>that kind of stuff. So if there's any

00:20:25.075 --> 00:20:26.755
<v Speaker 1>language here that I'm using that that, you

00:20:26.755 --> 00:20:28.035
<v Speaker 1>know, you think folks might not be familiar

00:20:28.035 --> 00:20:29.715
<v Speaker 1>with, I'm happy to happy to dive into

00:20:29.715 --> 00:20:29.795
<v Speaker 1>it.

00:20:30.520 --> 00:20:32.200
<v Speaker 1>And then lastly, and this is super exciting

00:20:32.200 --> 00:20:35.160
<v Speaker 1>also, automated hyperparameter tuning. So we're gonna get

00:20:35.160 --> 00:20:35.879
<v Speaker 1>into this

00:20:36.360 --> 00:20:38.600
<v Speaker 1>a little bit later on, but but and

00:20:38.600 --> 00:20:40.680
<v Speaker 1>I I don't like the the analogy, but

00:20:40.680 --> 00:20:41.800
<v Speaker 1>this it is a bit

00:20:43.000 --> 00:20:45.240
<v Speaker 1>this is sort of where the I I

00:20:45.320 --> 00:20:48.225
<v Speaker 1>the art of machine learning and data scientist

00:20:48.384 --> 00:20:51.104
<v Speaker 1>science comes in as opposed to the science.

00:20:52.144 --> 00:20:53.745
<v Speaker 1>I don't think those things really I don't

00:20:53.745 --> 00:20:55.745
<v Speaker 1>think art and science necessarily sit on opposite

00:20:55.745 --> 00:20:57.904
<v Speaker 1>ends of a of a spectrum. I don't

00:20:57.904 --> 00:20:59.825
<v Speaker 1>think they necessarily oppose one another, but

00:21:00.410 --> 00:21:02.330
<v Speaker 1>this is where there is

00:21:03.450 --> 00:21:04.809
<v Speaker 1>a certain amount of of

00:21:05.049 --> 00:21:06.410
<v Speaker 1>finesse that you need to be able to

00:21:06.410 --> 00:21:09.289
<v Speaker 1>read as a human that the the actual

00:21:09.289 --> 00:21:12.250
<v Speaker 1>training operation isn't gonna provide you. So that's

00:21:12.250 --> 00:21:15.370
<v Speaker 1>where that's where an experienced

00:21:14.565 --> 00:21:17.365
<v Speaker 1>data scientist or machine learning engineer will will

00:21:17.365 --> 00:21:19.605
<v Speaker 1>have an advantage, and and Kotib helps automate

00:21:19.605 --> 00:21:21.844
<v Speaker 1>the workflow for for picking those choices.

00:21:24.325 --> 00:21:26.404
<v Speaker 1>If we look just to for folks who

00:21:26.404 --> 00:21:27.845
<v Speaker 1>may not be familiar with what an ML

00:21:27.845 --> 00:21:29.684
<v Speaker 1>workflow actually looks like generally,

00:21:30.130 --> 00:21:31.090
<v Speaker 1>we

00:21:31.090 --> 00:21:33.010
<v Speaker 1>we can segment these. These are all these

00:21:33.010 --> 00:21:34.929
<v Speaker 1>diagrams are all available on kubeflow.org,

00:21:34.929 --> 00:21:37.010
<v Speaker 1>by the way. So that's the the source

00:21:37.010 --> 00:21:39.010
<v Speaker 1>for them. We can segment it into into

00:21:39.010 --> 00:21:41.250
<v Speaker 1>two phases. The first would be an experimental

00:21:41.250 --> 00:21:41.970
<v Speaker 1>phase,

00:21:42.130 --> 00:21:43.730
<v Speaker 1>which is identifying

00:21:43.730 --> 00:21:45.805
<v Speaker 1>what you're trying to do, identifying the problem,

00:21:45.805 --> 00:21:48.445
<v Speaker 1>and then collecting and analyzing the data.

00:21:49.085 --> 00:21:51.725
<v Speaker 1>Excluded from this is the the bulk of

00:21:51.725 --> 00:21:54.044
<v Speaker 1>the of of the time.

00:21:54.445 --> 00:21:56.445
<v Speaker 1>You know, I've I've had to explain to

00:21:56.445 --> 00:21:57.725
<v Speaker 1>family members and others

00:21:58.550 --> 00:21:59.350
<v Speaker 1>that

00:21:59.830 --> 00:22:00.789
<v Speaker 1>programming,

00:22:00.870 --> 00:22:02.550
<v Speaker 1>you spend, you know, 95%

00:22:02.550 --> 00:22:04.230
<v Speaker 1>of your time stuck. Most of the time,

00:22:04.230 --> 00:22:05.830
<v Speaker 1>we're not trying to reinvent the wheel. We

00:22:05.830 --> 00:22:08.389
<v Speaker 1>don't have to develop some fun new algorithm.

00:22:08.950 --> 00:22:10.710
<v Speaker 1>Something we think should be working is not

00:22:10.710 --> 00:22:12.390
<v Speaker 1>working, and we're spending time debugging that.

00:22:13.395 --> 00:22:15.475
<v Speaker 1>In so let's call that a

00:22:17.235 --> 00:22:21.555
<v Speaker 1>one to to 19 ratio, right, of time

00:22:21.555 --> 00:22:24.515
<v Speaker 1>productively plowing ahead with our project and time

00:22:25.040 --> 00:22:26.559
<v Speaker 1>trying to find an answer to what's not

00:22:26.559 --> 00:22:27.119
<v Speaker 1>working,

00:22:27.760 --> 00:22:29.600
<v Speaker 1>at least at least if you're a a

00:22:29.600 --> 00:22:31.519
<v Speaker 1>programmer at at my skill level.

00:22:31.760 --> 00:22:32.399
<v Speaker 1>In

00:22:33.360 --> 00:22:35.280
<v Speaker 1>data science, it's it's worse. It's probably, like,

00:22:35.280 --> 00:22:37.600
<v Speaker 1>99 to one or or one to 99

00:22:37.600 --> 00:22:39.040
<v Speaker 1>ratio because

00:22:39.040 --> 00:22:40.000
<v Speaker 1>cleaning the data,

00:22:41.495 --> 00:22:44.455
<v Speaker 1>amalgamating the data, coalescing the data, getting access

00:22:44.455 --> 00:22:45.335
<v Speaker 1>to the data,

00:22:45.735 --> 00:22:47.735
<v Speaker 1>eats up a a huge a huge huge

00:22:47.735 --> 00:22:48.695
<v Speaker 1>amount of time.

00:22:49.575 --> 00:22:51.255
<v Speaker 1>So, you know, anything that we can do

00:22:51.414 --> 00:22:53.095
<v Speaker 1>and and that's a that's a hard problem.

00:22:53.095 --> 00:22:55.220
<v Speaker 1>There's not, you know, there's not a ton

00:22:55.220 --> 00:22:56.660
<v Speaker 1>outside of, you know,

00:22:57.060 --> 00:22:59.300
<v Speaker 1>bringing in more humans to help with that

00:22:59.300 --> 00:23:01.060
<v Speaker 1>that that we can do. After all, if

00:23:01.060 --> 00:23:02.420
<v Speaker 1>you had the ability to,

00:23:03.220 --> 00:23:05.620
<v Speaker 1>make decisions about your data, then your job

00:23:05.620 --> 00:23:07.140
<v Speaker 1>would be done. That's that's kind of the

00:23:07.140 --> 00:23:07.860
<v Speaker 1>the point. Right?

00:23:09.375 --> 00:23:12.174
<v Speaker 1>So so we really wanna speed this up.

00:23:12.815 --> 00:23:14.175
<v Speaker 1>Then, you know, you need to code your

00:23:14.175 --> 00:23:16.895
<v Speaker 1>model, pick, pick, how you want the the

00:23:16.895 --> 00:23:18.655
<v Speaker 1>structure of the model to work. You need

00:23:18.655 --> 00:23:20.335
<v Speaker 1>to see, you know, what kind of results

00:23:20.335 --> 00:23:22.335
<v Speaker 1>you get. That's a sort of experimentation.

00:23:22.590 --> 00:23:25.150
<v Speaker 1>You need to tune that, the hyperparameters,

00:23:25.150 --> 00:23:26.830
<v Speaker 1>which we'll talk about in a second. Then

00:23:26.830 --> 00:23:28.269
<v Speaker 1>you need to do this whole thing again.

00:23:28.429 --> 00:23:29.789
<v Speaker 1>When it comes to production,

00:23:30.510 --> 00:23:33.070
<v Speaker 1>it's a similar set of steps, but but

00:23:33.070 --> 00:23:35.070
<v Speaker 1>a little bit different. So we've we've coded,

00:23:36.955 --> 00:23:39.995
<v Speaker 1>excuse me, a mechanism for transforming the data

00:23:39.995 --> 00:23:42.634
<v Speaker 1>into there's a sort of industry standard term

00:23:42.634 --> 00:23:43.115
<v Speaker 1>that,

00:23:43.595 --> 00:23:45.274
<v Speaker 1>for folks, watching.

00:23:45.355 --> 00:23:46.474
<v Speaker 1>If you're ever,

00:23:46.955 --> 00:23:48.394
<v Speaker 1>you know, if you ever wanna be the

00:23:48.394 --> 00:23:50.890
<v Speaker 1>person who, like, sounds, like, really educated, just,

00:23:50.890 --> 00:23:52.330
<v Speaker 1>you know, refer to what's known as a

00:23:52.330 --> 00:23:53.850
<v Speaker 1>model ready data frame.

00:23:54.250 --> 00:23:56.490
<v Speaker 1>You need to get the data into

00:23:56.650 --> 00:23:57.850
<v Speaker 1>a a,

00:23:58.730 --> 00:23:59.289
<v Speaker 1>state,

00:23:59.530 --> 00:24:01.530
<v Speaker 1>into a format, into a form that the

00:24:01.530 --> 00:24:03.530
<v Speaker 1>model can understand. You tell the model, this

00:24:03.530 --> 00:24:04.970
<v Speaker 1>is what you should expect in terms of

00:24:04.970 --> 00:24:05.985
<v Speaker 1>data coming in.

00:24:07.105 --> 00:24:09.105
<v Speaker 1>So there's there's that. We'd like to automate

00:24:09.105 --> 00:24:11.105
<v Speaker 1>that. That's that's where the notion of having

00:24:11.105 --> 00:24:13.345
<v Speaker 1>a pipeline really makes a big difference. Then

00:24:13.345 --> 00:24:14.865
<v Speaker 1>we have to train the model. We have

00:24:14.865 --> 00:24:16.865
<v Speaker 1>to we'll we'll show that in a second.

00:24:17.345 --> 00:24:19.505
<v Speaker 1>And then we have to actually serve the

00:24:19.505 --> 00:24:21.130
<v Speaker 1>model. We have to deploy it in some

00:24:21.130 --> 00:24:23.850
<v Speaker 1>in some way that, we can see what

00:24:23.850 --> 00:24:26.170
<v Speaker 1>the we can have other microservices or other

00:24:26.170 --> 00:24:28.090
<v Speaker 1>services in our environment speak to the model.

00:24:28.090 --> 00:24:30.330
<v Speaker 1>Ask the model a question. Say, hey.

00:24:30.650 --> 00:24:31.450
<v Speaker 1>I've got,

00:24:31.770 --> 00:24:35.370
<v Speaker 1>I've got, Dave over here. He's, he's his

00:24:35.370 --> 00:24:37.905
<v Speaker 1>last five shows that he watched were x

00:24:37.905 --> 00:24:39.424
<v Speaker 1>y z a b c.

00:24:39.825 --> 00:24:41.345
<v Speaker 1>I guess that would be six shows.

00:24:41.585 --> 00:24:42.144
<v Speaker 1>And

00:24:42.705 --> 00:24:44.385
<v Speaker 1>and tell me what I what I should

00:24:44.385 --> 00:24:45.825
<v Speaker 1>recommend to him next.

00:24:47.025 --> 00:24:49.745
<v Speaker 1>And then over time, as as more and

00:24:49.745 --> 00:24:50.624
<v Speaker 1>more people,

00:24:50.785 --> 00:24:53.184
<v Speaker 1>you know, choose not to watch

00:24:54.120 --> 00:24:56.679
<v Speaker 1>Tiger King or choose not to watch don't

00:24:56.679 --> 00:24:58.440
<v Speaker 1>don't pick up on those recommendations,

00:24:58.519 --> 00:25:00.679
<v Speaker 1>the model is performing worse. Right? Like, that

00:25:00.679 --> 00:25:02.760
<v Speaker 1>that ship has sailed. So there is a

00:25:02.760 --> 00:25:04.600
<v Speaker 1>a process by which we must

00:25:05.065 --> 00:25:08.025
<v Speaker 1>update, monitor the quality of the the model's

00:25:08.025 --> 00:25:09.785
<v Speaker 1>output, and then update it on a on

00:25:09.785 --> 00:25:11.625
<v Speaker 1>a regular cadence. And indeed,

00:25:12.185 --> 00:25:15.145
<v Speaker 1>there's lots of exciting work going on and

00:25:15.145 --> 00:25:18.185
<v Speaker 1>some organizations that are indeed using continuous learning,

00:25:18.185 --> 00:25:21.049
<v Speaker 1>what's known as continuous learning in production.

00:25:22.970 --> 00:25:24.809
<v Speaker 1>So just to to,

00:25:25.610 --> 00:25:28.090
<v Speaker 1>you know, hammer the point home, these are

00:25:28.090 --> 00:25:29.370
<v Speaker 1>the the

00:25:30.330 --> 00:25:32.970
<v Speaker 1>these are the the Kubeflow components that map

00:25:32.970 --> 00:25:35.130
<v Speaker 1>to the different the different stages. You'll notice

00:25:35.130 --> 00:25:37.075
<v Speaker 1>the the data cleansing problem,

00:25:37.635 --> 00:25:39.315
<v Speaker 1>and data collection

00:25:39.315 --> 00:25:41.794
<v Speaker 1>problem is, is left untouched.

00:25:42.515 --> 00:25:43.154
<v Speaker 1>Oftentimes,

00:25:43.395 --> 00:25:44.995
<v Speaker 1>in the wild for folks who might be

00:25:44.995 --> 00:25:46.914
<v Speaker 1>interested, you'll see the the,

00:25:47.955 --> 00:25:49.635
<v Speaker 1>what we used to call the smack stack,

00:25:50.090 --> 00:25:51.690
<v Speaker 1>but now I guess it'd be the stack

00:25:51.690 --> 00:25:52.490
<v Speaker 1>stack

00:25:53.290 --> 00:25:55.130
<v Speaker 1>with Kubernetes. Is that amazing?

00:25:55.450 --> 00:25:57.130
<v Speaker 1>But Kafka, Cassandra,

00:25:57.290 --> 00:25:58.169
<v Speaker 1>Spark,

00:25:58.170 --> 00:26:00.730
<v Speaker 1>you know, these types of of tools,

00:26:00.890 --> 00:26:02.010
<v Speaker 1>streaming or batch

00:26:02.415 --> 00:26:04.495
<v Speaker 1>to be able to to ingest

00:26:04.575 --> 00:26:06.015
<v Speaker 1>large amounts of data,

00:26:06.575 --> 00:26:08.735
<v Speaker 1>and then we can pass it into a

00:26:08.815 --> 00:26:11.455
<v Speaker 1>into a process for for transforming it.

00:26:13.295 --> 00:26:16.175
<v Speaker 1>At the production level, you'll notice that pipeline

00:26:16.175 --> 00:26:18.290
<v Speaker 1>span all of this. Right? We would have

00:26:18.290 --> 00:26:19.890
<v Speaker 1>in our pipeline a a

00:26:20.210 --> 00:26:22.450
<v Speaker 1>could even have a transformed data step.

00:26:22.930 --> 00:26:25.330
<v Speaker 1>We even have a a train model step.

00:26:25.330 --> 00:26:26.930
<v Speaker 1>We would have a serving step and then

00:26:26.930 --> 00:26:28.610
<v Speaker 1>a monitoring step as well and hear how

00:26:28.610 --> 00:26:30.290
<v Speaker 1>the frameworks line up there.

00:26:32.835 --> 00:26:34.995
<v Speaker 1>So I'll take a pause, actually. I'm I'm

00:26:34.995 --> 00:26:37.155
<v Speaker 1>sure you have questions, Dave, or someone from

00:26:37.155 --> 00:26:37.874
<v Speaker 1>the audience.

00:26:40.034 --> 00:26:42.354
<v Speaker 0>I love how you started with, you know,

00:26:42.355 --> 00:26:45.395
<v Speaker 0>it's just an endpoint that answers a question

00:26:44.940 --> 00:26:46.779
<v Speaker 0>for you. And then you kinda look under

00:26:46.779 --> 00:26:48.460
<v Speaker 0>the covers and you're like, oh, shit. Like,

00:26:48.460 --> 00:26:50.539
<v Speaker 0>there's like so many different different parts here,

00:26:50.539 --> 00:26:52.299
<v Speaker 0>so many different pieces of the stack and

00:26:52.299 --> 00:26:53.580
<v Speaker 0>the architecture and

00:26:54.779 --> 00:26:56.859
<v Speaker 0>wow. There's an awful lot going on here.

00:26:57.100 --> 00:26:59.775
<v Speaker 0>And I'm very excited to see just how

00:26:59.775 --> 00:27:02.015
<v Speaker 0>Kubeflow is stitching all this together and making

00:27:02.015 --> 00:27:04.495
<v Speaker 0>it better for people to consume. Because like,

00:27:04.495 --> 00:27:06.175
<v Speaker 0>is I mean, is this a standard machine

00:27:06.175 --> 00:27:09.375
<v Speaker 0>learning pipeline? Like, you know, 12 or more

00:27:09.375 --> 00:27:11.135
<v Speaker 0>different pieces of software?

00:27:12.095 --> 00:27:12.975
<v Speaker 0>It's just

00:27:14.029 --> 00:27:15.149
<v Speaker 0>it's complex.

00:27:16.110 --> 00:27:16.909
<v Speaker 1>Yeah.

00:27:16.990 --> 00:27:19.789
<v Speaker 1>Yeah. Yeah. I used to joke,

00:27:20.750 --> 00:27:22.990
<v Speaker 1>you know, that that Kubeflow

00:27:22.990 --> 00:27:24.669
<v Speaker 1>is more complicated than Kubernetes

00:27:24.909 --> 00:27:26.669
<v Speaker 1>in in many ways. Right?

00:27:27.070 --> 00:27:29.794
<v Speaker 1>To to have a functional Kubernetes cluster, you

00:27:29.794 --> 00:27:31.475
<v Speaker 1>know, let's see. What would you need? You

00:27:31.475 --> 00:27:33.554
<v Speaker 1>need the the API. Right? So you need

00:27:33.554 --> 00:27:34.514
<v Speaker 1>some some

00:27:36.195 --> 00:27:39.394
<v Speaker 1>control plane, you know, resources scheduler.

00:27:39.635 --> 00:27:40.674
<v Speaker 1>You'd need,

00:27:41.635 --> 00:27:42.355
<v Speaker 1>you know,

00:27:42.835 --> 00:27:43.955
<v Speaker 1>Kube proxy,

00:27:44.195 --> 00:27:45.075
<v Speaker 1>core DNS,

00:27:47.130 --> 00:27:48.089
<v Speaker 1>Kubelet.

00:27:48.730 --> 00:27:50.169
<v Speaker 1>What am I missing, Dave?

00:27:50.570 --> 00:27:52.250
<v Speaker 0>That's pretty much the building blocks of a

00:27:52.250 --> 00:27:54.570
<v Speaker 0>distributed applications which just be need networking. I

00:27:54.570 --> 00:27:57.210
<v Speaker 0>need discovery for DNS. I need compute and

00:27:57.210 --> 00:27:59.210
<v Speaker 0>a scheduler. And then, like, let the workloads

00:27:59.210 --> 00:28:00.649
<v Speaker 0>go and and do their thing and, obviously,

00:28:00.649 --> 00:28:02.975
<v Speaker 0>an API to coordinate that. But I think

00:28:02.975 --> 00:28:05.215
<v Speaker 0>what I didn't appreciate until you kinda walked

00:28:05.215 --> 00:28:07.775
<v Speaker 0>me through these slides is and I love

00:28:07.775 --> 00:28:08.975
<v Speaker 0>the way you said you just start with

00:28:08.975 --> 00:28:10.654
<v Speaker 0>an endpoint. Right? But that's just once the

00:28:10.654 --> 00:28:12.174
<v Speaker 0>model is trained, but there's all of that

00:28:12.174 --> 00:28:14.770
<v Speaker 0>legwork to get to that point. And, you

00:28:14.770 --> 00:28:15.970
<v Speaker 0>know, when you had that graph and you're

00:28:15.970 --> 00:28:17.730
<v Speaker 0>saying, well, you know, some organizations, it's taken

00:28:17.730 --> 00:28:18.930
<v Speaker 0>them six to nine months, and it cost

00:28:18.930 --> 00:28:20.930
<v Speaker 0>them half a million dollars. And, like, there's

00:28:20.930 --> 00:28:23.250
<v Speaker 0>just so many different components here. And I

00:28:23.330 --> 00:28:24.690
<v Speaker 0>I'm assuming that's

00:28:24.690 --> 00:28:28.050
<v Speaker 0>probably consistent across most machine learning workloads is

00:28:28.050 --> 00:28:30.895
<v Speaker 0>that it's the training and evolution of the

00:28:30.895 --> 00:28:31.455
<v Speaker 0>model

00:28:31.855 --> 00:28:34.015
<v Speaker 0>that is the best that needs coordinated.

00:28:34.015 --> 00:28:35.854
<v Speaker 0>And the faster that you do that, the

00:28:35.934 --> 00:28:37.774
<v Speaker 0>the better velocity you've got in shipping new

00:28:37.774 --> 00:28:38.975
<v Speaker 0>versions of that model is how you make

00:28:38.975 --> 00:28:41.135
<v Speaker 0>your money. Is that fair to say? Yeah.

00:28:41.135 --> 00:28:42.414
<v Speaker 1>Yeah. I mean, that's that's

00:28:43.050 --> 00:28:44.410
<v Speaker 1>thank you for raising that. I mean, that

00:28:44.570 --> 00:28:47.050
<v Speaker 1>that's the that's the the between the lines

00:28:47.050 --> 00:28:49.610
<v Speaker 1>message. Right? It still pays

00:28:49.850 --> 00:28:51.450
<v Speaker 1>significantly.

00:28:52.650 --> 00:28:54.490
<v Speaker 1>You know, it's still an ROI

00:28:54.730 --> 00:28:56.170
<v Speaker 1>deeply ROI positive

00:28:58.265 --> 00:28:59.224
<v Speaker 1>endeavor

00:28:59.385 --> 00:29:00.184
<v Speaker 1>to

00:29:00.585 --> 00:29:03.465
<v Speaker 1>to actually spend that half million dollars. That's

00:29:03.465 --> 00:29:06.024
<v Speaker 1>just in compliance cost. Right? So

00:29:06.664 --> 00:29:08.745
<v Speaker 1>so that's that's not even including the the

00:29:08.745 --> 00:29:10.985
<v Speaker 1>labor time and the infrastructure and all the

00:29:10.985 --> 00:29:11.865
<v Speaker 1>stuff that went into it.

00:29:13.070 --> 00:29:14.910
<v Speaker 1>And, you know, you can see the impact

00:29:14.910 --> 00:29:16.670
<v Speaker 1>of it. I mean, AI is everywhere. I'm

00:29:16.750 --> 00:29:19.630
<v Speaker 1>I mean, I'm using a a camera application

00:29:19.630 --> 00:29:20.590
<v Speaker 1>on my

00:29:20.910 --> 00:29:22.110
<v Speaker 1>iPhone to

00:29:22.430 --> 00:29:24.590
<v Speaker 1>be serve as my webcam. You know, your

00:29:24.590 --> 00:29:28.105
<v Speaker 1>your your telephone or with the Apple architecture,

00:29:28.105 --> 00:29:30.745
<v Speaker 1>it's got multiple special purpose cores on it.

00:29:30.745 --> 00:29:33.304
<v Speaker 1>Right? Some are are neural cores. Some are

00:29:33.304 --> 00:29:35.705
<v Speaker 1>image processing cores. You know, there's a, you

00:29:35.705 --> 00:29:37.385
<v Speaker 1>know, a high speed and low speed CPU

00:29:37.385 --> 00:29:39.785
<v Speaker 1>cores. There's there's this this is this is

00:29:39.785 --> 00:29:42.169
<v Speaker 1>everywhere. You know? If I move my head,

00:29:42.650 --> 00:29:43.130
<v Speaker 1>the,

00:29:43.850 --> 00:29:46.250
<v Speaker 1>the the bubble around me, you see shifts.

00:29:46.250 --> 00:29:47.930
<v Speaker 1>Right? Like James James Bond. Oh, this is

00:29:47.930 --> 00:29:49.049
<v Speaker 0>cool. James Bond.

00:29:51.050 --> 00:29:53.530
<v Speaker 1>So so how's it doing that? It's it's

00:29:53.530 --> 00:29:55.610
<v Speaker 1>recognizing my face. In real time, that's crazy

00:29:55.935 --> 00:29:57.055
<v Speaker 1>and terrifying.

00:29:57.135 --> 00:29:57.855
<v Speaker 1>You know?

00:29:58.815 --> 00:30:02.415
<v Speaker 1>The COVID vaccine. Another perfect example. The COVID

00:30:02.415 --> 00:30:06.815
<v Speaker 1>vaccine is, uses mRNA. MRNA is super unstable.

00:30:06.815 --> 00:30:09.295
<v Speaker 1>That's why these vaccines go

00:30:09.649 --> 00:30:11.490
<v Speaker 1>spoil so quickly. Right? Need to be kept

00:30:11.490 --> 00:30:13.649
<v Speaker 1>in liquid nitrogen and all this stuff. It's

00:30:13.649 --> 00:30:17.169
<v Speaker 1>because the the the the molecule degrades,

00:30:17.330 --> 00:30:19.490
<v Speaker 1>and being able to predict where that molecule

00:30:19.490 --> 00:30:20.049
<v Speaker 1>degrade

00:30:21.904 --> 00:30:24.144
<v Speaker 1>transform the world. Right? I'm I'm very much

00:30:24.144 --> 00:30:26.144
<v Speaker 1>looking forward to getting back into society when

00:30:26.144 --> 00:30:27.825
<v Speaker 1>all of this blows over.

00:30:28.225 --> 00:30:31.184
<v Speaker 1>Right? Like, so so it's everywhere. It's everywhere.

00:30:31.345 --> 00:30:31.984
<v Speaker 1>You know?

00:30:32.625 --> 00:30:34.465
<v Speaker 0>Okay. Could we And the reason that yeah.

00:30:34.465 --> 00:30:36.490
<v Speaker 1>Sorry. Go ahead. I was just curious. Like,

00:30:36.490 --> 00:30:37.850
<v Speaker 0>you know, obviously, like, so we're we're we're

00:30:37.850 --> 00:30:39.210
<v Speaker 0>looking at Kubeflow today. This is a way

00:30:39.210 --> 00:30:40.730
<v Speaker 0>to kind of I I don't know if

00:30:40.730 --> 00:30:43.050
<v Speaker 0>it's to automate or orchestrate or to simplify

00:30:43.050 --> 00:30:45.210
<v Speaker 0>all of these moving parts on Kubernetes. But

00:30:45.210 --> 00:30:47.610
<v Speaker 0>what was it like before Kubernetes?

00:30:47.610 --> 00:30:48.570
<v Speaker 0>Was it just the Wild West?

00:30:50.195 --> 00:30:52.835
<v Speaker 1>Oh, well, before Kubernetes, you know, it's so

00:30:52.835 --> 00:30:54.995
<v Speaker 1>interesting I find in in technology.

00:30:55.635 --> 00:30:56.995
<v Speaker 1>You know, do should we should we kill

00:30:56.995 --> 00:30:58.435
<v Speaker 1>the slides for a second? Just just chat

00:30:58.435 --> 00:30:59.635
<v Speaker 1>this one out? I mean, I I don't

00:30:59.635 --> 00:31:00.835
<v Speaker 1>know. Yeah. Yeah. Yeah. Okay.

00:31:09.270 --> 00:31:10.390
<v Speaker 0>Where'd your audio go?

00:31:21.405 --> 00:31:23.164
<v Speaker 0>No. I'm not hearing anything.

00:31:25.005 --> 00:31:27.805
<v Speaker 0>I think it when the screen share dropped,

00:31:27.805 --> 00:31:28.684
<v Speaker 0>it kind of

00:31:30.365 --> 00:31:31.325
<v Speaker 0>cut you out.

00:31:31.805 --> 00:31:33.885
<v Speaker 1>How about now? Oh, yeah. It's back now.

00:31:33.885 --> 00:31:34.445
<v Speaker 0>That was weird.

00:31:35.080 --> 00:31:37.480
<v Speaker 1>Okay. Yeah. That's that's fun. Yeah.

00:31:37.720 --> 00:31:40.600
<v Speaker 1>I I could see the little microphone bar.

00:31:43.080 --> 00:31:44.440
<v Speaker 1>Yeah. What was it like? What was it

00:31:44.440 --> 00:31:46.040
<v Speaker 1>like? So, you know, one of the things

00:31:46.040 --> 00:31:48.375
<v Speaker 1>that blows my mind is, just how, you

00:31:48.375 --> 00:31:49.735
<v Speaker 1>know, the left hand doesn't talk to the

00:31:49.735 --> 00:31:51.415
<v Speaker 1>right hand. Right? I mean, there wasn't a

00:31:51.415 --> 00:31:53.335
<v Speaker 1>lot of distributed computing going on.

00:31:53.815 --> 00:31:56.695
<v Speaker 1>But at the, but at the same time,

00:31:58.695 --> 00:31:59.575
<v Speaker 1>but at the same time,

00:32:01.559 --> 00:32:02.839
<v Speaker 1>there you know,

00:32:03.799 --> 00:32:05.399
<v Speaker 1>everything was being done. There wasn't a lot

00:32:05.399 --> 00:32:07.080
<v Speaker 1>of distributed computing going on, but it was

00:32:07.080 --> 00:32:08.919
<v Speaker 1>possible. Right? Like, there there were there were

00:32:08.919 --> 00:32:10.679
<v Speaker 1>options for this. But

00:32:11.159 --> 00:32:13.000
<v Speaker 1>the people who are working on these these

00:32:13.000 --> 00:32:16.120
<v Speaker 1>training and data science questions

00:32:17.265 --> 00:32:18.225
<v Speaker 1>weren't

00:32:18.305 --> 00:32:20.065
<v Speaker 1>talking to the people who are doing a

00:32:20.065 --> 00:32:22.145
<v Speaker 1>lot of the distributed computing stuff. Right? And

00:32:22.145 --> 00:32:23.585
<v Speaker 1>they're certainly the people who are doing the

00:32:23.585 --> 00:32:25.745
<v Speaker 1>distributed machine learning at that time, if you

00:32:25.745 --> 00:32:27.265
<v Speaker 1>could even call it machine learning. I mean,

00:32:27.265 --> 00:32:29.105
<v Speaker 1>you gotta remember a lot of these these

00:32:29.185 --> 00:32:32.190
<v Speaker 1>discoveries around machine learning are are extremely recent,

00:32:32.190 --> 00:32:33.950
<v Speaker 1>I mean, really in the last ten years.

00:32:34.750 --> 00:32:37.630
<v Speaker 1>You know, neural networks were for fifty years.

00:32:37.630 --> 00:32:39.470
<v Speaker 1>You know, they they were conceptualized in the

00:32:39.470 --> 00:32:41.309
<v Speaker 1>sixties. For fifty years, everyone thought it was

00:32:41.309 --> 00:32:43.870
<v Speaker 1>a ridiculous and impossible thing until somebody figured

00:32:43.870 --> 00:32:46.184
<v Speaker 1>out, okay. Let's do back propagation, and, well,

00:32:46.184 --> 00:32:48.265
<v Speaker 1>it'll work. And it and, you know, there's

00:32:48.265 --> 00:32:49.785
<v Speaker 1>a there was a great article. Oh my

00:32:49.785 --> 00:32:50.345
<v Speaker 1>goodness.

00:32:50.985 --> 00:32:52.745
<v Speaker 1>I can I I'll share a link with

00:32:52.745 --> 00:32:56.025
<v Speaker 1>you talking about, the the folks who, the

00:32:56.025 --> 00:32:59.385
<v Speaker 1>the academic team, who who

00:32:58.950 --> 00:33:01.269
<v Speaker 1>discovered that you could do deep neural networks?

00:33:01.750 --> 00:33:04.470
<v Speaker 1>And, and with, you know, with no product,

00:33:04.470 --> 00:33:05.909
<v Speaker 1>they they sold their company

00:33:06.390 --> 00:33:09.510
<v Speaker 1>for, like, in an auction for, like, $50,000,000

00:33:09.510 --> 00:33:11.110
<v Speaker 1>to Google. It's just like an acquihire. You

00:33:11.110 --> 00:33:12.230
<v Speaker 1>know? Anyways,

00:33:13.495 --> 00:33:14.855
<v Speaker 1>so it is you know, that's the one

00:33:14.855 --> 00:33:16.054
<v Speaker 1>size. It's very new. On the other hand,

00:33:16.054 --> 00:33:17.655
<v Speaker 1>you know, the folks don't don't talk to

00:33:17.655 --> 00:33:18.215
<v Speaker 1>each other.

00:33:19.735 --> 00:33:22.614
<v Speaker 1>And then we also concurrently had had

00:33:24.695 --> 00:33:25.575
<v Speaker 1>hardware breakthroughs.

00:33:25.840 --> 00:33:28.320
<v Speaker 1>Right? I mean, the this is some I

00:33:28.480 --> 00:33:30.320
<v Speaker 1>I'm not a a gamer,

00:33:30.480 --> 00:33:33.600
<v Speaker 1>personally, but, you know, the the gaming world,

00:33:34.640 --> 00:33:36.800
<v Speaker 1>we owe them a debt of gratitude in

00:33:36.800 --> 00:33:39.440
<v Speaker 1>a way because by purchasing high end GPUs,

00:33:39.440 --> 00:33:40.880
<v Speaker 1>they essentially subsidized

00:33:41.065 --> 00:33:43.865
<v Speaker 1>the development of of GPUs

00:33:44.025 --> 00:33:47.385
<v Speaker 1>such that they became useful for machine learning.

00:33:47.385 --> 00:33:47.945
<v Speaker 1>Right?

00:33:48.265 --> 00:33:50.985
<v Speaker 1>Which is something that I don't think most

00:33:50.985 --> 00:33:52.505
<v Speaker 1>people really think about.

00:33:52.985 --> 00:33:55.065
<v Speaker 1>So you had really, what you had is

00:33:55.065 --> 00:33:55.545
<v Speaker 1>people

00:33:57.190 --> 00:33:57.509
<v Speaker 1>a a

00:33:58.230 --> 00:33:59.509
<v Speaker 1>confluence of events.

00:33:59.750 --> 00:34:02.870
<v Speaker 1>One being we now have Internet scale data.

00:34:02.870 --> 00:34:05.989
<v Speaker 1>Right? We now have problems we wanna solve

00:34:06.230 --> 00:34:07.909
<v Speaker 1>that previously

00:34:07.909 --> 00:34:09.429
<v Speaker 1>we didn't have the the

00:34:10.404 --> 00:34:11.525
<v Speaker 1>mathematical

00:34:12.404 --> 00:34:13.204
<v Speaker 1>algorithms

00:34:13.204 --> 00:34:14.804
<v Speaker 1>to be able to to

00:34:15.364 --> 00:34:17.045
<v Speaker 1>process in a way that would result in

00:34:17.045 --> 00:34:18.645
<v Speaker 1>anything at all valuable.

00:34:18.804 --> 00:34:20.964
<v Speaker 1>Right? So, I mean, it doesn't matter if

00:34:20.964 --> 00:34:22.324
<v Speaker 1>if I'm not you know, if I wanna

00:34:22.324 --> 00:34:23.764
<v Speaker 1>have a self driving car, if I don't

00:34:23.764 --> 00:34:26.300
<v Speaker 1>have a machine learning framework or or the

00:34:26.300 --> 00:34:29.260
<v Speaker 1>algorithms to be able to to produce something

00:34:29.260 --> 00:34:30.620
<v Speaker 1>that will learn how to drive,

00:34:30.860 --> 00:34:32.540
<v Speaker 1>I'm not gonna even attempt it. Right?

00:34:33.100 --> 00:34:34.220
<v Speaker 1>And then,

00:34:34.780 --> 00:34:36.940
<v Speaker 1>and then we had GPU. Right? And that

00:34:36.940 --> 00:34:40.780
<v Speaker 1>that really gave us a a lot of

00:34:39.495 --> 00:34:41.095
<v Speaker 1>a a lot of horsepower.

00:34:43.095 --> 00:34:44.535
<v Speaker 1>You know? And and the scale of these

00:34:44.535 --> 00:34:46.375
<v Speaker 1>things for things that are meaningful, you know,

00:34:46.375 --> 00:34:46.775
<v Speaker 1>I I

00:34:47.415 --> 00:34:50.375
<v Speaker 1>GPT three, which is a an NLP model,

00:34:50.535 --> 00:34:52.455
<v Speaker 1>you know, got a lot of attention, when

00:34:52.455 --> 00:34:53.495
<v Speaker 1>it came out fairly recently.

00:34:54.110 --> 00:34:56.989
<v Speaker 1>That to train that model required,

00:34:57.710 --> 00:35:01.230
<v Speaker 1>I'm I'm not so good with, with electromagnetism.

00:35:01.230 --> 00:35:02.430
<v Speaker 1>It was, like, three

00:35:02.670 --> 00:35:05.470
<v Speaker 1>gigawatt hours of electric does that is that

00:35:05.470 --> 00:35:06.990
<v Speaker 1>higher? That seems like a lot. Right? That

00:35:06.990 --> 00:35:08.305
<v Speaker 1>is a lot. It was it was the

00:35:08.385 --> 00:35:09.825
<v Speaker 1>it was three hours

00:35:10.145 --> 00:35:13.665
<v Speaker 1>of a full nuclear power plant's output.

00:35:14.385 --> 00:35:17.185
<v Speaker 1>Okay? So that's that's the meaningful metric by

00:35:17.185 --> 00:35:19.585
<v Speaker 1>analogy for me. It's it's a lot. Right?

00:35:19.585 --> 00:35:21.505
<v Speaker 1>So these are computationally

00:35:21.810 --> 00:35:22.770
<v Speaker 1>extraordinarily

00:35:22.770 --> 00:35:24.130
<v Speaker 1>expensive operations,

00:35:24.130 --> 00:35:25.570
<v Speaker 1>but the yield is there. There's there's a

00:35:25.570 --> 00:35:26.530
<v Speaker 1>reason to do it.

00:35:26.850 --> 00:35:28.610
<v Speaker 1>Right? So that's that's really how I see

00:35:28.610 --> 00:35:30.370
<v Speaker 1>it. We we we didn't really have a

00:35:30.370 --> 00:35:31.810
<v Speaker 1>lot of distributed computing.

00:35:31.970 --> 00:35:34.210
<v Speaker 1>People could get away with using really big

00:35:34.210 --> 00:35:37.010
<v Speaker 1>boxes with a couple GPUs attached to them.

00:35:38.445 --> 00:35:41.165
<v Speaker 1>The and the the the

00:35:41.165 --> 00:35:44.365
<v Speaker 1>objectives were less ambitious than they are today,

00:35:45.085 --> 00:35:46.845
<v Speaker 0>if that makes sense. Yeah. That does make

00:35:46.845 --> 00:35:48.605
<v Speaker 0>a lot of sense. It it helps

00:35:48.605 --> 00:35:50.525
<v Speaker 0>solidify everything that you're seeing and makes me

00:35:50.525 --> 00:35:52.285
<v Speaker 0>understand that a little bit better just that

00:35:52.500 --> 00:35:54.420
<v Speaker 0>evolution. You know, I could even think back

00:35:54.420 --> 00:35:55.140
<v Speaker 0>as probably

00:35:55.540 --> 00:35:57.540
<v Speaker 0>around ten years ago as well and everything,

00:35:57.780 --> 00:35:59.300
<v Speaker 0>at least the organization's time is that was

00:35:59.300 --> 00:36:01.940
<v Speaker 0>all about ETL pipelines and doing everything in

00:36:01.940 --> 00:36:03.860
<v Speaker 0>big batch machines at night when it was

00:36:03.860 --> 00:36:06.100
<v Speaker 0>maybe cheaper or using spawns and season, stuff

00:36:06.100 --> 00:36:08.255
<v Speaker 0>like that. But now, you know, with things

00:36:08.255 --> 00:36:10.095
<v Speaker 0>like Kubeflow and TensorFlow and all this other

00:36:10.095 --> 00:36:12.975
<v Speaker 0>stuff, we're we're more real time. We're streaming

00:36:12.975 --> 00:36:16.015
<v Speaker 0>machine learning or training models and I think

00:36:16.015 --> 00:36:17.775
<v Speaker 0>that's probably driven a lot of,

00:36:18.175 --> 00:36:19.775
<v Speaker 0>I don't know, change in the tools that

00:36:19.775 --> 00:36:21.620
<v Speaker 0>we use as well. Like, it's not just

00:36:21.620 --> 00:36:24.260
<v Speaker 0>here. Send us send us zip archive to

00:36:24.260 --> 00:36:26.420
<v Speaker 0>someone at 10PM, and they'll process it at

00:36:26.420 --> 00:36:28.660
<v Speaker 0>3AM over four weeks, and then you'll get

00:36:28.660 --> 00:36:32.260
<v Speaker 0>it back. Yeah. Yeah. Exact exactly. Exactly. You

00:36:32.260 --> 00:36:34.500
<v Speaker 1>know, I remember, you know, back in my

00:36:34.500 --> 00:36:37.055
<v Speaker 1>Mesos days, you know, one just to have

00:36:37.055 --> 00:36:39.295
<v Speaker 1>a a silly example. China Unicom was a

00:36:39.295 --> 00:36:41.295
<v Speaker 1>a huge and very public user of Apache

00:36:41.295 --> 00:36:43.295
<v Speaker 1>Mesos just as a to to go in

00:36:43.295 --> 00:36:45.375
<v Speaker 1>the way back machine here. And

00:36:46.015 --> 00:36:49.375
<v Speaker 1>the the the reason that they they made

00:36:49.375 --> 00:36:51.740
<v Speaker 1>the migration to to to use Mesos was

00:36:51.740 --> 00:36:53.579
<v Speaker 1>because when someone wanted to figure out what

00:36:53.579 --> 00:36:55.100
<v Speaker 1>their cell phone bill was,

00:36:55.500 --> 00:36:58.060
<v Speaker 1>they had to wait, like, forty eight hours

00:36:58.299 --> 00:37:00.619
<v Speaker 1>for for for a combination of batch processes

00:37:00.619 --> 00:37:03.180
<v Speaker 1>and just compute time. Right? And, you know,

00:37:03.180 --> 00:37:05.420
<v Speaker 1>that who would accept that now? Like, that's,

00:37:05.420 --> 00:37:07.315
<v Speaker 1>you know, that's crazy. We would we would

00:37:07.795 --> 00:37:09.315
<v Speaker 1>anytime I log on to my bank and

00:37:09.315 --> 00:37:11.955
<v Speaker 1>they have they have a a maintenance window,

00:37:11.955 --> 00:37:13.875
<v Speaker 1>I I consider getting a new bank. I

00:37:13.875 --> 00:37:15.955
<v Speaker 1>consider getting it, like, inexcusable.

00:37:16.035 --> 00:37:18.115
<v Speaker 0>I do that with every company. If I

00:37:18.115 --> 00:37:19.475
<v Speaker 0>see a maintenance page, oh, we're done for

00:37:19.475 --> 00:37:21.395
<v Speaker 0>scheduled maintenance for the next six hours. I'm

00:37:21.395 --> 00:37:23.369
<v Speaker 0>like, what is this? Like, this is that

00:37:23.369 --> 00:37:25.130
<v Speaker 0>just gives me so much fear about the

00:37:25.130 --> 00:37:26.730
<v Speaker 0>way that they handle their data, work with

00:37:26.730 --> 00:37:28.330
<v Speaker 0>their data, and work with their systems.

00:37:29.049 --> 00:37:30.890
<v Speaker 0>There's very few cases where I think that

00:37:30.890 --> 00:37:33.530
<v Speaker 0>acceptable these days. I I refer to that

00:37:33.530 --> 00:37:34.970
<v Speaker 1>as the onion ring and the french fry

00:37:34.970 --> 00:37:36.745
<v Speaker 1>problem. I like onion rings. I like french

00:37:36.745 --> 00:37:38.105
<v Speaker 1>fries. If I order french fries and I

00:37:38.105 --> 00:37:39.545
<v Speaker 1>see an onion ring in my basket of

00:37:39.545 --> 00:37:41.145
<v Speaker 1>french fries, now I'm worried about what's going

00:37:41.145 --> 00:37:42.585
<v Speaker 1>on. You know what I'm saying?

00:37:43.705 --> 00:37:44.905
<v Speaker 0>I like that.

00:37:45.465 --> 00:37:46.505
<v Speaker 0>Alright. So

00:37:46.985 --> 00:37:48.830
<v Speaker 1>Alright. Back to it. Yeah. Do you want

00:37:48.830 --> 00:37:50.830
<v Speaker 0>me to pop out your slides back up?

00:37:50.990 --> 00:37:52.430
<v Speaker 1>Please do. Yeah.

00:37:53.550 --> 00:37:56.590
<v Speaker 1>Alright. So what's new in Kubeflow1.three?

00:37:56.590 --> 00:37:57.950
<v Speaker 1>I know we wanted to give a quick

00:37:57.950 --> 00:37:59.550
<v Speaker 1>update. I'll just go through this.

00:38:00.750 --> 00:38:03.475
<v Speaker 1>It's a this is a big feature release

00:38:03.635 --> 00:38:06.595
<v Speaker 1>that we're that we're coming up to. So

00:38:07.075 --> 00:38:10.595
<v Speaker 1>we've got new and updated UIs. So we

00:38:10.595 --> 00:38:12.995
<v Speaker 1>have a serving UI now that's got integrated

00:38:12.995 --> 00:38:14.195
<v Speaker 1>logging and monitoring.

00:38:15.270 --> 00:38:18.310
<v Speaker 1>We've got a new UI for hyperparameter

00:38:18.310 --> 00:38:19.830
<v Speaker 1>optimization experiments.

00:38:20.070 --> 00:38:22.710
<v Speaker 1>We've got TensorBoard coming. This is the TensorBoard

00:38:22.710 --> 00:38:24.710
<v Speaker 1>provides you with monitoring

00:38:25.510 --> 00:38:28.230
<v Speaker 1>not from endpoint health perspective, but from quality

00:38:28.230 --> 00:38:29.190
<v Speaker 1>of model perspective.

00:38:29.835 --> 00:38:31.595
<v Speaker 1>If that makes sense. We talked about before,

00:38:31.595 --> 00:38:33.915
<v Speaker 1>know, don't keep recommending Tiger King. We have

00:38:33.915 --> 00:38:35.994
<v Speaker 1>a way to monitor manage volumes.

00:38:35.994 --> 00:38:37.515
<v Speaker 1>A lot of these datasets are big. How

00:38:37.515 --> 00:38:39.755
<v Speaker 1>do we avoid copying them a million times,

00:38:39.755 --> 00:38:41.915
<v Speaker 1>and how do we get visibility into that?

00:38:41.994 --> 00:38:45.195
<v Speaker 1>We have integration with an open source project

00:38:45.660 --> 00:38:46.380
<v Speaker 1>that

00:38:47.020 --> 00:38:49.500
<v Speaker 1>we call Kail. This is part of the

00:38:49.500 --> 00:38:52.300
<v Speaker 1>the stack developed by one of my colleagues

00:38:52.300 --> 00:38:53.580
<v Speaker 1>here at

00:38:54.780 --> 00:38:57.339
<v Speaker 1>Aricto in my day job and better integration

00:38:57.339 --> 00:38:58.940
<v Speaker 1>with pipeline. So all of this is is

00:38:58.940 --> 00:38:59.660
<v Speaker 1>being

00:38:59.740 --> 00:39:02.115
<v Speaker 1>you know, getting to the point where we've

00:39:02.115 --> 00:39:03.795
<v Speaker 1>got so many people in production. You know,

00:39:03.795 --> 00:39:05.635
<v Speaker 1>we really wanna make this as easy and

00:39:05.635 --> 00:39:06.835
<v Speaker 1>as clean as possible.

00:39:07.155 --> 00:39:08.915
<v Speaker 1>We are also including,

00:39:09.475 --> 00:39:10.995
<v Speaker 1>it's been out in the in the world

00:39:10.995 --> 00:39:11.715
<v Speaker 1>for a little bit,

00:39:12.860 --> 00:39:15.100
<v Speaker 1>But the ability to run Versus Code in

00:39:15.100 --> 00:39:16.860
<v Speaker 1>RStudio as your IDE,

00:39:17.340 --> 00:39:19.100
<v Speaker 1>like I said, you can if if it

00:39:19.100 --> 00:39:21.500
<v Speaker 1>if it fit you know, if it's containerizable,

00:39:21.500 --> 00:39:23.660
<v Speaker 1>which what isn't, you know, then you're generally

00:39:23.660 --> 00:39:26.155
<v Speaker 1>good to go. But but this will come

00:39:26.155 --> 00:39:29.115
<v Speaker 1>out of the box with a new example

00:39:29.515 --> 00:39:31.835
<v Speaker 1>notebook images for TensorFlow two dot o and

00:39:31.835 --> 00:39:32.555
<v Speaker 1>PyTorch.

00:39:32.875 --> 00:39:35.994
<v Speaker 1>And then lastly, we've made some enhancements to

00:39:35.994 --> 00:39:38.480
<v Speaker 1>KF serving, such as making it easier to

00:39:38.480 --> 00:39:41.440
<v Speaker 1>do canary deployments. Super important, right,

00:39:41.839 --> 00:39:44.320
<v Speaker 1>with a with a model in particular because,

00:39:45.359 --> 00:39:47.119
<v Speaker 1>we're not you know, it's it's different than

00:39:47.119 --> 00:39:50.285
<v Speaker 1>the software development life cycle where, okay. Sure.

00:39:50.285 --> 00:39:52.205
<v Speaker 1>We can, you know, put something in stage

00:39:52.205 --> 00:39:53.405
<v Speaker 1>and use production,

00:39:53.885 --> 00:39:55.885
<v Speaker 1>you know, anonymize production data that we pull

00:39:55.885 --> 00:39:57.005
<v Speaker 1>back into staging.

00:39:57.245 --> 00:40:00.045
<v Speaker 1>It's not you know, the the the issue

00:40:00.045 --> 00:40:02.205
<v Speaker 1>that we'll see with with machine learning models,

00:40:02.205 --> 00:40:02.925
<v Speaker 1>you'll see in a second,

00:40:04.119 --> 00:40:04.840
<v Speaker 1>is

00:40:05.000 --> 00:40:08.840
<v Speaker 1>that we don't really know what exactly is

00:40:08.840 --> 00:40:11.240
<v Speaker 1>gonna happen till we get out there. Right?

00:40:11.240 --> 00:40:13.640
<v Speaker 1>So you want to, you wanna really take

00:40:13.640 --> 00:40:15.480
<v Speaker 1>your time and roll these out progressively over

00:40:15.480 --> 00:40:15.640
<v Speaker 1>time.

00:40:17.615 --> 00:40:19.295
<v Speaker 1>And, you know, just some additional

00:40:19.375 --> 00:40:20.895
<v Speaker 1>library support there.

00:40:23.135 --> 00:40:25.935
<v Speaker 1>We've upgraded Istio. Istio one dot nine will

00:40:25.935 --> 00:40:26.735
<v Speaker 1>be shipping.

00:40:27.135 --> 00:40:30.370
<v Speaker 1>We've completely refactored the way that the manifest

00:40:30.370 --> 00:40:32.290
<v Speaker 1>working group, led by,

00:40:32.610 --> 00:40:33.970
<v Speaker 1>Ioannis Arcadis,

00:40:34.370 --> 00:40:36.530
<v Speaker 1>also one of my colleagues at Aricto, has

00:40:36.530 --> 00:40:38.050
<v Speaker 1>completely changed the way that we deploy it.

00:40:38.050 --> 00:40:39.650
<v Speaker 1>So it's pure customized now.

00:40:39.890 --> 00:40:42.290
<v Speaker 1>You can you can deploy Kubeflow as one

00:40:42.290 --> 00:40:43.890
<v Speaker 1>dot three with

00:40:44.395 --> 00:40:46.635
<v Speaker 1>with, just basic KubeCTL.

00:40:46.715 --> 00:40:49.515
<v Speaker 1>We've got multiuser pipelines, so now you can

00:40:49.515 --> 00:40:50.235
<v Speaker 1>isolate,

00:40:50.635 --> 00:40:51.595
<v Speaker 1>pipelines,

00:40:52.075 --> 00:40:53.035
<v Speaker 1>appropriately

00:40:53.195 --> 00:40:55.275
<v Speaker 1>for production deployments.

00:40:55.835 --> 00:40:57.880
<v Speaker 1>And, you know, Pod Affinity,

00:40:57.960 --> 00:41:01.560
<v Speaker 1>pretty standard stuff, but just making the the,

00:41:02.280 --> 00:41:04.120
<v Speaker 1>sort of catching Kubeflow up to the latest

00:41:04.120 --> 00:41:06.200
<v Speaker 1>and greatest really in the in the Kubeflow

00:41:06.200 --> 00:41:07.960
<v Speaker 1>community. I mean, Pod Affinity is not latest

00:41:07.960 --> 00:41:09.880
<v Speaker 1>and greatest, but we have to think about

00:41:09.880 --> 00:41:12.485
<v Speaker 1>how we expose these knobs and dials from

00:41:12.485 --> 00:41:15.205
<v Speaker 1>a you know, to a a an end

00:41:15.205 --> 00:41:17.045
<v Speaker 1>user who is unfamiliar

00:41:17.445 --> 00:41:19.685
<v Speaker 1>very likely unfamiliar with Kubernetes,

00:41:21.045 --> 00:41:23.365
<v Speaker 1>objects and and deployment models.

00:41:24.245 --> 00:41:26.920
<v Speaker 1>So that's that's the that's the state of

00:41:26.920 --> 00:41:29.320
<v Speaker 1>affairs with new stuff in one dot three.

00:41:29.480 --> 00:41:32.360
<v Speaker 1>And, I promise we'll be getting to a

00:41:32.360 --> 00:41:34.600
<v Speaker 1>a live coding example in,

00:41:34.840 --> 00:41:36.680
<v Speaker 1>in a MO. But

00:41:41.225 --> 00:41:43.305
<v Speaker 1>I wanted to describe a little bit about

00:41:43.305 --> 00:41:46.185
<v Speaker 1>what the, coding just provide an analogy for

00:41:46.185 --> 00:41:47.465
<v Speaker 1>what the the coding,

00:41:47.785 --> 00:41:48.665
<v Speaker 1>example

00:41:48.825 --> 00:41:49.465
<v Speaker 1>will,

00:41:49.785 --> 00:41:50.985
<v Speaker 1>be demonstrating.

00:41:51.465 --> 00:41:53.465
<v Speaker 1>Because if it you know, code that makes

00:41:53.465 --> 00:41:55.820
<v Speaker 1>no sense, you know, seems of of limited

00:41:55.820 --> 00:41:57.980
<v Speaker 1>value. So if you this is this is

00:41:57.980 --> 00:41:59.020
<v Speaker 1>your your

00:41:59.340 --> 00:42:00.380
<v Speaker 1>first time

00:42:01.100 --> 00:42:02.780
<v Speaker 1>being exposed to deep learning.

00:42:03.020 --> 00:42:04.860
<v Speaker 1>I apologize that I'm the one to introduce

00:42:04.860 --> 00:42:06.700
<v Speaker 1>you to it, but I don't have a

00:42:06.700 --> 00:42:09.260
<v Speaker 1>PhD in anything, let alone mathematics. So

00:42:09.885 --> 00:42:11.805
<v Speaker 1>if I can learn it, you can too.

00:42:12.525 --> 00:42:15.005
<v Speaker 1>And I'll be borrowing an analogy from Andrew

00:42:15.005 --> 00:42:17.645
<v Speaker 1>Trask's grokking deep learning, which is published by

00:42:17.645 --> 00:42:21.005
<v Speaker 1>Manning. Highly, highly, highly recommend it as a

00:42:21.005 --> 00:42:23.805
<v Speaker 1>as a way to conceptualize and understand what

00:42:23.805 --> 00:42:25.880
<v Speaker 1>we're actually doing here. So

00:42:27.240 --> 00:42:30.280
<v Speaker 1>we are going to, use an analogy of

00:42:30.280 --> 00:42:32.040
<v Speaker 1>a of a fork analyzer.

00:42:32.120 --> 00:42:33.560
<v Speaker 1>And what I mean by that is we

00:42:33.560 --> 00:42:36.280
<v Speaker 1>are going to attempt to, create

00:42:36.600 --> 00:42:37.080
<v Speaker 1>a,

00:42:37.480 --> 00:42:39.035
<v Speaker 1>clay mold. You can think of it as

00:42:39.035 --> 00:42:40.715
<v Speaker 1>a a clay mold, a block of clay,

00:42:40.715 --> 00:42:42.235
<v Speaker 1>and we're gonna try and make a mold.

00:42:42.235 --> 00:42:43.915
<v Speaker 1>And the mold is not going to be

00:42:43.915 --> 00:42:46.475
<v Speaker 1>for the purposes of pouring liquid metal and

00:42:46.475 --> 00:42:48.075
<v Speaker 1>producing additional forks.

00:42:48.235 --> 00:42:50.955
<v Speaker 1>Instead, it's the the goal of our exercise

00:42:50.955 --> 00:42:53.609
<v Speaker 1>here is to produce a mold that has

00:42:53.770 --> 00:42:55.849
<v Speaker 1>that that anything that is a fork should

00:42:55.849 --> 00:42:56.890
<v Speaker 1>fit into the mold,

00:42:57.130 --> 00:42:58.970
<v Speaker 1>and anything that isn't a fork should not

00:42:58.970 --> 00:43:01.450
<v Speaker 1>fit into the mold. Right? So so the

00:43:01.450 --> 00:43:03.369
<v Speaker 1>the the mold will tell us is the

00:43:03.369 --> 00:43:05.690
<v Speaker 1>thing I'm putting, you know, into it a

00:43:05.690 --> 00:43:07.765
<v Speaker 1>fork, And the way it will determine that

00:43:07.765 --> 00:43:09.685
<v Speaker 1>is whether the fork sits in the mold

00:43:09.685 --> 00:43:10.485
<v Speaker 1>comfortably

00:43:10.485 --> 00:43:12.085
<v Speaker 1>or whether it,

00:43:12.245 --> 00:43:14.165
<v Speaker 1>you know, gets bumped by the sides of

00:43:14.165 --> 00:43:15.685
<v Speaker 1>the mold or something like that such that

00:43:15.685 --> 00:43:18.005
<v Speaker 1>it doesn't sit comfortably. Does that make sense?

00:43:18.725 --> 00:43:19.125
<v Speaker 0>Yes.

00:43:20.060 --> 00:43:20.780
<v Speaker 1>Okay.

00:43:21.020 --> 00:43:21.660
<v Speaker 1>So,

00:43:23.020 --> 00:43:26.140
<v Speaker 1>I apologize for my, heinously terrible,

00:43:26.460 --> 00:43:28.540
<v Speaker 1>graphic design skills, but,

00:43:29.020 --> 00:43:30.859
<v Speaker 1>you know, it is what it is. So

00:43:30.859 --> 00:43:32.780
<v Speaker 1>here's here's our our clay mold. It's a

00:43:32.780 --> 00:43:34.140
<v Speaker 1>block of clay. Right?

00:43:34.775 --> 00:43:35.335
<v Speaker 1>And

00:43:36.295 --> 00:43:39.255
<v Speaker 1>I will use you as as my my

00:43:39.255 --> 00:43:40.055
<v Speaker 1>audience

00:43:40.135 --> 00:43:41.255
<v Speaker 1>foil here.

00:43:41.575 --> 00:43:42.135
<v Speaker 1>So

00:43:42.775 --> 00:43:43.975
<v Speaker 1>so, David,

00:43:44.135 --> 00:43:46.375
<v Speaker 1>tell me. Do you think this is a

00:43:46.375 --> 00:43:48.615
<v Speaker 1>fork? Are you smarter than a clay mold?

00:43:49.910 --> 00:43:50.950
<v Speaker 0>That

00:43:50.950 --> 00:43:52.070
<v Speaker 0>is a fork.

00:43:52.790 --> 00:43:53.430
<v Speaker 1>Okay.

00:43:53.590 --> 00:43:55.270
<v Speaker 1>So I would agree with that. And so

00:43:55.270 --> 00:43:57.270
<v Speaker 1>what we will do is we will take

00:43:57.270 --> 00:44:00.550
<v Speaker 1>this this this rendering of a fork, and

00:44:00.550 --> 00:44:02.630
<v Speaker 1>we will dip it into press it into

00:44:02.630 --> 00:44:04.795
<v Speaker 1>the mold. Alright? So what's the outcome of

00:44:04.795 --> 00:44:05.675
<v Speaker 1>that? Well,

00:44:05.915 --> 00:44:08.315
<v Speaker 1>now we've got a fork shaped mold. Right?

00:44:08.315 --> 00:44:10.235
<v Speaker 1>But it's this fork shape. Right?

00:44:10.555 --> 00:44:12.955
<v Speaker 1>So let's see how how well our mold

00:44:12.955 --> 00:44:14.235
<v Speaker 1>performs. What's next?

00:44:15.195 --> 00:44:17.595
<v Speaker 1>David, time to shine. Fork or nonfork?

00:44:19.410 --> 00:44:20.130
<v Speaker 0>Fork.

00:44:20.770 --> 00:44:23.170
<v Speaker 1>Alright. Agreed. I think this is a fork.

00:44:23.329 --> 00:44:26.290
<v Speaker 1>Alright. So let's dip it into the into

00:44:26.290 --> 00:44:27.970
<v Speaker 1>the mold and see what happens.

00:44:28.210 --> 00:44:30.290
<v Speaker 1>Well, you can see on the screen that

00:44:30.290 --> 00:44:31.090
<v Speaker 1>actually,

00:44:31.569 --> 00:44:33.730
<v Speaker 1>if we put this fork into the mold,

00:44:34.404 --> 00:44:36.484
<v Speaker 1>the mold would tell us that it's not

00:44:36.484 --> 00:44:39.285
<v Speaker 1>a fork. Right? It wouldn't sit comfortably in

00:44:39.285 --> 00:44:40.805
<v Speaker 1>the mold that we've made. Right?

00:44:41.365 --> 00:44:42.165
<v Speaker 1>Correct.

00:44:42.884 --> 00:44:45.765
<v Speaker 1>The mold would say, this this ain't no

00:44:45.765 --> 00:44:46.085
<v Speaker 1>fork.

00:44:46.730 --> 00:44:48.410
<v Speaker 1>We would say it is. So the mold

00:44:48.410 --> 00:44:50.170
<v Speaker 1>goes, ugh. Alright. Fine. This is a fork

00:44:50.170 --> 00:44:52.970
<v Speaker 1>too? Alright. I will change my molds. Right?

00:44:52.970 --> 00:44:55.530
<v Speaker 1>I will the mold will change shape, right,

00:44:55.530 --> 00:44:58.410
<v Speaker 1>as it's clay to accommodate this. You told

00:44:58.410 --> 00:44:59.930
<v Speaker 1>me this is a fork. Fine. Alright. It's

00:44:59.930 --> 00:45:01.530
<v Speaker 1>a fork. I believe you. Whatever. I'll change

00:45:01.530 --> 00:45:04.305
<v Speaker 1>myself to to accommodate this weird, you know,

00:45:04.625 --> 00:45:06.065
<v Speaker 1>I don't know, a

00:45:06.065 --> 00:45:08.705
<v Speaker 1>Victorian style tea fork or whatever whatever it

00:45:08.705 --> 00:45:09.505
<v Speaker 1>is. Alright.

00:45:09.745 --> 00:45:11.265
<v Speaker 1>So next up,

00:45:11.665 --> 00:45:13.025
<v Speaker 1>fork or nonfork?

00:45:13.345 --> 00:45:14.625
<v Speaker 0>I'm gonna stick with fork.

00:45:15.480 --> 00:45:17.720
<v Speaker 1>Agreed. This is a fork as far as

00:45:17.720 --> 00:45:19.960
<v Speaker 1>I'm concerned too. But let's actually just take

00:45:19.960 --> 00:45:21.800
<v Speaker 1>a second here and observe some differences.

00:45:21.960 --> 00:45:23.800
<v Speaker 1>The forks that we've seen so far have

00:45:23.800 --> 00:45:25.720
<v Speaker 1>four tines. This one has five tines.

00:45:27.345 --> 00:45:30.224
<v Speaker 1>The forks that we've seen before all merge

00:45:30.224 --> 00:45:32.305
<v Speaker 1>down at the base of the tines.

00:45:32.385 --> 00:45:34.865
<v Speaker 1>This one has a perplexing gap.

00:45:35.425 --> 00:45:36.705
<v Speaker 1>So if we were to put it in

00:45:36.705 --> 00:45:38.545
<v Speaker 1>the mold, we would say, wait a second.

00:45:38.545 --> 00:45:40.145
<v Speaker 1>This this isn't a fork. The mold would

00:45:40.145 --> 00:45:41.750
<v Speaker 1>reject it. So the mold has to update

00:45:41.750 --> 00:45:43.670
<v Speaker 1>itself. Right? As we dip it in, now

00:45:43.670 --> 00:45:45.830
<v Speaker 1>it's going to make space in the clay

00:45:45.830 --> 00:45:47.430
<v Speaker 1>to account for forks like this.

00:45:48.070 --> 00:45:50.070
<v Speaker 1>Next up, fork or non fork?

00:45:50.310 --> 00:45:51.350
<v Speaker 0>Definite fork.

00:45:51.750 --> 00:45:53.750
<v Speaker 1>Definite fork agreed. What do you think is

00:45:53.750 --> 00:45:55.190
<v Speaker 1>gonna happen when we try to overlay it?

00:45:58.005 --> 00:45:59.765
<v Speaker 1>We have to rotate it. Right? If we

00:45:59.765 --> 00:46:01.845
<v Speaker 1>put it in horizontally, it's not gonna work.

00:46:01.845 --> 00:46:03.765
<v Speaker 1>Right? So now what we're saying to the

00:46:03.765 --> 00:46:06.244
<v Speaker 1>mold is a fork is a fork regardless

00:46:06.244 --> 00:46:08.325
<v Speaker 1>of which way it's presented to you. Right?

00:46:08.650 --> 00:46:11.050
<v Speaker 1>You you need to to account for different

00:46:11.050 --> 00:46:14.330
<v Speaker 1>rotations of a potential fork. Right? So we'll

00:46:14.330 --> 00:46:16.250
<v Speaker 1>layer that in. And the mold at this

00:46:16.250 --> 00:46:19.530
<v Speaker 1>point learns, ah, so orientation doesn't matter. Right?

00:46:19.610 --> 00:46:21.369
<v Speaker 1>Like, as long as I I can sort

00:46:21.369 --> 00:46:23.495
<v Speaker 1>of standardize the way that I'm observing these,

00:46:23.495 --> 00:46:25.335
<v Speaker 1>as long as they have these characteristics

00:46:25.335 --> 00:46:27.415
<v Speaker 1>and you're starting to see with the overlay

00:46:27.415 --> 00:46:30.295
<v Speaker 1>what exactly a fork looks like. Right? There's

00:46:30.295 --> 00:46:32.215
<v Speaker 1>a little bit of gap between the tines.

00:46:32.215 --> 00:46:34.375
<v Speaker 1>There are tines. There's a a part of

00:46:34.375 --> 00:46:36.455
<v Speaker 1>the fork where it all merges together, and

00:46:36.455 --> 00:46:37.859
<v Speaker 1>there's a handle. Right?

00:46:38.740 --> 00:46:40.339
<v Speaker 1>Let's look at another example.

00:46:40.819 --> 00:46:42.180
<v Speaker 1>Fork or nonfork?

00:46:45.059 --> 00:46:47.460
<v Speaker 0>I mean, I guess technically it's a fork,

00:46:47.460 --> 00:46:48.579
<v Speaker 0>but I wanna say not a fork.

00:46:49.905 --> 00:46:52.305
<v Speaker 1>It's so. I I for the purposes of

00:46:52.305 --> 00:46:54.465
<v Speaker 1>this highly contrived example,

00:46:54.705 --> 00:46:56.545
<v Speaker 1>it is a pitchfork exactly.

00:46:56.865 --> 00:46:57.425
<v Speaker 1>And

00:46:57.905 --> 00:46:58.785
<v Speaker 1>and

00:46:59.585 --> 00:47:01.839
<v Speaker 1>but you're you're right. It in I'm gonna

00:47:01.839 --> 00:47:03.359
<v Speaker 1>call pitchfork a fork. It has fork in

00:47:03.359 --> 00:47:05.520
<v Speaker 1>the name. I'm not a linguist. You know?

00:47:05.680 --> 00:47:07.760
<v Speaker 1>Don't don't hate me. But let's see what

00:47:07.760 --> 00:47:09.280
<v Speaker 1>the model would say. Well, the mold would

00:47:09.280 --> 00:47:11.440
<v Speaker 1>say, nah. This doesn't fit in comfortably.

00:47:11.599 --> 00:47:13.520
<v Speaker 1>Right? This is this is not a fork.

00:47:13.520 --> 00:47:15.440
<v Speaker 1>Okay. So now the model has to take

00:47:15.440 --> 00:47:17.175
<v Speaker 1>into account a

00:47:18.295 --> 00:47:20.535
<v Speaker 1>fork that has an odd ratio of length

00:47:20.535 --> 00:47:22.695
<v Speaker 1>of handle to length of time. Right?

00:47:22.935 --> 00:47:24.375
<v Speaker 1>Right? And that that would be different. Think

00:47:24.375 --> 00:47:26.135
<v Speaker 1>about a rake. Right? That that also looks

00:47:26.135 --> 00:47:28.295
<v Speaker 1>like but it's not. Right? So think about

00:47:28.295 --> 00:47:30.535
<v Speaker 1>that. So now the model says, David, you're

00:47:30.535 --> 00:47:33.450
<v Speaker 1>killing me here. Right? Does the handle even

00:47:33.450 --> 00:47:34.810
<v Speaker 1>matter at all?

00:47:35.370 --> 00:47:38.250
<v Speaker 1>And the the the the the model in

00:47:38.250 --> 00:47:39.530
<v Speaker 1>this case is saying,

00:47:41.210 --> 00:47:44.025
<v Speaker 1>I guess not. Right? The the thing that

00:47:44.025 --> 00:47:46.025
<v Speaker 1>seems to be important are these tines and

00:47:46.025 --> 00:47:47.464
<v Speaker 1>the fact that they come together and there's

00:47:47.464 --> 00:47:48.984
<v Speaker 1>a little space between them and yada yada.

00:47:48.984 --> 00:47:51.065
<v Speaker 1>It seems like the handle is irrelevant. Right?

00:47:51.385 --> 00:47:54.265
<v Speaker 1>So you know what? I'm gonna ignore handles.

00:47:54.425 --> 00:47:56.505
<v Speaker 1>I'm just gonna chop a section of myself

00:47:56.760 --> 00:47:59.240
<v Speaker 1>out so that any handle that comes, you

00:47:59.240 --> 00:48:01.720
<v Speaker 1>know, through I'm just gonna disregard that. Apologies.

00:48:01.800 --> 00:48:03.960
<v Speaker 1>My dog is harassing me.

00:48:04.200 --> 00:48:07.720
<v Speaker 1>I'm gonna completely I'm gonna completely ignore

00:48:07.720 --> 00:48:08.520
<v Speaker 1>handles.

00:48:08.520 --> 00:48:10.120
<v Speaker 1>Alright? Now

00:48:11.945 --> 00:48:13.225
<v Speaker 1>is this a fork?

00:48:14.105 --> 00:48:15.065
<v Speaker 1>What do you think?

00:48:15.385 --> 00:48:16.105
<v Speaker 1>No.

00:48:16.825 --> 00:48:20.265
<v Speaker 1>No. But similar to a fork. Right? Yeah.

00:48:20.265 --> 00:48:22.825
<v Speaker 1>So if if we were to compare this,

00:48:22.825 --> 00:48:23.945
<v Speaker 1>you know, the model would say,

00:48:24.770 --> 00:48:26.849
<v Speaker 1>okay. Yeah. That's a fork. From what I

00:48:26.849 --> 00:48:28.609
<v Speaker 1>can tell, in order for something to be

00:48:28.609 --> 00:48:29.730
<v Speaker 1>a fork, it has to have tines and

00:48:29.730 --> 00:48:31.570
<v Speaker 1>it has to come together at the bottom.

00:48:31.570 --> 00:48:34.369
<v Speaker 1>Right? But that's actually not true. Right? It

00:48:34.369 --> 00:48:36.130
<v Speaker 1>must have a handle to be considered a

00:48:36.130 --> 00:48:39.075
<v Speaker 1>fork. Right? And some some there's some ratio

00:48:39.075 --> 00:48:40.835
<v Speaker 1>of handle to time length that we were

00:48:40.835 --> 00:48:42.275
<v Speaker 1>not exactly sure what it is, but we

00:48:42.275 --> 00:48:43.555
<v Speaker 1>know for sure you're telling me this isn't

00:48:43.555 --> 00:48:45.075
<v Speaker 1>a fork, then I know I need to

00:48:45.075 --> 00:48:46.675
<v Speaker 1>be looking at the handle. Right?

00:48:47.235 --> 00:48:47.875
<v Speaker 1>So

00:48:48.115 --> 00:48:49.715
<v Speaker 1>the mold would say, it looks like a

00:48:49.715 --> 00:48:51.800
<v Speaker 1>fork to me. The comb admits it, you

00:48:51.800 --> 00:48:53.480
<v Speaker 1>know, comes comes out of the closet, admits

00:48:53.480 --> 00:48:55.080
<v Speaker 1>that it's a comb. And,

00:48:55.560 --> 00:48:57.240
<v Speaker 1>you know, the the model then, you know,

00:48:57.240 --> 00:48:59.640
<v Speaker 1>says, okay. I need to consider the handle

00:48:59.640 --> 00:49:02.200
<v Speaker 1>when evaluating, but apparently, I don't really care

00:49:02.280 --> 00:49:04.585
<v Speaker 1>how long the handle is. Right? So you

00:49:04.745 --> 00:49:06.105
<v Speaker 1>this is the process.

00:49:06.985 --> 00:49:09.145
<v Speaker 1>Credit all credit due thank you, Solomon. All

00:49:09.145 --> 00:49:11.145
<v Speaker 1>credit due to Andrew

00:49:11.785 --> 00:49:14.345
<v Speaker 1>Tresk who wrote wrote this book. Is a

00:49:14.345 --> 00:49:15.145
<v Speaker 1>sport a sport?

00:49:18.119 --> 00:49:19.319
<v Speaker 0>I think we have to answer all the

00:49:19.319 --> 00:49:22.040
<v Speaker 0>difficult questions today, don't we? Like Well,

00:49:22.040 --> 00:49:24.760
<v Speaker 1>it's it's so funny. So so my girlfriend

00:49:24.760 --> 00:49:26.440
<v Speaker 1>is a is a lawyer. She's gonna hate

00:49:26.440 --> 00:49:28.359
<v Speaker 1>me for referencing this. My girlfriend is a

00:49:28.359 --> 00:49:28.920
<v Speaker 1>lawyer,

00:49:29.240 --> 00:49:31.984
<v Speaker 1>but she studied linguistics in college. And,

00:49:32.464 --> 00:49:34.704
<v Speaker 1>and the the there was a supreme court

00:49:34.704 --> 00:49:36.785
<v Speaker 1>case here in The United States where,

00:49:37.585 --> 00:49:39.984
<v Speaker 1>where you're not allowed to destroy financial records.

00:49:39.984 --> 00:49:41.585
<v Speaker 1>Right? Like, if if, you know, the government

00:49:41.585 --> 00:49:42.944
<v Speaker 1>wants to investigate, you can't just throw it

00:49:42.944 --> 00:49:44.625
<v Speaker 1>all in a dumpster fire and say, I

00:49:44.625 --> 00:49:46.740
<v Speaker 1>don't have any records. Right? And there was

00:49:46.740 --> 00:49:48.900
<v Speaker 1>someone who was caught fishing and and fishing

00:49:48.900 --> 00:49:51.300
<v Speaker 1>fish that he wasn't allowed to fish, and

00:49:51.300 --> 00:49:54.180
<v Speaker 1>he threw the the the

00:49:54.660 --> 00:49:56.500
<v Speaker 1>not to put what I don't know. Not

00:49:56.500 --> 00:49:58.100
<v Speaker 1>illegal. I guess illegal. The the fish he

00:49:58.100 --> 00:50:00.260
<v Speaker 1>wasn't supposed to catch, threw overboard before the,

00:50:00.260 --> 00:50:02.895
<v Speaker 1>you know, police boat caught up with him.

00:50:03.135 --> 00:50:03.615
<v Speaker 1>And,

00:50:04.095 --> 00:50:06.655
<v Speaker 1>and so the government argued that a fish

00:50:06.655 --> 00:50:08.815
<v Speaker 1>was a record, that you have thrown a

00:50:08.815 --> 00:50:09.535
<v Speaker 1>fish out.

00:50:09.775 --> 00:50:11.295
<v Speaker 1>And in this case, the fish is the

00:50:11.295 --> 00:50:13.375
<v Speaker 1>record. Right? But he would you know, his

00:50:13.375 --> 00:50:15.375
<v Speaker 1>lawyers argued, a record's a record. A fish

00:50:15.375 --> 00:50:17.630
<v Speaker 1>is a fish. So these these sort of

00:50:17.630 --> 00:50:21.550
<v Speaker 1>ontological questions, these definition questions are super important.

00:50:21.790 --> 00:50:24.910
<v Speaker 1>And I think your your your comment highlights

00:50:24.910 --> 00:50:26.830
<v Speaker 1>just how important it is to label things

00:50:26.830 --> 00:50:29.710
<v Speaker 1>correctly, right, and to understand cultural perspective. Like,

00:50:30.234 --> 00:50:31.595
<v Speaker 1>as far as I'm concerned, this is not

00:50:31.595 --> 00:50:33.435
<v Speaker 1>a fork, but I don't I I don't

00:50:33.435 --> 00:50:35.355
<v Speaker 1>speak for every person on planet Earth. I

00:50:35.355 --> 00:50:37.035
<v Speaker 1>have no idea. Like, maybe this is a

00:50:37.035 --> 00:50:39.994
<v Speaker 1>fork. You know? Maybe this is a maybe

00:50:39.994 --> 00:50:41.515
<v Speaker 1>this is a fork to somebody else out

00:50:41.515 --> 00:50:43.569
<v Speaker 1>there, or maybe there's only one word, right,

00:50:43.569 --> 00:50:45.650
<v Speaker 1>that that we that exists in a in

00:50:45.650 --> 00:50:46.530
<v Speaker 1>a language,

00:50:46.849 --> 00:50:49.410
<v Speaker 1>human or extraterrestrial to describe this this object.

00:50:49.410 --> 00:50:51.970
<v Speaker 1>So that the model only knows what you

00:50:51.970 --> 00:50:55.010
<v Speaker 1>show it. Right? And and and its its

00:50:55.010 --> 00:50:56.450
<v Speaker 1>universe is restricted

00:50:56.450 --> 00:50:57.970
<v Speaker 1>to the data that you train it on,

00:50:57.970 --> 00:50:59.675
<v Speaker 1>the the images of forks being the data

00:50:59.675 --> 00:51:01.035
<v Speaker 1>that we've trained it on in this case.

00:51:01.035 --> 00:51:01.995
<v Speaker 1>Does that make sense?

00:51:02.555 --> 00:51:04.315
<v Speaker 0>Yes. Am I am I doing okay? Am

00:51:04.315 --> 00:51:05.595
<v Speaker 0>I winning the fart game?

00:51:06.315 --> 00:51:07.994
<v Speaker 1>Yeah. So far, you've done a great job.

00:51:07.994 --> 00:51:10.235
<v Speaker 1>Yeah. Yeah. Yeah. Yeah. Okay.

00:51:10.875 --> 00:51:12.490
<v Speaker 1>Yeah. I would I would encourage you to

00:51:12.490 --> 00:51:15.849
<v Speaker 1>take up, data labeling if you ever have

00:51:15.849 --> 00:51:16.809
<v Speaker 1>extra

00:51:16.809 --> 00:51:18.490
<v Speaker 1>time. But you can see this is this

00:51:18.490 --> 00:51:20.170
<v Speaker 1>is the the challenge. Right? How do we

00:51:20.170 --> 00:51:21.450
<v Speaker 1>label data? How do we ensure that the

00:51:21.450 --> 00:51:24.165
<v Speaker 1>data is labeled correctly? How do I if

00:51:24.165 --> 00:51:26.565
<v Speaker 1>I have a model that's continuously learning, how

00:51:26.565 --> 00:51:27.925
<v Speaker 1>do I not how do I know that

00:51:27.925 --> 00:51:30.165
<v Speaker 1>someone isn't feeding me a bunch of combs

00:51:30.165 --> 00:51:32.405
<v Speaker 1>to attack my model? Now it's now my

00:51:32.405 --> 00:51:34.085
<v Speaker 1>model's gonna start thinking that combs are forks.

00:51:34.085 --> 00:51:36.565
<v Speaker 1>That's not good. So Is that something analogy.

00:51:37.329 --> 00:51:38.609
<v Speaker 0>Are you okay for a question just now?

00:51:38.609 --> 00:51:40.450
<v Speaker 0>Yeah. What's up? Please. Yeah. As many as

00:51:40.450 --> 00:51:41.970
<v Speaker 1>you'd like. So how

00:51:42.690 --> 00:51:44.770
<v Speaker 0>one of, you know, I am

00:51:45.410 --> 00:51:47.890
<v Speaker 0>putting us online as a quiz and encouraging

00:51:47.890 --> 00:51:49.650
<v Speaker 0>people to answer questions to help me train

00:51:49.650 --> 00:51:51.730
<v Speaker 0>my model and there are bad actors that

00:51:51.730 --> 00:51:54.025
<v Speaker 0>are, you know, throwing in bad data. Is

00:51:54.025 --> 00:51:56.345
<v Speaker 0>that easy to identify and work with? Is

00:51:56.505 --> 00:51:58.105
<v Speaker 0>does that ruin the whole model?

00:51:59.865 --> 00:52:00.505
<v Speaker 1>Yeah.

00:52:00.985 --> 00:52:03.305
<v Speaker 1>It does, and it is a challenge.

00:52:03.865 --> 00:52:04.505
<v Speaker 1>So

00:52:06.265 --> 00:52:08.105
<v Speaker 1>I'm trying to remember. I believe it was

00:52:08.105 --> 00:52:08.665
<v Speaker 1>the

00:52:09.430 --> 00:52:09.910
<v Speaker 1>I

00:52:10.470 --> 00:52:12.230
<v Speaker 1>have to remember the name of the podcast.

00:52:12.230 --> 00:52:14.470
<v Speaker 1>It it it was, I don't think it

00:52:14.470 --> 00:52:16.310
<v Speaker 1>was it wasn't the Go Time podcast, but

00:52:16.310 --> 00:52:17.270
<v Speaker 1>it's the same,

00:52:17.510 --> 00:52:19.110
<v Speaker 1>network of podcasts.

00:52:20.150 --> 00:52:22.230
<v Speaker 1>Oh, thanks, Salman. Really appreciate the feedback.

00:52:23.005 --> 00:52:25.565
<v Speaker 1>It's the same network of of podcasts. Anyways,

00:52:25.645 --> 00:52:26.765
<v Speaker 1>they had

00:52:27.725 --> 00:52:29.965
<v Speaker 1>very interesting discussion

00:52:30.605 --> 00:52:33.805
<v Speaker 1>with some of the folks from Mozilla

00:52:33.805 --> 00:52:35.085
<v Speaker 1>who are,

00:52:35.645 --> 00:52:35.965
<v Speaker 1>you know,

00:52:37.820 --> 00:52:38.700
<v Speaker 1>Mozilla,

00:52:39.740 --> 00:52:40.460
<v Speaker 1>really,

00:52:41.020 --> 00:52:43.900
<v Speaker 1>you're doing you're doing, really important work, and

00:52:43.900 --> 00:52:46.220
<v Speaker 1>thank you. I'm sure, you know, it's it's

00:52:46.220 --> 00:52:47.980
<v Speaker 1>a challenge. But one of the issues is,

00:52:47.980 --> 00:52:51.355
<v Speaker 1>you know, there's really a dearth of material

00:52:51.355 --> 00:52:54.235
<v Speaker 1>for, like, natural language processing in

00:52:56.555 --> 00:52:58.555
<v Speaker 1>languages with that don't have a huge

00:52:59.435 --> 00:53:01.915
<v Speaker 1>community of speakers. Right? So

00:53:02.315 --> 00:53:03.835
<v Speaker 1>how they have a a

00:53:04.539 --> 00:53:07.980
<v Speaker 1>great system whereby, essentially, the labeling

00:53:08.940 --> 00:53:11.099
<v Speaker 1>people can contribute, right, spoken

00:53:12.539 --> 00:53:14.859
<v Speaker 1>versions of of text that's read.

00:53:16.299 --> 00:53:16.539
<v Speaker 1>And

00:53:18.845 --> 00:53:21.244
<v Speaker 1>and then that goes through a peer review

00:53:21.885 --> 00:53:23.085
<v Speaker 1>process,

00:53:23.325 --> 00:53:25.645
<v Speaker 1>if that makes sense. Right? So so people

00:53:25.645 --> 00:53:27.565
<v Speaker 1>will double check to confirm that you're not

00:53:27.565 --> 00:53:28.845
<v Speaker 1>attempting to submit

00:53:29.805 --> 00:53:30.684
<v Speaker 1>bad data.

00:53:31.190 --> 00:53:33.910
<v Speaker 1>The other resource that I would encourage folks

00:53:33.910 --> 00:53:36.150
<v Speaker 1>to take a look at is David Aronchik,

00:53:36.230 --> 00:53:38.070
<v Speaker 1>who's one of the cofounders

00:53:38.070 --> 00:53:39.110
<v Speaker 1>of Kubeflow,

00:53:39.670 --> 00:53:42.470
<v Speaker 1>currently runs open source machine learning over at

00:53:42.470 --> 00:53:43.190
<v Speaker 1>Microsoft.

00:53:43.670 --> 00:53:46.550
<v Speaker 1>He gave a KubeCon talk this past KubeCon,

00:53:47.015 --> 00:53:49.095
<v Speaker 1>the most recent one, in which he spoke

00:53:49.095 --> 00:53:52.215
<v Speaker 1>about different attack vectors and for machine learning

00:53:52.215 --> 00:53:53.655
<v Speaker 1>models and ways to

00:53:54.295 --> 00:53:55.415
<v Speaker 1>ways to

00:53:55.815 --> 00:53:58.455
<v Speaker 1>mitigate them. But, yeah, if you're if you're

00:53:58.455 --> 00:54:00.055
<v Speaker 1>taking input from the community,

00:54:01.530 --> 00:54:02.810
<v Speaker 1>you know, we I think we've seen that

00:54:02.810 --> 00:54:04.250
<v Speaker 1>quite a bit with with sort of the

00:54:04.250 --> 00:54:06.330
<v Speaker 1>issues of, news bubbles

00:54:06.330 --> 00:54:08.010
<v Speaker 1>on social media networks,

00:54:08.090 --> 00:54:08.650
<v Speaker 1>right,

00:54:09.530 --> 00:54:11.050
<v Speaker 1>where the the

00:54:11.210 --> 00:54:11.930
<v Speaker 1>the

00:54:12.010 --> 00:54:13.530
<v Speaker 1>stream of of

00:54:14.805 --> 00:54:17.285
<v Speaker 1>information, stream of of of news

00:54:17.365 --> 00:54:19.365
<v Speaker 1>that gets the most reaction,

00:54:19.365 --> 00:54:21.045
<v Speaker 1>you know, continues to feed on, and it

00:54:21.045 --> 00:54:24.085
<v Speaker 1>leads to extremes and perspectives and exclusion of

00:54:24.085 --> 00:54:25.125
<v Speaker 1>counter perspectives.

00:54:25.685 --> 00:54:27.930
<v Speaker 1>So, yes, this is this is a a

00:54:27.930 --> 00:54:28.330
<v Speaker 1>a

00:54:28.730 --> 00:54:31.130
<v Speaker 1>the ethics around AI are

00:54:31.290 --> 00:54:32.170
<v Speaker 1>incredibly

00:54:32.170 --> 00:54:32.890
<v Speaker 1>important,

00:54:32.970 --> 00:54:33.370
<v Speaker 1>and

00:54:34.570 --> 00:54:36.170
<v Speaker 1>and, everyone

00:54:36.170 --> 00:54:38.570
<v Speaker 1>needs to be extreme needs to pay extreme

00:54:38.570 --> 00:54:40.585
<v Speaker 1>attention to them and and be aware of

00:54:40.585 --> 00:54:42.825
<v Speaker 1>who you're excluding. Think about this. If you're

00:54:43.865 --> 00:54:45.065
<v Speaker 1>and I think

00:54:45.545 --> 00:54:46.505
<v Speaker 1>999

00:54:46.505 --> 00:54:48.585
<v Speaker 1>for you all, 911 for us, you know,

00:54:48.585 --> 00:54:49.545
<v Speaker 1>an emergency

00:54:49.705 --> 00:54:50.345
<v Speaker 1>response,

00:54:51.065 --> 00:54:53.785
<v Speaker 1>if if you've only trained on people with

00:54:54.600 --> 00:54:55.960
<v Speaker 1>native accents,

00:54:56.280 --> 00:54:59.480
<v Speaker 1>right, 20 Yeah. 20 of America's foreign born.

00:54:59.480 --> 00:55:00.120
<v Speaker 1>Right?

00:55:00.760 --> 00:55:02.680
<v Speaker 1>So guarantee that these I mean, heck,

00:55:03.240 --> 00:55:05.640
<v Speaker 1>you for we pronounce things differently. We speak

00:55:05.640 --> 00:55:08.305
<v Speaker 1>the same language. So, you know, the this

00:55:08.625 --> 00:55:11.425
<v Speaker 1>these questions can't be afterthoughts. They must be

00:55:11.425 --> 00:55:13.185
<v Speaker 1>be preliminary thoughts,

00:55:14.065 --> 00:55:16.065
<v Speaker 1>prerequisites to to using this. So

00:55:16.785 --> 00:55:17.425
<v Speaker 0>Nice.

00:55:17.825 --> 00:55:19.265
<v Speaker 0>Yeah. I guess it it helps to be

00:55:19.265 --> 00:55:21.080
<v Speaker 0>Google. Right? Mean, you can just launch something

00:55:21.080 --> 00:55:23.240
<v Speaker 0>called recapture claim it for security, but really

00:55:23.240 --> 00:55:25.320
<v Speaker 0>you're training all your internal models.

00:55:25.320 --> 00:55:25.720
<v Speaker 1>Exactly.

00:55:27.080 --> 00:55:29.480
<v Speaker 1>Exactly. Please click the one with the motorbike

00:55:29.480 --> 00:55:30.120
<v Speaker 0>on it.

00:55:30.760 --> 00:55:32.760
<v Speaker 0>So we do have a a couple of

00:55:32.760 --> 00:55:34.075
<v Speaker 0>questions. I don't know if you wanna them

00:55:34.075 --> 00:55:35.675
<v Speaker 0>now, whether you wanna take them as we

00:55:35.675 --> 00:55:37.435
<v Speaker 0>go. I'll let you decide if they're appropriate

00:55:37.435 --> 00:55:38.875
<v Speaker 0>for the moment or if you're gonna cover

00:55:38.875 --> 00:55:40.875
<v Speaker 0>it later, just say. So while it is

00:55:40.875 --> 00:55:41.595
<v Speaker 0>asking,

00:55:41.675 --> 00:55:43.035
<v Speaker 0>do you have any advice for people that

00:55:43.035 --> 00:55:45.275
<v Speaker 0>wanna run it on restricted networks on prem?

00:55:49.950 --> 00:55:50.590
<v Speaker 1>Yes.

00:55:51.230 --> 00:55:54.590
<v Speaker 1>Come to the Kubeflow on prem speciality group

00:55:54.830 --> 00:55:56.830
<v Speaker 1>meetings. Those are on Thursdays.

00:55:57.230 --> 00:55:58.590
<v Speaker 1>We also have,

00:55:59.630 --> 00:56:02.270
<v Speaker 1>we also have a

00:56:03.384 --> 00:56:05.865
<v Speaker 1>a mailing list, a dedicated mailing list, that

00:56:05.865 --> 00:56:07.545
<v Speaker 1>we use for our SIG.

00:56:07.865 --> 00:56:08.425
<v Speaker 1>So,

00:56:09.865 --> 00:56:10.904
<v Speaker 1>George is,

00:56:11.224 --> 00:56:12.744
<v Speaker 1>is helping us out too,

00:56:13.144 --> 00:56:13.704
<v Speaker 1>so,

00:56:14.025 --> 00:56:16.100
<v Speaker 1>maybe he can share a link to that.

00:56:16.100 --> 00:56:18.020
<v Speaker 1>Our meetings alternate between

00:56:19.140 --> 00:56:20.820
<v Speaker 1>European friendly times and

00:56:22.500 --> 00:56:24.740
<v Speaker 1>West Coast friendly times and Asia Pacific friendly

00:56:24.740 --> 00:56:26.740
<v Speaker 1>times. They're on Thursdays. We'd love for you

00:56:26.740 --> 00:56:29.525
<v Speaker 1>to come join our join Kubeflow Slack. We

00:56:29.525 --> 00:56:31.045
<v Speaker 1>have a channel there too, and we'll be

00:56:31.045 --> 00:56:33.205
<v Speaker 1>more than happy to help you.

00:56:34.725 --> 00:56:37.045
<v Speaker 1>As as one of Jeff Fogarty, who's one

00:56:37.045 --> 00:56:38.005
<v Speaker 1>of the the

00:56:38.965 --> 00:56:42.645
<v Speaker 1>coleads of the special interest group and runs

00:56:42.885 --> 00:56:46.750
<v Speaker 1>production Kubeflow clusters on premises for a big

00:56:46.750 --> 00:56:48.990
<v Speaker 1>American bank says, if it's not behind the

00:56:48.990 --> 00:56:50.190
<v Speaker 1>proxy, it doesn't count.

00:56:50.510 --> 00:56:52.670
<v Speaker 1>So you will find lots of lots of

00:56:52.670 --> 00:56:54.030
<v Speaker 1>kindred spirits there.

00:56:54.750 --> 00:56:57.549
<v Speaker 1>Let's see. I have other questions in the

00:56:57.549 --> 00:56:58.190
<v Speaker 1>chat here.

00:56:58.755 --> 00:57:00.195
<v Speaker 1>Happy to take them.

00:57:02.115 --> 00:57:05.555
<v Speaker 1>Solomon, a great question regarding Istio.

00:57:06.674 --> 00:57:08.755
<v Speaker 1>So the question is why why was Istio

00:57:08.755 --> 00:57:10.755
<v Speaker 1>chosen as a service mesh for Kubeflow?

00:57:11.234 --> 00:57:13.880
<v Speaker 1>I think that this is where the politics

00:57:13.880 --> 00:57:15.960
<v Speaker 1>of, open source come into play.

00:57:16.279 --> 00:57:19.800
<v Speaker 1>Istio, obviously, a Google and IBM

00:57:19.960 --> 00:57:20.840
<v Speaker 1>collaboration.

00:57:21.720 --> 00:57:23.400
<v Speaker 1>And so I I think that that was

00:57:23.400 --> 00:57:24.695
<v Speaker 1>that was the way the way to go.

00:57:24.695 --> 00:57:26.055
<v Speaker 1>For a long time also, I think Istio

00:57:26.295 --> 00:57:27.815
<v Speaker 1>you know, Linkerd at the time didn't have

00:57:27.815 --> 00:57:31.015
<v Speaker 1>a sidecar proxy model, and, so it didn't

00:57:31.015 --> 00:57:32.935
<v Speaker 1>get anywhere near the kind of performance,

00:57:33.335 --> 00:57:34.135
<v Speaker 1>that

00:57:34.215 --> 00:57:35.655
<v Speaker 1>that Istio did. It, you know, had some

00:57:35.655 --> 00:57:37.575
<v Speaker 1>scaling issues. Now they moved to a

00:57:38.700 --> 00:57:40.300
<v Speaker 1>a sidecar model as far as I understand.

00:57:40.300 --> 00:57:41.980
<v Speaker 1>And now everyone and their brother-in-law has a

00:57:41.980 --> 00:57:44.380
<v Speaker 1>service mesh. So to the question of,

00:57:45.740 --> 00:57:47.580
<v Speaker 1>you know, are there plans to allow for

00:57:47.580 --> 00:57:50.780
<v Speaker 1>different service mesh? Yes. And simply by asking

00:57:50.780 --> 00:57:52.895
<v Speaker 1>that question, you are now mandated

00:57:53.055 --> 00:57:54.975
<v Speaker 1>by law to come to our working group

00:57:54.975 --> 00:57:57.215
<v Speaker 1>meetings because we are working on,

00:57:58.015 --> 00:58:01.135
<v Speaker 1>with, one of our technical co, coleads,

00:58:01.855 --> 00:58:04.895
<v Speaker 1>Marlo Weston, who works at, Intel.

00:58:05.330 --> 00:58:07.490
<v Speaker 1>We are spearheading

00:58:07.490 --> 00:58:10.530
<v Speaker 1>an attempt to get service mesh interface

00:58:10.610 --> 00:58:14.290
<v Speaker 1>implemented to allow anyone service mesh a day

00:58:14.290 --> 00:58:16.290
<v Speaker 1>in the sun and to, you know, decouple

00:58:16.290 --> 00:58:18.450
<v Speaker 1>in some way a dependency on on Istio.

00:58:19.365 --> 00:58:21.765
<v Speaker 1>Super early days. Do not get your hopes

00:58:21.765 --> 00:58:22.325
<v Speaker 1>up.

00:58:22.805 --> 00:58:24.965
<v Speaker 1>But, you know, that I think there's a

00:58:24.965 --> 00:58:26.965
<v Speaker 1>lot of, I think there's a lot of

00:58:27.605 --> 00:58:30.245
<v Speaker 1>really exciting work going on, in that regard

00:58:30.245 --> 00:58:32.040
<v Speaker 1>too. So yep.

00:58:32.120 --> 00:58:33.320
<v Speaker 0>Awesome. Perfect.

00:58:34.200 --> 00:58:35.880
<v Speaker 0>Should we jump back to our forks?

00:58:36.760 --> 00:58:38.200
<v Speaker 1>We're done with forks. Oh, done with the

00:58:38.200 --> 00:58:39.480
<v Speaker 0>forks. Got it. That was that was the

00:58:39.480 --> 00:58:41.240
<v Speaker 1>that was that was that was the the

00:58:41.240 --> 00:58:43.000
<v Speaker 1>whole kit and caboodle. I I was just

00:58:43.000 --> 00:58:44.600
<v Speaker 0>getting a roll there. I feel like you've

00:58:44.600 --> 00:58:45.880
<v Speaker 0>cut me off too soon. I was just

00:58:45.880 --> 00:58:46.760
<v Speaker 0>getting the swing of it.

00:58:49.295 --> 00:58:51.215
<v Speaker 1>Listen, I can't decide if it would be

00:58:51.694 --> 00:58:52.974
<v Speaker 1>if it would be a great job or

00:58:52.974 --> 00:58:54.575
<v Speaker 1>a terrible job to, you know, it's certainly

00:58:54.575 --> 00:58:56.974
<v Speaker 1>not very stressful. But, know, do we do

00:58:56.974 --> 00:58:58.895
<v Speaker 1>I wanna be a full time fork analyzer?

00:58:59.410 --> 00:59:00.770
<v Speaker 0>I know. But if you sit and do

00:59:00.770 --> 00:59:02.690
<v Speaker 0>like 30,000 of those in a day and

00:59:02.690 --> 00:59:04.210
<v Speaker 0>you click one wrong and then you can't

00:59:04.210 --> 00:59:05.490
<v Speaker 0>stop thinking about it and you wake up

00:59:05.490 --> 00:59:06.290
<v Speaker 0>in the middle of the night and you're

00:59:06.290 --> 00:59:07.570
<v Speaker 0>like, what if I have destroyed this model

00:59:07.570 --> 00:59:09.170
<v Speaker 0>by clicking fork and it was like, you

00:59:09.170 --> 00:59:11.650
<v Speaker 0>know, a spark. Like, oh shit. There were

00:59:11.650 --> 00:59:13.010
<v Speaker 0>no rules on that. I I

00:59:13.570 --> 00:59:14.690
<v Speaker 0>not for me. Too stressful.

00:59:15.435 --> 00:59:17.755
<v Speaker 1>Too stressful. Okay. Yeah. No. I I agree.

00:59:17.755 --> 00:59:18.475
<v Speaker 1>I agree.

00:59:19.035 --> 00:59:21.915
<v Speaker 1>You know, better better to to avoid any,

00:59:23.195 --> 00:59:25.195
<v Speaker 1>you know, additional stress

00:59:27.675 --> 00:59:28.635
<v Speaker 1>burden in your life.

00:59:29.920 --> 00:59:32.160
<v Speaker 1>So just to let you know, I have

00:59:32.320 --> 00:59:35.280
<v Speaker 1>up here an example of Kubeflow.

00:59:35.680 --> 00:59:37.680
<v Speaker 1>Can you see that? Okay. Yeah. Can you

00:59:37.680 --> 00:59:38.960
<v Speaker 0>zoom in a bit on that? It's a

00:59:38.960 --> 00:59:40.560
<v Speaker 0>little difficult to read this. Yeah.

00:59:41.760 --> 00:59:43.280
<v Speaker 1>Let me see. Let me zoom it.

00:59:45.505 --> 00:59:47.905
<v Speaker 1>How about that? Let's go two more.

00:59:48.625 --> 00:59:49.825
<v Speaker 1>Two more? Okay.

00:59:50.465 --> 00:59:53.425
<v Speaker 1>Fingers crossed everything works as intended.

00:59:53.585 --> 00:59:55.425
<v Speaker 0>Yeah. I think that's alright. If anyone has

00:59:55.425 --> 00:59:57.105
<v Speaker 0>a problem reading that, just drop in the

00:59:57.105 --> 00:59:58.545
<v Speaker 0>comments. We'll go we'll go more. But it

00:59:58.545 --> 00:59:59.345
<v Speaker 0>looks okay for me.

01:00:00.090 --> 01:00:02.170
<v Speaker 1>Okay. Cool. And just to let you know,

01:00:02.410 --> 01:00:05.210
<v Speaker 1>I have clicked away from seeing the screen

01:00:05.530 --> 01:00:06.810
<v Speaker 1>because I am

01:00:07.130 --> 01:00:07.930
<v Speaker 1>100%

01:00:07.930 --> 01:00:10.410
<v Speaker 1>cheating on this live covert coding exercise.

01:00:12.425 --> 01:00:13.225
<v Speaker 1>Because

01:00:13.305 --> 01:00:15.145
<v Speaker 1>if I if I goof it, it's not

01:00:15.145 --> 01:00:16.825
<v Speaker 1>gonna be fun for anyone to watch. Mean,

01:00:16.825 --> 01:00:18.265
<v Speaker 1>try to debug it. So

01:00:19.225 --> 01:00:21.145
<v Speaker 1>so, yeah, should we get started? Yeah. Let's

01:00:21.145 --> 01:00:23.145
<v Speaker 0>go for it. Any questions come up, I'll

01:00:23.145 --> 01:00:24.025
<v Speaker 0>keep you updated.

01:00:24.345 --> 01:00:25.945
<v Speaker 1>Yes. Thank you. That's that's what I was

01:00:25.945 --> 01:00:27.640
<v Speaker 1>hoping for. Alright. So this is the Kubeflow

01:00:27.640 --> 01:00:28.360
<v Speaker 1>UI.

01:00:28.920 --> 01:00:31.160
<v Speaker 1>Every user has their own namespace,

01:00:33.080 --> 01:00:35.240
<v Speaker 1>and that translates to or a workspace that

01:00:35.240 --> 01:00:37.800
<v Speaker 1>translates to a a Kubernetes namespace.

01:00:38.760 --> 01:00:39.560
<v Speaker 1>Let's open up

01:00:40.925 --> 01:00:42.925
<v Speaker 1>notebooks. Right? So I need an environment in

01:00:42.925 --> 01:00:43.885
<v Speaker 1>which to,

01:00:44.605 --> 01:00:46.045
<v Speaker 1>start my development.

01:00:46.605 --> 01:00:47.245
<v Speaker 1>So,

01:00:48.685 --> 01:00:50.525
<v Speaker 1>what can I what can I do? I

01:00:50.525 --> 01:00:52.685
<v Speaker 1>can give my environment a name. We'll give

01:00:52.685 --> 01:00:53.325
<v Speaker 1>this,

01:00:53.885 --> 01:00:55.244
<v Speaker 1>we'll call this X-ray.

01:00:56.200 --> 01:00:56.840
<v Speaker 1>And,

01:00:57.560 --> 01:00:59.480
<v Speaker 1>I can pick an image that I wanna

01:00:59.480 --> 01:01:01.000
<v Speaker 1>use. I can also use any kind of

01:01:01.000 --> 01:01:03.000
<v Speaker 1>custom image. Most people, you know, will have

01:01:03.000 --> 01:01:05.640
<v Speaker 1>an image that they're for a project. Right?

01:01:05.640 --> 01:01:07.080
<v Speaker 1>So your team is all sort of aligned

01:01:07.080 --> 01:01:07.640
<v Speaker 1>on one thing.

01:01:09.245 --> 01:01:10.525
<v Speaker 1>I can specify

01:01:10.525 --> 01:01:11.325
<v Speaker 1>my

01:01:12.525 --> 01:01:14.285
<v Speaker 1>CPU and and memory

01:01:14.925 --> 01:01:15.885
<v Speaker 1>guarantees.

01:01:15.885 --> 01:01:17.645
<v Speaker 1>So this would be a request.

01:01:18.525 --> 01:01:20.125
<v Speaker 1>There's no

01:01:22.690 --> 01:01:24.930
<v Speaker 1>you know, you don't really necessarily for the

01:01:24.930 --> 01:01:25.490
<v Speaker 1>audience,

01:01:25.810 --> 01:01:27.410
<v Speaker 1>that's gonna be using this. The end user

01:01:27.410 --> 01:01:29.730
<v Speaker 1>data science scientists, you don't necessarily wanna put

01:01:29.730 --> 01:01:31.330
<v Speaker 1>a a a limit on it. That's generally

01:01:31.330 --> 01:01:33.010
<v Speaker 1>sort of an administrative task.

01:01:33.730 --> 01:01:37.010
<v Speaker 1>Let's see here. Oh, this is not

01:01:39.385 --> 01:01:41.065
<v Speaker 1>give me my configurations.

01:01:41.065 --> 01:01:44.105
<v Speaker 1>Oh. Uh-oh. Alright. Time to go to work.

01:01:44.105 --> 01:01:45.865
<v Speaker 1>No. No. No. We're good. We're good. Did

01:01:45.865 --> 01:01:47.305
<v Speaker 1>I tell you it was cooking show style,

01:01:47.305 --> 01:01:48.345
<v Speaker 1>or did I tell you it was cooking

01:01:48.345 --> 01:01:49.225
<v Speaker 1>show style?

01:01:49.385 --> 01:01:50.105
<v Speaker 1>So

01:01:51.160 --> 01:01:53.800
<v Speaker 1>here's a cluster that's actually working. Woo hoo.

01:01:53.800 --> 01:01:55.800
<v Speaker 1>Alright. So I have an example that stood

01:01:55.800 --> 01:01:58.120
<v Speaker 1>up, but we're we're gonna do we're doing

01:01:58.120 --> 01:01:59.560
<v Speaker 1>a live. And I gotta zoom this one

01:01:59.560 --> 01:02:01.560
<v Speaker 1>in, of course, because I didn't I did

01:02:01.560 --> 01:02:03.400
<v Speaker 1>the same on the other one. And just

01:02:03.400 --> 01:02:04.360
<v Speaker 1>tell me when to stop.

01:02:05.225 --> 01:02:06.825
<v Speaker 1>How we want it? Yeah. I think that

01:02:06.825 --> 01:02:08.185
<v Speaker 0>should be alright. Let's take it from there.

01:02:08.185 --> 01:02:08.665
<v Speaker 1>Okay.

01:02:09.305 --> 01:02:11.625
<v Speaker 1>Cool. Thank you for your

01:02:12.025 --> 01:02:14.265
<v Speaker 1>flexibility. So let's call this X-ray two.

01:02:15.865 --> 01:02:17.625
<v Speaker 1>We're gonna do the same thing we did

01:02:17.625 --> 01:02:20.985
<v Speaker 1>before. We're gonna give it a a nice

01:02:19.860 --> 01:02:20.580
<v Speaker 1>big,

01:02:22.260 --> 01:02:23.780
<v Speaker 1>drive. I think I have, like, 200 gig

01:02:23.780 --> 01:02:25.140
<v Speaker 1>on here. So

01:02:25.140 --> 01:02:27.220
<v Speaker 1>another 50 shouldn't hurt anybody. I can add

01:02:27.220 --> 01:02:28.340
<v Speaker 1>extra volumes.

01:02:29.700 --> 01:02:32.100
<v Speaker 1>I wanna be able to interact with Kubeflow

01:02:32.100 --> 01:02:33.700
<v Speaker 1>pipelines. I could also, at this point,

01:02:34.434 --> 01:02:36.115
<v Speaker 1>specify whether I wanna attach this to a

01:02:36.115 --> 01:02:38.275
<v Speaker 1>GPU. I believe I have GPU in this

01:02:38.275 --> 01:02:40.194
<v Speaker 1>cluster, but I don't wanna attach it to

01:02:40.194 --> 01:02:41.395
<v Speaker 1>a GPU because,

01:02:42.115 --> 01:02:43.714
<v Speaker 1>it's just it's it's a it's something I

01:02:43.714 --> 01:02:46.355
<v Speaker 1>advise folks against because most of the time,

01:02:46.355 --> 01:02:48.150
<v Speaker 1>the GPU is gonna be idle. And the

01:02:48.150 --> 01:02:51.109
<v Speaker 1>beauty of Kubernetes is we have shared resources.

01:02:51.109 --> 01:02:53.270
<v Speaker 1>So make a pipeline, have one of the

01:02:53.270 --> 01:02:55.349
<v Speaker 1>pipeline steps, use the GPU, and then let

01:02:55.349 --> 01:02:57.750
<v Speaker 1>other people use it. Right? Does that make

01:02:57.750 --> 01:02:59.829
<v Speaker 1>sense? Makes sense. Definitely. Alright.

01:03:00.365 --> 01:03:01.005
<v Speaker 1>So

01:03:01.565 --> 01:03:02.605
<v Speaker 1>this is

01:03:02.845 --> 01:03:04.765
<v Speaker 1>gonna take a second to come up.

01:03:06.045 --> 01:03:09.165
<v Speaker 1>In the background, I am going to

01:03:09.325 --> 01:03:10.125
<v Speaker 1>SSH

01:03:10.125 --> 01:03:11.005
<v Speaker 1>into

01:03:12.890 --> 01:03:14.730
<v Speaker 0>So what's this spinning up right now? Is

01:03:14.730 --> 01:03:17.130
<v Speaker 0>this the virtual machine inside of Kubernetes?

01:03:17.690 --> 01:03:20.730
<v Speaker 1>A virtual machine inside of Kubernetes. Shame on

01:03:20.730 --> 01:03:23.930
<v Speaker 1>you. You know it's not. No. This is

01:03:25.515 --> 01:03:27.035
<v Speaker 1>no. I know I know you're you're just

01:03:27.035 --> 01:03:28.555
<v Speaker 1>trying to feed me the the line here,

01:03:28.555 --> 01:03:31.355
<v Speaker 1>but, no. No. In fact, no, David. It's

01:03:31.355 --> 01:03:31.755
<v Speaker 1>not.

01:03:32.234 --> 01:03:34.075
<v Speaker 1>This is a this is a container. This

01:03:34.075 --> 01:03:35.595
<v Speaker 1>is a pod that's being deployed to my

01:03:35.595 --> 01:03:36.395
<v Speaker 1>namespace.

01:03:36.714 --> 01:03:37.195
<v Speaker 1>And,

01:03:37.835 --> 01:03:40.234
<v Speaker 1>there's a a a Jupiter,

01:03:41.170 --> 01:03:42.770
<v Speaker 1>like I said, it's gonna be renamed a

01:03:42.770 --> 01:03:45.890
<v Speaker 1>Jupiter web application. It's Jupiter controller that that

01:03:45.890 --> 01:03:47.090
<v Speaker 1>manages that.

01:03:48.370 --> 01:03:50.290
<v Speaker 1>And if you'll notice here,

01:03:51.010 --> 01:03:53.490
<v Speaker 1>there are configurations that I can apply,

01:03:54.585 --> 01:03:55.945
<v Speaker 1>and this uses

01:03:56.425 --> 01:03:57.065
<v Speaker 1>an

01:03:58.025 --> 01:04:01.225
<v Speaker 1>object called pod defaults. I is that I

01:04:01.225 --> 01:04:02.744
<v Speaker 1>I don't know how common the use of

01:04:02.744 --> 01:04:05.545
<v Speaker 1>pod defaults are outside of machine learning and

01:04:05.545 --> 01:04:06.825
<v Speaker 1>Kubeflow in particular.

01:04:06.985 --> 01:04:09.059
<v Speaker 1>But suffice it to say, the way that

01:04:09.059 --> 01:04:11.220
<v Speaker 1>this works is what I'm doing when I

01:04:11.220 --> 01:04:13.859
<v Speaker 1>actually click this, one of these configurations, and

01:04:13.859 --> 01:04:15.539
<v Speaker 1>that could be, you know, for example, you

01:04:15.539 --> 01:04:17.380
<v Speaker 1>know, give me give us give me in

01:04:17.380 --> 01:04:19.220
<v Speaker 1>this notebook, want an environment variable

01:04:20.145 --> 01:04:23.105
<v Speaker 1>that has access to that has the the

01:04:23.105 --> 01:04:24.545
<v Speaker 1>up to date secrets

01:04:24.545 --> 01:04:27.185
<v Speaker 1>for our private container registry or a private,

01:04:27.185 --> 01:04:29.905
<v Speaker 1>you know, git repository or whatever we're doing

01:04:29.905 --> 01:04:32.385
<v Speaker 1>within our environment. Right? Alright. So any anything

01:04:32.385 --> 01:04:34.450
<v Speaker 1>like that. Or it could be, you know,

01:04:34.450 --> 01:04:37.010
<v Speaker 1>a a a you know, maybe I'm about

01:04:37.010 --> 01:04:39.090
<v Speaker 1>to do some stuff that requires a a

01:04:39.090 --> 01:04:39.570
<v Speaker 1>specific

01:04:40.130 --> 01:04:42.290
<v Speaker 1>type of, hard disk at a minimum. So,

01:04:42.290 --> 01:04:44.210
<v Speaker 1>you know, you can access it that way.

01:04:44.210 --> 01:04:46.210
<v Speaker 1>And what the what the pod default controller

01:04:46.210 --> 01:04:47.490
<v Speaker 1>actually does is,

01:04:48.050 --> 01:04:49.475
<v Speaker 1>what we do with the Jupyter web app

01:04:49.475 --> 01:04:51.475
<v Speaker 1>controller does is it puts a label

01:04:51.715 --> 01:04:52.275
<v Speaker 1>that,

01:04:52.755 --> 01:04:54.275
<v Speaker 1>that the the,

01:04:55.075 --> 01:04:57.235
<v Speaker 1>that will be applied to the,

01:04:57.635 --> 01:04:58.355
<v Speaker 1>the

01:04:58.595 --> 01:05:01.315
<v Speaker 1>deployment, the stateful set that's actually being generated

01:05:01.315 --> 01:05:01.955
<v Speaker 1>behind the scenes,

01:05:02.690 --> 01:05:05.410
<v Speaker 1>abstracted for the end user, GUI driven. But,

01:05:05.650 --> 01:05:07.890
<v Speaker 1>it will apply a label to to that,

01:05:07.890 --> 01:05:09.730
<v Speaker 1>and then the pod defaults controller knows to

01:05:09.730 --> 01:05:12.930
<v Speaker 1>observe that that label and then to inject,

01:05:14.290 --> 01:05:16.210
<v Speaker 1>you know, a a config map or a

01:05:16.210 --> 01:05:18.565
<v Speaker 1>secret or or anything like that. You know,

01:05:18.565 --> 01:05:20.245
<v Speaker 1>either it's environment variable or it's a mounted,

01:05:20.245 --> 01:05:22.085
<v Speaker 1>what do they call, projected volume, whatever.

01:05:23.045 --> 01:05:25.045
<v Speaker 1>You're making me dig into my, like, CKA

01:05:25.045 --> 01:05:27.045
<v Speaker 1>studying. This is this is a

01:05:27.365 --> 01:05:28.565
<v Speaker 1>it's been a it's been a while since

01:05:28.565 --> 01:05:30.165
<v Speaker 1>I took that test. Thank goodness they made

01:05:30.165 --> 01:05:32.965
<v Speaker 1>it valid for three years now, though. That's

01:05:32.540 --> 01:05:34.540
<v Speaker 1>huge benefit. I think that feature used to

01:05:34.540 --> 01:05:36.780
<v Speaker 0>live as a pod preset back in the

01:05:36.780 --> 01:05:39.020
<v Speaker 0>day before it was deprecated. Correct. I'm assuming

01:05:39.020 --> 01:05:41.180
<v Speaker 0>it's now just the mission controller and Kubeflow's

01:05:41.180 --> 01:05:43.180
<v Speaker 0>version is called pod defaults. But it's it's

01:05:43.180 --> 01:05:44.300
<v Speaker 0>not something I've used personally.

01:05:45.015 --> 01:05:46.694
<v Speaker 0>At least the the pod default version, I

01:05:46.694 --> 01:05:48.214
<v Speaker 0>mean. But it sounds it sounds like the

01:05:48.214 --> 01:05:49.734
<v Speaker 0>same thing as the old pod presets.

01:05:50.135 --> 01:05:52.214
<v Speaker 1>Exactly. Right. This is this is like a

01:05:52.214 --> 01:05:54.295
<v Speaker 1>successor to that. Yep. Exactly.

01:05:55.494 --> 01:05:56.775
<v Speaker 1>Okay. So what did I do? I just

01:05:56.775 --> 01:05:57.415
<v Speaker 1>clicked

01:05:58.055 --> 01:05:59.654
<v Speaker 1>I just clicked connect,

01:06:00.339 --> 01:06:00.740
<v Speaker 1>and,

01:06:01.140 --> 01:06:01.860
<v Speaker 1>now

01:06:02.020 --> 01:06:04.980
<v Speaker 1>I am presented with a JupyterLab

01:06:04.980 --> 01:06:05.940
<v Speaker 1>environment.

01:06:06.500 --> 01:06:07.460
<v Speaker 1>Right? So,

01:06:07.859 --> 01:06:10.020
<v Speaker 1>you have a a file browser,

01:06:10.900 --> 01:06:12.660
<v Speaker 1>some plug ins. We'll take a look at

01:06:12.660 --> 01:06:13.620
<v Speaker 1>those in a minute.

01:06:14.339 --> 01:06:16.115
<v Speaker 1>First things first

01:06:16.275 --> 01:06:17.715
<v Speaker 1>excuse me. I have to cough.

01:06:19.474 --> 01:06:20.675
<v Speaker 1>First things first,

01:06:20.994 --> 01:06:22.355
<v Speaker 1>we need to get our data. So in

01:06:22.355 --> 01:06:25.475
<v Speaker 1>order to get our data, we need my,

01:06:26.194 --> 01:06:27.075
<v Speaker 1>Kaggle key,

01:06:28.310 --> 01:06:30.710
<v Speaker 1>which I don't know where I put. Actually,

01:06:30.710 --> 01:06:31.990
<v Speaker 1>I do know where I put

01:06:32.950 --> 01:06:34.630
<v Speaker 1>oh, alright. You can share it. But, basically,

01:06:34.630 --> 01:06:36.150
<v Speaker 0>we're very trustworthy here.

01:06:36.790 --> 01:06:39.270
<v Speaker 1>Yeah. I I'm I just don't wanna shame

01:06:39.270 --> 01:06:40.310
<v Speaker 1>myself with,

01:06:40.550 --> 01:06:41.990
<v Speaker 1>let me let me pull up a a

01:06:41.990 --> 01:06:44.665
<v Speaker 1>finder window here and drag and drop.

01:06:45.385 --> 01:06:48.105
<v Speaker 1>Please hold. Alright. So we I need my

01:06:48.105 --> 01:06:49.785
<v Speaker 1>Kaggle key. Kaggle is,

01:06:50.105 --> 01:06:52.425
<v Speaker 1>a great place if you're getting started with

01:06:52.425 --> 01:06:54.665
<v Speaker 1>all this stuff and and you wanna get

01:06:54.665 --> 01:06:56.425
<v Speaker 1>some good datasets to experiment

01:06:57.065 --> 01:07:01.130
<v Speaker 1>with, yada yada, highly recommend highly, highly recommend,

01:07:01.290 --> 01:07:02.730
<v Speaker 1>checking out Kaggle.

01:07:02.890 --> 01:07:04.490
<v Speaker 1>The other thing I'm going to do just

01:07:04.490 --> 01:07:05.290
<v Speaker 1>because it's,

01:07:05.690 --> 01:07:08.490
<v Speaker 1>really boring to go through it one by

01:07:08.490 --> 01:07:10.250
<v Speaker 1>one is copy,

01:07:10.569 --> 01:07:12.329
<v Speaker 1>in a requirements

01:07:12.329 --> 01:07:12.569
<v Speaker 1>file.

01:07:13.145 --> 01:07:13.945
<v Speaker 1>This is

01:07:14.505 --> 01:07:16.265
<v Speaker 1>a Python notebook. So

01:07:17.385 --> 01:07:19.305
<v Speaker 1>there we go. Requirements.

01:07:19.305 --> 01:07:21.704
<v Speaker 1>Okay. So I'm gonna pop open a terminal.

01:07:21.704 --> 01:07:24.744
<v Speaker 1>So this is like if you did kubectl

01:07:24.744 --> 01:07:27.065
<v Speaker 1>exec dash I t dash dash bash or

01:07:27.065 --> 01:07:28.425
<v Speaker 1>something like that, same sort of thing.

01:07:29.280 --> 01:07:31.600
<v Speaker 1>I'm gonna do a few things. First, I'm

01:07:31.600 --> 01:07:33.360
<v Speaker 1>gonna alias l

01:07:33.760 --> 01:07:34.320
<v Speaker 1>oh,

01:07:34.960 --> 01:07:36.640
<v Speaker 1>there we Docs. Be my friend. There we

01:07:36.640 --> 01:07:38.880
<v Speaker 1>go. I'm gonna alias l as

01:07:39.280 --> 01:07:41.920
<v Speaker 1>l s dash a l h. Okay.

01:07:42.080 --> 01:07:43.600
<v Speaker 1>Alright. See, what can we see in here?

01:07:43.600 --> 01:07:44.320
<v Speaker 1>I've got some

01:07:44.795 --> 01:07:45.515
<v Speaker 1>environment

01:07:45.835 --> 01:07:48.715
<v Speaker 1>specific stuff from Jupiter specific stuff. Nothing too

01:07:48.715 --> 01:07:49.355
<v Speaker 1>crazy.

01:07:49.515 --> 01:07:51.035
<v Speaker 1>First thing I'm gonna do is put my

01:07:51.035 --> 01:07:52.475
<v Speaker 1>key where I need it to be. So

01:07:52.475 --> 01:07:54.715
<v Speaker 1>I gotta make a dot Kaggle file folder.

01:07:54.715 --> 01:07:56.955
<v Speaker 1>I'm gonna c p kaggle

01:07:57.275 --> 01:07:58.635
<v Speaker 1>dot json.

01:07:59.515 --> 01:07:59.915
<v Speaker 0>Mhmm.

01:08:02.480 --> 01:08:03.360
<v Speaker 1>Kaggle.

01:08:03.520 --> 01:08:06.160
<v Speaker 1>There we go. Dot JSON to dot I

01:08:06.160 --> 01:08:08.240
<v Speaker 1>don't know why it didn't autocomplete like that.

01:08:08.320 --> 01:08:10.800
<v Speaker 1>Alright. So let's l.Kaggle

01:08:10.800 --> 01:08:12.400
<v Speaker 1>just to make sure it's there, and it

01:08:12.400 --> 01:08:14.705
<v Speaker 1>is. Okay. Great. So next up, what are

01:08:14.705 --> 01:08:17.104
<v Speaker 1>we gonna do? We're gonna do pip three

01:08:17.425 --> 01:08:18.625
<v Speaker 1>install

01:08:18.625 --> 01:08:19.904
<v Speaker 1>dash u

01:08:20.145 --> 01:08:22.465
<v Speaker 1>Kaggle. That's gonna give us the

01:08:23.585 --> 01:08:25.024
<v Speaker 1>Kaggle CLI,

01:08:25.024 --> 01:08:26.865
<v Speaker 1>which will be super helpful.

01:08:27.979 --> 01:08:28.859
<v Speaker 1>Alright.

01:08:29.020 --> 01:08:29.979
<v Speaker 1>Next up,

01:08:30.460 --> 01:08:31.979
<v Speaker 1>we are going to

01:08:32.860 --> 01:08:35.740
<v Speaker 1>download a dataset. How about that? So we

01:08:35.740 --> 01:08:37.180
<v Speaker 1>are going to do Kaggle

01:08:37.580 --> 01:08:38.620
<v Speaker 1>datasets

01:08:38.700 --> 01:08:39.819
<v Speaker 1>download.

01:08:40.060 --> 01:08:41.420
<v Speaker 1>Download.

01:08:44.015 --> 01:08:45.854
<v Speaker 1>What do we want? Okay. Let me just

01:08:45.854 --> 01:08:48.814
<v Speaker 1>copy the repo here. Can you try pressing

01:08:48.814 --> 01:08:50.415
<v Speaker 0>command plus on that a few times and

01:08:50.415 --> 01:08:51.854
<v Speaker 0>see if it zooms in?

01:08:52.095 --> 01:08:53.615
<v Speaker 1>Yeah. I think there actually is a way

01:08:53.615 --> 01:08:54.735
<v Speaker 1>to change the

01:08:55.360 --> 01:08:56.640
<v Speaker 1>console.

01:08:57.280 --> 01:08:59.040
<v Speaker 0>There was a presentation mode there. I don't

01:08:59.040 --> 01:09:00.800
<v Speaker 0>know if that does anything, though, under view.

01:09:00.800 --> 01:09:02.319
<v Speaker 1>Oh, really? Where did you see that?

01:09:02.800 --> 01:09:04.319
<v Speaker 0>The top of the presentation mode.

01:09:05.920 --> 01:09:08.640
<v Speaker 1>And that doesn't do it. Yeah. Just try

01:09:08.640 --> 01:09:10.479
<v Speaker 0>command plus. You're on a Mac or you're

01:09:10.479 --> 01:09:12.635
<v Speaker 0>on Linux Windows? Yeah. Yeah. I'm on a

01:09:12.635 --> 01:09:14.314
<v Speaker 1>I'm on a Mac command

01:09:14.474 --> 01:09:15.354
<v Speaker 1>and

01:09:16.474 --> 01:09:18.795
<v Speaker 1>I've got so many like modifier

01:09:18.795 --> 01:09:21.835
<v Speaker 1>keys on the Ergodox.

01:09:21.835 --> 01:09:23.675
<v Speaker 0>Nobody that has an Ergodox and has come

01:09:23.675 --> 01:09:25.594
<v Speaker 0>on the stream has a pleasant time typing.

01:09:26.850 --> 01:09:28.290
<v Speaker 0>Seems to be the way. He's like paying

01:09:28.290 --> 01:09:29.649
<v Speaker 0>you Ergodox users.

01:09:30.529 --> 01:09:32.289
<v Speaker 1>No. No. No. It's it's it

01:09:32.850 --> 01:09:34.130
<v Speaker 1>is the best.

01:09:34.449 --> 01:09:36.449
<v Speaker 1>But when you ask me to do something

01:09:36.529 --> 01:09:37.969
<v Speaker 1>different than what I'm used to,

01:09:38.734 --> 01:09:41.534
<v Speaker 1>I don't oftentimes I have to remember. Plus,

01:09:41.534 --> 01:09:44.094
<v Speaker 1>I use the Dvorak keyboard layout.

01:09:44.494 --> 01:09:45.215
<v Speaker 1>I

01:09:45.694 --> 01:09:47.215
<v Speaker 1>I mean, that blew it up, but it's

01:09:47.934 --> 01:09:49.454
<v Speaker 1>for the purpose that we'll we'll we'll zoom

01:09:49.454 --> 01:09:50.574
<v Speaker 1>it out. How about when we get into

01:09:50.574 --> 01:09:52.090
<v Speaker 1>the notebook? There we go. Yeah. If we're

01:09:52.090 --> 01:09:53.290
<v Speaker 0>not doing much on a terminal, if it's

01:09:53.290 --> 01:09:55.290
<v Speaker 0>just getting dependencies, we can just move on.

01:09:55.370 --> 01:09:57.530
<v Speaker 1>Yeah. Let me control. I don't think downloading

01:09:57.530 --> 01:09:59.370
<v Speaker 0>a YouTube URL is gonna work with Kaggle

01:09:59.370 --> 01:10:00.010
<v Speaker 0>though.

01:10:01.290 --> 01:10:02.090
<v Speaker 1>Not

01:10:02.090 --> 01:10:03.784
<v Speaker 1>yet anyway. Alright.

01:10:04.105 --> 01:10:04.985
<v Speaker 1>Copy.

01:10:05.145 --> 01:10:07.385
<v Speaker 1>No. Alright. I'm just gonna type it out.

01:10:07.465 --> 01:10:10.905
<v Speaker 1>So this this user on Kaggle is awesome

01:10:10.905 --> 01:10:13.704
<v Speaker 1>and you should totally check out everything

01:10:13.705 --> 01:10:14.585
<v Speaker 1>that

01:10:15.240 --> 01:10:16.840
<v Speaker 1>he's got on there because these are some

01:10:16.840 --> 01:10:19.640
<v Speaker 1>really fun datasets. So to this time, we

01:10:19.640 --> 01:10:21.079
<v Speaker 1>are going to

01:10:23.160 --> 01:10:26.760
<v Speaker 1>we are going to be trying to create

01:10:26.760 --> 01:10:28.280
<v Speaker 1>an image classification

01:10:28.280 --> 01:10:29.800
<v Speaker 1>model similar to the fork.

01:10:30.465 --> 01:10:31.985
<v Speaker 1>But instead of predicting,

01:10:32.625 --> 01:10:34.304
<v Speaker 1>forks and nonforks,

01:10:34.304 --> 01:10:35.665
<v Speaker 1>we are going to be looking at chest

01:10:35.665 --> 01:10:39.185
<v Speaker 1>X rays to determine if the, X-ray,

01:10:39.264 --> 01:10:41.744
<v Speaker 1>presents with pneumonia or does not.

01:10:42.065 --> 01:10:45.209
<v Speaker 1>And one can imagine, many many valuable,

01:10:45.449 --> 01:10:48.489
<v Speaker 1>applications for that, particularly, say, in in remote

01:10:48.489 --> 01:10:49.129
<v Speaker 1>places,

01:10:49.449 --> 01:10:51.769
<v Speaker 1>that may not have access to radiologists all

01:10:51.769 --> 01:10:53.769
<v Speaker 1>the time, that kind of thing, or as,

01:10:53.849 --> 01:10:56.489
<v Speaker 1>an enhancement, a double check to a clinical

01:10:56.489 --> 01:10:58.329
<v Speaker 1>decision making, sort of a process.

01:10:59.975 --> 01:11:02.775
<v Speaker 1>Next up, we're going to unzip

01:11:03.175 --> 01:11:05.574
<v Speaker 1>chest X-ray. There we go.

01:11:07.175 --> 01:11:08.455
<v Speaker 1>So you can see here,

01:11:09.415 --> 01:11:11.175
<v Speaker 1>lots happening on the screen. Basically,

01:11:12.990 --> 01:11:14.670
<v Speaker 1>the way that the

01:11:15.550 --> 01:11:17.070
<v Speaker 1>images are

01:11:17.310 --> 01:11:18.990
<v Speaker 1>labeled, that is to say, how do we

01:11:18.990 --> 01:11:20.829
<v Speaker 1>know whether something is a

01:11:21.150 --> 01:11:22.030
<v Speaker 1>a healthy,

01:11:22.190 --> 01:11:24.349
<v Speaker 1>normal image or a

01:11:24.510 --> 01:11:25.389
<v Speaker 1>pneumonia

01:11:25.630 --> 01:11:27.470
<v Speaker 1>image is by the directory.

01:11:27.805 --> 01:11:29.405
<v Speaker 1>And so the,

01:11:29.965 --> 01:11:31.724
<v Speaker 1>the modern machine learning,

01:11:31.885 --> 01:11:35.645
<v Speaker 1>frameworks all have very, useful helpers to just

01:11:35.645 --> 01:11:39.565
<v Speaker 1>say, here's, you know, here's the the

01:11:40.590 --> 01:11:42.909
<v Speaker 1>here's the the zero and here's the one.

01:11:42.909 --> 01:11:44.909
<v Speaker 1>Right? A binary outcome. Either this person's got

01:11:44.909 --> 01:11:47.869
<v Speaker 1>pneumonia or they don't. Right? That make sense?

01:11:48.110 --> 01:11:48.829
<v Speaker 1>Yeah.

01:11:49.230 --> 01:11:50.030
<v Speaker 1>Alright.

01:11:50.270 --> 01:11:52.510
<v Speaker 1>So next up, what we're gonna do is

01:11:52.875 --> 01:11:55.195
<v Speaker 1>just make our lives simple by doing pip

01:11:55.195 --> 01:11:57.114
<v Speaker 1>three install

01:11:57.435 --> 01:11:58.875
<v Speaker 1>dash user

01:11:59.515 --> 01:12:00.395
<v Speaker 1>dash

01:12:00.395 --> 01:12:02.235
<v Speaker 1>r requirements

01:12:02.235 --> 01:12:03.594
<v Speaker 1>dot t x t.

01:12:04.395 --> 01:12:05.114
<v Speaker 1>And

01:12:05.275 --> 01:12:07.790
<v Speaker 1>we're gonna go through all of this, and

01:12:07.790 --> 01:12:09.150
<v Speaker 1>it's gonna install

01:12:09.470 --> 01:12:10.670
<v Speaker 1>all of the,

01:12:11.550 --> 01:12:14.110
<v Speaker 1>libraries and so on. You know, such a

01:12:14.110 --> 01:12:16.110
<v Speaker 1>great oh, let me just open this up

01:12:16.110 --> 01:12:17.230
<v Speaker 1>and edit it

01:12:17.550 --> 01:12:20.910
<v Speaker 1>because there is something that is not a

01:12:20.910 --> 01:12:21.790
<v Speaker 1>kosher

01:12:21.790 --> 01:12:22.190
<v Speaker 1>file.

01:12:22.905 --> 01:12:26.264
<v Speaker 1>Save file. Let's try this again. I like,

01:12:27.224 --> 01:12:29.065
<v Speaker 1>looking at this. You know, I it it

01:12:29.065 --> 01:12:31.065
<v Speaker 1>takes a second, but I like it because

01:12:31.065 --> 01:12:35.224
<v Speaker 1>it just demonstrates, like, so many people contribute,

01:12:35.385 --> 01:12:37.850
<v Speaker 1>like, stuff that's super important,

01:12:38.090 --> 01:12:39.930
<v Speaker 1>you know, that that we all rely on.

01:12:39.930 --> 01:12:42.170
<v Speaker 1>And and, like, we really build

01:12:42.650 --> 01:12:45.050
<v Speaker 1>on the shoulders of everybody else, you know,

01:12:45.050 --> 01:12:46.970
<v Speaker 1>the the people who have contributed stuff before

01:12:46.970 --> 01:12:49.050
<v Speaker 1>and what's it's what lets us do our

01:12:49.210 --> 01:12:51.290
<v Speaker 1>do what we do. And

01:12:52.105 --> 01:12:53.784
<v Speaker 1>so I I don't

01:12:54.585 --> 01:12:56.265
<v Speaker 1>I don't begrudge it. I'll put it that

01:12:56.265 --> 01:12:56.745
<v Speaker 1>way.

01:12:58.105 --> 01:12:59.945
<v Speaker 1>It's like a a good reminder to be

01:12:59.945 --> 01:13:02.185
<v Speaker 1>appreciative for everything that's been invested.

01:13:02.425 --> 01:13:04.940
<v Speaker 0>Yeah. There's so much amazing open source software.

01:13:04.940 --> 01:13:06.540
<v Speaker 0>There are any problem you can think of.

01:13:06.540 --> 01:13:08.699
<v Speaker 0>You can go to NPM, crates, you know,

01:13:08.699 --> 01:13:09.900
<v Speaker 0>the GoRegistry,

01:13:09.900 --> 01:13:10.780
<v Speaker 0>PHP.

01:13:10.860 --> 01:13:12.540
<v Speaker 0>You search for it. Someone's

01:13:12.540 --> 01:13:15.179
<v Speaker 0>generally done it for free, made it available,

01:13:15.179 --> 01:13:17.495
<v Speaker 0>and it's there for you to use, and

01:13:17.495 --> 01:13:19.575
<v Speaker 0>hopefully contribute back to it. It always amazes

01:13:19.575 --> 01:13:21.735
<v Speaker 1>me. Exactly. Open source is a wonderful thing.

01:13:22.615 --> 01:13:25.015
<v Speaker 1>Yeah. Yeah. And there's, you know, there's libraries

01:13:25.015 --> 01:13:26.935
<v Speaker 1>that, like, everything

01:13:26.935 --> 01:13:30.150
<v Speaker 1>in the world relies on, you know, maintained

01:13:30.150 --> 01:13:32.710
<v Speaker 1>by one lady in a basement somewhere. You

01:13:32.710 --> 01:13:33.190
<v Speaker 1>know?

01:13:33.910 --> 01:13:36.550
<v Speaker 1>So it's yeah. It's it's incredible. It's like

01:13:36.550 --> 01:13:38.230
<v Speaker 1>the it's a it's a real

01:13:39.270 --> 01:13:40.310
<v Speaker 1>free for all.

01:13:40.710 --> 01:13:42.710
<v Speaker 1>Okay. So we've got our

01:13:45.315 --> 01:13:47.875
<v Speaker 1>dependencies installed, our our libraries installed.

01:13:48.035 --> 01:13:50.195
<v Speaker 1>Now we will come over to the launcher,

01:13:50.355 --> 01:13:52.355
<v Speaker 1>and we will open a Python three notebook.

01:13:52.755 --> 01:13:53.554
<v Speaker 1>Ta da.

01:13:54.035 --> 01:13:55.074
<v Speaker 1>How about that?

01:13:55.635 --> 01:13:58.595
<v Speaker 1>I will give of course, I mentioned

01:13:58.750 --> 01:14:00.190
<v Speaker 1>Paul Timothy Mooney,

01:14:00.510 --> 01:14:01.230
<v Speaker 1>from

01:14:01.950 --> 01:14:02.750
<v Speaker 1>Kaggle.

01:14:02.910 --> 01:14:05.550
<v Speaker 1>I also wanna thank, the the

01:14:07.630 --> 01:14:08.989
<v Speaker 1>Coursera course

01:14:09.550 --> 01:14:10.190
<v Speaker 1>by,

01:14:10.430 --> 01:14:12.190
<v Speaker 1>Andrew and his call

01:14:13.725 --> 01:14:14.525
<v Speaker 1>collaborators,

01:14:14.844 --> 01:14:15.724
<v Speaker 1>from Google.

01:14:15.965 --> 01:14:16.445
<v Speaker 1>So,

01:14:17.165 --> 01:14:18.525
<v Speaker 1>you know, this is where this is where

01:14:18.525 --> 01:14:20.205
<v Speaker 1>I've learned a lot. And and, you know,

01:14:20.205 --> 01:14:21.725
<v Speaker 1>it's all open source, but, know, I wanna

01:14:21.725 --> 01:14:23.324
<v Speaker 1>give credit where it's where it's due.

01:14:23.885 --> 01:14:25.885
<v Speaker 1>I borrowed some of their their techniques and

01:14:25.885 --> 01:14:27.085
<v Speaker 1>a little bit of their

01:14:28.710 --> 01:14:30.630
<v Speaker 1>display code here. So the first thing we

01:14:30.630 --> 01:14:33.510
<v Speaker 1>gotta do is import some stuff. So

01:14:33.990 --> 01:14:34.710
<v Speaker 1>let me actually

01:14:35.270 --> 01:14:37.110
<v Speaker 1>Jupyter has this weird thing where, like, it

01:14:37.110 --> 01:14:40.390
<v Speaker 1>doesn't it really cares, like, when you name

01:14:40.390 --> 01:14:42.070
<v Speaker 1>a notebook, like, as to whether you end

01:14:42.070 --> 01:14:44.324
<v Speaker 1>up with, like, 10,000 files. So let's do

01:14:44.324 --> 01:14:45.204
<v Speaker 1>import

01:14:45.605 --> 01:14:49.364
<v Speaker 1>OS. We're gonna import random. We're gonna import

01:14:49.764 --> 01:14:51.844
<v Speaker 1>NumPy as NP.

01:14:52.085 --> 01:14:53.604
<v Speaker 1>Import tensor

01:14:53.764 --> 01:14:55.364
<v Speaker 1>tensor flow

01:14:55.684 --> 01:14:56.565
<v Speaker 1>as TF.

01:14:57.760 --> 01:15:00.320
<v Speaker 1>Import TensorFlow

01:15:00.480 --> 01:15:02.239
<v Speaker 1>dot Keras as

01:15:02.800 --> 01:15:04.639
<v Speaker 1>Keras. So Keras is like a sugar layer

01:15:04.639 --> 01:15:06.400
<v Speaker 1>on top of TensorFlow.

01:15:06.400 --> 01:15:07.999
<v Speaker 1>This makes your life a lot easier.

01:15:08.719 --> 01:15:11.120
<v Speaker 1>Then we're gonna get even more specific. We're

01:15:11.120 --> 01:15:12.080
<v Speaker 1>gonna say from

01:15:12.325 --> 01:15:13.844
<v Speaker 1>tensorflow

01:15:14.245 --> 01:15:16.645
<v Speaker 1>dot keras dot optimizers.

01:15:16.645 --> 01:15:18.805
<v Speaker 1>We'll talk about what these are. I even

01:15:18.805 --> 01:15:20.485
<v Speaker 1>have a a track down a a neat

01:15:20.485 --> 01:15:22.725
<v Speaker 1>little GIF to sort of illustrate it.

01:15:23.845 --> 01:15:25.285
<v Speaker 1>Again, thank you, Internet.

01:15:26.110 --> 01:15:27.070
<v Speaker 1>We're gonna

01:15:27.390 --> 01:15:29.230
<v Speaker 1>import the RMS prop

01:15:29.870 --> 01:15:30.830
<v Speaker 1>optimizer.

01:15:31.070 --> 01:15:33.390
<v Speaker 1>And from TensorFlow

01:15:35.470 --> 01:15:42.234
<v Speaker 1>.KerasKeras.preprocessing.image.

01:15:42.474 --> 01:15:44.314
<v Speaker 1>We are going to import

01:15:45.114 --> 01:15:45.994
<v Speaker 1>image

01:15:46.315 --> 01:15:48.474
<v Speaker 1>generator four. Okay.

01:15:50.155 --> 01:15:52.315
<v Speaker 1>Oops. Sorry. I misspelled that. It's image data

01:15:52.315 --> 01:15:55.034
<v Speaker 1>generator. I I'm a % cheating. I find

01:15:55.034 --> 01:15:57.360
<v Speaker 1>live coding in front of other people, like,

01:15:57.360 --> 01:16:00.640
<v Speaker 1>the the most stressful thing. Okay. So then

01:16:00.640 --> 01:16:02.400
<v Speaker 1>we're gonna do some other stuff that'll be

01:16:02.400 --> 01:16:05.120
<v Speaker 1>familiar. We're gonna import matplotlib

01:16:05.120 --> 01:16:07.920
<v Speaker 1>dot pyplot as PLT.

01:16:08.160 --> 01:16:10.560
<v Speaker 1>We're gonna import matplotlib

01:16:10.560 --> 01:16:11.440
<v Speaker 1>dot

01:16:12.395 --> 01:16:13.994
<v Speaker 1>image as

01:16:13.995 --> 01:16:15.114
<v Speaker 1>m p image.

01:16:16.795 --> 01:16:19.035
<v Speaker 1>Nope. None of that was correct. MIMPIBG.

01:16:19.035 --> 01:16:21.195
<v Speaker 1>Yep. And then just so that we get

01:16:21.915 --> 01:16:22.795
<v Speaker 1>pretty

01:16:23.515 --> 01:16:25.515
<v Speaker 1>so we get consistent results, we're gonna set

01:16:25.515 --> 01:16:27.199
<v Speaker 1>the random seed, you know, just so we

01:16:27.199 --> 01:16:29.360
<v Speaker 1>can do apples to apples. Alright? And

01:16:30.480 --> 01:16:33.360
<v Speaker 1>we will execute the cell with shift enter.

01:16:35.199 --> 01:16:37.600
<v Speaker 1>No module found. Oh, because I missed a

01:16:37.600 --> 01:16:38.159
<v Speaker 1>p. That's

01:16:39.600 --> 01:16:41.905
<v Speaker 1>yeah. Thing I always have to tell noncomputer

01:16:41.905 --> 01:16:43.985
<v Speaker 1>folks is that the thing about computers is

01:16:43.985 --> 01:16:44.465
<v Speaker 1>if

01:16:46.785 --> 01:16:48.465
<v Speaker 1>if the computer says you did it wrong,

01:16:48.465 --> 01:16:50.304
<v Speaker 1>it's because you did it wrong. You know?

01:16:51.105 --> 01:16:53.505
<v Speaker 1>I'm just gonna copy and paste in this

01:16:53.505 --> 01:16:54.945
<v Speaker 1>is just we're just gonna look at the

01:16:54.945 --> 01:16:58.040
<v Speaker 1>length of a directory because our images are

01:16:58.040 --> 01:17:00.120
<v Speaker 1>in the directory. Right? And I just wanna

01:17:00.120 --> 01:17:01.720
<v Speaker 1>be able to use that to say, this

01:17:01.720 --> 01:17:02.600
<v Speaker 1>is how many

01:17:03.480 --> 01:17:05.320
<v Speaker 1>images we have. So we have

01:17:05.960 --> 01:17:09.000
<v Speaker 1>thirteen hundred forty two normals and

01:17:09.640 --> 01:17:11.955
<v Speaker 1>thirty eight seventy six pneumonias.

01:17:12.195 --> 01:17:14.915
<v Speaker 1>This is a very small dataset. You you

01:17:14.915 --> 01:17:15.955
<v Speaker 1>know, this

01:17:16.595 --> 01:17:18.515
<v Speaker 1>should never be used for anything serious at

01:17:18.515 --> 01:17:18.995
<v Speaker 1>all.

01:17:19.395 --> 01:17:21.555
<v Speaker 1>But you'll see that we are still able

01:17:21.555 --> 01:17:22.915
<v Speaker 1>within this context to,

01:17:23.590 --> 01:17:25.750
<v Speaker 1>I mean, you know, if we had 25

01:17:25.750 --> 01:17:28.150
<v Speaker 1>gigs of images, we'd we'd have to check

01:17:28.150 --> 01:17:29.429
<v Speaker 1>back next week. You know?

01:17:31.750 --> 01:17:34.230
<v Speaker 0>Is that a sort of normal ratio, like,

01:17:34.230 --> 01:17:36.525
<v Speaker 0>three to one? Is that, like, just is

01:17:36.525 --> 01:17:38.445
<v Speaker 0>that still the golden ratio for machine learning?

01:17:38.445 --> 01:17:40.445
<v Speaker 0>Like, if we wanna do pneumonia detection, we

01:17:40.445 --> 01:17:42.125
<v Speaker 0>need three of them to every one non

01:17:42.125 --> 01:17:44.765
<v Speaker 0>pneumonia? Or is that just complete serendipity?

01:17:45.485 --> 01:17:48.045
<v Speaker 1>It's this is this is complete serendipity.

01:17:49.239 --> 01:17:51.080
<v Speaker 1>You know, to the best of my knowledge,

01:17:51.080 --> 01:17:52.040
<v Speaker 1>I don't I I

01:17:53.560 --> 01:17:55.719
<v Speaker 1>the golden rule is more is better, defer

01:17:55.800 --> 01:17:58.440
<v Speaker 1>more diverse is better. Right? So, you know,

01:17:58.440 --> 01:18:01.320
<v Speaker 1>equally weighted among the the the the

01:18:02.145 --> 01:18:04.145
<v Speaker 1>group that you want to you know, the

01:18:04.145 --> 01:18:05.425
<v Speaker 1>groups that you wanna be able to make

01:18:05.425 --> 01:18:08.065
<v Speaker 1>predictions for. Right? So I believe, in fact,

01:18:08.065 --> 01:18:09.905
<v Speaker 1>that this dataset comes from,

01:18:12.385 --> 01:18:14.704
<v Speaker 1>I wanna say, Vietnam, if I recall correctly.

01:18:14.704 --> 01:18:16.625
<v Speaker 1>Suffice it to say, it's it's gonna be

01:18:16.625 --> 01:18:19.160
<v Speaker 1>a population of patients from Vietnam that may

01:18:19.160 --> 01:18:20.760
<v Speaker 1>or may not be, you know, applicable to

01:18:20.760 --> 01:18:22.039
<v Speaker 1>everybody else. Right?

01:18:22.280 --> 01:18:24.679
<v Speaker 0>Okay. Does that make sense? Yeah. Alright.

01:18:25.960 --> 01:18:26.599
<v Speaker 1>So

01:18:27.400 --> 01:18:29.159
<v Speaker 1>just keeping an eye on the time.

01:18:29.719 --> 01:18:30.520
<v Speaker 1>There's a

01:18:31.915 --> 01:18:33.435
<v Speaker 1>I'm gonna do a copy paste for the

01:18:33.435 --> 01:18:34.955
<v Speaker 1>boring bits because I wanna be able to

01:18:34.955 --> 01:18:36.795
<v Speaker 1>spend time on the exciting bits.

01:18:37.195 --> 01:18:38.554
<v Speaker 1>And here, what I'm gonna do this is

01:18:38.554 --> 01:18:41.195
<v Speaker 1>a really handy technique that ever since I

01:18:41.195 --> 01:18:42.554
<v Speaker 1>learned about it, I do it all the

01:18:42.554 --> 01:18:45.514
<v Speaker 1>time where we'll just define a base directory.

01:18:45.594 --> 01:18:47.355
<v Speaker 1>We've got a training directory, so this is

01:18:47.355 --> 01:18:50.050
<v Speaker 1>very helpful. Right? So among our training data,

01:18:50.050 --> 01:18:51.330
<v Speaker 1>you can see here it's all under the

01:18:51.330 --> 01:18:53.489
<v Speaker 1>the subdirectory train. You could see it over

01:18:53.489 --> 01:18:56.050
<v Speaker 1>here too. Right? So here we go. Train

01:18:56.050 --> 01:18:57.889
<v Speaker 1>test. Test X-ray.

01:18:58.210 --> 01:19:00.369
<v Speaker 1>Train test and validation. So

01:19:02.050 --> 01:19:02.370
<v Speaker 1>training

01:19:03.935 --> 01:19:06.255
<v Speaker 1>is the dataset we'll use to train on.

01:19:06.415 --> 01:19:08.095
<v Speaker 1>The the testing

01:19:08.095 --> 01:19:08.975
<v Speaker 1>is to,

01:19:09.375 --> 01:19:11.215
<v Speaker 1>observe whether or not that,

01:19:11.535 --> 01:19:13.695
<v Speaker 1>you know, to to keep some data outside

01:19:13.695 --> 01:19:15.775
<v Speaker 1>so that the model can't cheat and update

01:19:15.775 --> 01:19:18.230
<v Speaker 1>itself based on, you know, the forks we're

01:19:18.230 --> 01:19:19.670
<v Speaker 1>gonna test it against in the future because

01:19:19.670 --> 01:19:21.190
<v Speaker 1>then it'll learn about those forks or, in

01:19:21.190 --> 01:19:22.230
<v Speaker 1>this case, the

01:19:23.350 --> 01:19:24.230
<v Speaker 1>X rays,

01:19:24.390 --> 01:19:27.350
<v Speaker 1>and, it won't be representative of new data

01:19:27.350 --> 01:19:29.110
<v Speaker 1>that it's never seen before in the real

01:19:29.110 --> 01:19:31.635
<v Speaker 1>world. Right? Yep. So all I'm doing here

01:19:31.635 --> 01:19:34.915
<v Speaker 1>is just a a little directory manipulation.

01:19:34.915 --> 01:19:35.795
<v Speaker 1>Okeydoke.

01:19:36.275 --> 01:19:38.594
<v Speaker 1>And if we add up the training

01:19:38.995 --> 01:19:42.675
<v Speaker 1>for for normal, so there'll be a 5,218

01:19:42.755 --> 01:19:43.555
<v Speaker 1>training

01:19:43.920 --> 01:19:45.920
<v Speaker 1>examples and 624

01:19:45.920 --> 01:19:48.000
<v Speaker 1>testing examples. Alright? So this will be used

01:19:48.000 --> 01:19:48.800
<v Speaker 1>to validate.

01:19:49.760 --> 01:19:52.160
<v Speaker 1>This is very handy that the dataset comes

01:19:52.160 --> 01:19:54.480
<v Speaker 1>like this. It almost never does. There are

01:19:54.480 --> 01:19:55.600
<v Speaker 1>some really helpful

01:19:59.284 --> 01:20:01.205
<v Speaker 1>helper functions that will split your dataset for

01:20:01.205 --> 01:20:01.684
<v Speaker 1>you,

01:20:02.885 --> 01:20:05.605
<v Speaker 1>like, the test train split, appropriately named test

01:20:05.605 --> 01:20:06.485
<v Speaker 1>train split,

01:20:06.645 --> 01:20:07.284
<v Speaker 1>tool

01:20:08.405 --> 01:20:10.164
<v Speaker 1>that comes with, with

01:20:10.324 --> 01:20:11.284
<v Speaker 1>SciPy.

01:20:11.284 --> 01:20:11.925
<v Speaker 1>So

01:20:12.570 --> 01:20:14.890
<v Speaker 1>let's actually you know, let's be data scientists

01:20:14.890 --> 01:20:17.130
<v Speaker 1>for a moment and take a look at

01:20:18.010 --> 01:20:20.010
<v Speaker 1>some examples of, you know, what this what

01:20:20.010 --> 01:20:22.330
<v Speaker 1>this data actually looks like. So we'll set

01:20:22.330 --> 01:20:23.850
<v Speaker 1>an index for ourselves

01:20:24.570 --> 01:20:26.330
<v Speaker 1>for comparison purposes.

01:20:26.810 --> 01:20:27.210
<v Speaker 1>Alright.

01:20:27.784 --> 01:20:28.344
<v Speaker 1>And

01:20:28.824 --> 01:20:30.744
<v Speaker 1>let's take a look. Let's call this normal.

01:20:30.744 --> 01:20:32.185
<v Speaker 1>Right? So we're gonna look at a normal

01:20:32.185 --> 01:20:32.905
<v Speaker 1>example.

01:20:33.065 --> 01:20:35.545
<v Speaker 1>I'm gonna give it an image path, and

01:20:35.545 --> 01:20:36.824
<v Speaker 1>that's going to be

01:20:40.320 --> 01:20:42.559
<v Speaker 1>gotta join this up. Train

01:20:43.199 --> 01:20:44.079
<v Speaker 1>normal

01:20:44.480 --> 01:20:45.439
<v Speaker 1>dir

01:20:46.000 --> 01:20:46.959
<v Speaker 1>dir.

01:20:49.520 --> 01:20:51.920
<v Speaker 1>Yep. Here we go. And then within that,

01:20:51.920 --> 01:20:53.360
<v Speaker 1>I want train

01:20:53.945 --> 01:20:54.824
<v Speaker 1>normal,

01:20:55.865 --> 01:20:57.224
<v Speaker 1>f names,

01:20:57.225 --> 01:20:58.745
<v Speaker 1>and I wanna pull the,

01:20:59.225 --> 01:21:01.465
<v Speaker 1>obviously, pick index. That's why we made it.

01:21:01.465 --> 01:21:02.264
<v Speaker 1>Okay.

01:21:03.385 --> 01:21:04.025
<v Speaker 1>And

01:21:04.825 --> 01:21:05.625
<v Speaker 1>then

01:21:05.945 --> 01:21:07.670
<v Speaker 1>oh, it's it's a little it's a little

01:21:07.670 --> 01:21:09.429
<v Speaker 1>hard to do with the Zoom, but we'll

01:21:09.429 --> 01:21:11.030
<v Speaker 1>get it. We'll it. We'll get it. Alright.

01:21:11.030 --> 01:21:12.949
<v Speaker 1>We can scrunch this a bit. There we

01:21:12.949 --> 01:21:15.110
<v Speaker 1>go. Alright. So then what we're gonna do

01:21:15.110 --> 01:21:18.949
<v Speaker 1>is we're gonna have an image variable and

01:21:19.985 --> 01:21:22.865
<v Speaker 1>m image. Remember, we made that variable up

01:21:22.865 --> 01:21:25.505
<v Speaker 1>at the top. We're gonna do I'm read

01:21:25.665 --> 01:21:26.545
<v Speaker 1>image

01:21:26.545 --> 01:21:27.425
<v Speaker 1>path,

01:21:27.985 --> 01:21:30.625
<v Speaker 1>and then we're gonna do plot dot

01:21:30.625 --> 01:21:32.545
<v Speaker 1>I'm show

01:21:33.130 --> 01:21:35.930
<v Speaker 1>image. I'm not a professional data scientist. If

01:21:35.930 --> 01:21:37.050
<v Speaker 1>there's, you know,

01:21:37.610 --> 01:21:40.410
<v Speaker 1>folks who take offense to any of this

01:21:40.410 --> 01:21:42.170
<v Speaker 1>know that I I do this

01:21:42.730 --> 01:21:44.890
<v Speaker 1>very much as a novice. Alright. Here we

01:21:44.890 --> 01:21:47.425
<v Speaker 1>go. So these are grayscale images. I'm I'm

01:21:47.425 --> 01:21:48.465
<v Speaker 1>displaying them,

01:21:48.705 --> 01:21:50.864
<v Speaker 1>in a, you know, a sort of

01:21:51.505 --> 01:21:54.305
<v Speaker 1>fun color, you know, highlight way to make

01:21:54.305 --> 01:21:55.665
<v Speaker 1>it just look a little bit different. But

01:21:55.665 --> 01:21:57.665
<v Speaker 1>here's a person who does not have pneumonia.

01:21:57.665 --> 01:22:00.060
<v Speaker 1>Alright? So there will be a test at

01:22:00.060 --> 01:22:02.459
<v Speaker 1>the end. Are you smarter than the model?

01:22:02.780 --> 01:22:05.499
<v Speaker 1>Apropos the, forks discussion earlier.

01:22:05.739 --> 01:22:08.380
<v Speaker 1>So now let's compare that with a pneumonia

01:22:08.380 --> 01:22:09.260
<v Speaker 1>example.

01:22:10.219 --> 01:22:11.420
<v Speaker 1>And

01:22:11.655 --> 01:22:14.054
<v Speaker 1>I've already you know, no need to watch

01:22:14.054 --> 01:22:16.854
<v Speaker 1>me type poorly. So Feel free just to

01:22:16.855 --> 01:22:19.175
<v Speaker 0>paste whatever. Like, can just run. Yeah. If

01:22:19.175 --> 01:22:20.454
<v Speaker 0>I have questions about the code, I'll just

01:22:20.454 --> 01:22:21.574
<v Speaker 0>throw them at you. Don't worry about it.

01:22:21.574 --> 01:22:23.335
<v Speaker 1>Okay. Cool. Cool. Cool. Yeah. Sorry. I wanna

01:22:23.335 --> 01:22:24.375
<v Speaker 1>make sure we get through it. So, anyways,

01:22:24.510 --> 01:22:26.030
<v Speaker 1>okay. So we're doing this. Now we're doing

01:22:26.030 --> 01:22:27.629
<v Speaker 1>it with a pneumonia example.

01:22:27.869 --> 01:22:29.869
<v Speaker 1>Okay. You know, it looks pretty

01:22:30.670 --> 01:22:31.949
<v Speaker 1>pretty different. Sorta

01:22:34.909 --> 01:22:36.909
<v Speaker 1>I wanna use the word gloopy,

01:22:36.909 --> 01:22:38.989
<v Speaker 1>but I don't think that's a

01:22:39.630 --> 01:22:41.775
<v Speaker 1>a Scrabble accepted word. So I was thinking

01:22:41.775 --> 01:22:42.655
<v Speaker 0>more haunted.

01:22:43.135 --> 01:22:44.815
<v Speaker 0>It looks more haunted. You're thinking what? More

01:22:44.815 --> 01:22:45.534
<v Speaker 0>haunted.

01:22:46.014 --> 01:22:47.854
<v Speaker 1>More haunted. There we go.

01:22:48.255 --> 01:22:50.815
<v Speaker 1>Yep. Okay. So I think I well, so

01:22:50.815 --> 01:22:52.655
<v Speaker 1>this is interesting. Right? Like, these are these

01:22:52.655 --> 01:22:55.000
<v Speaker 1>are different cases, and this one is only

01:22:55.000 --> 01:22:58.199
<v Speaker 1>barely more haunted. Right? So, you know, not

01:22:58.199 --> 01:23:01.159
<v Speaker 1>not so super simple here. So it fails

01:23:01.159 --> 01:23:01.959
<v Speaker 0>already. You

01:23:03.800 --> 01:23:05.159
<v Speaker 1>and me both. I mean,

01:23:05.480 --> 01:23:07.320
<v Speaker 1>you know, if I didn't go to if

01:23:07.320 --> 01:23:09.915
<v Speaker 1>I didn't go to a a data science

01:23:09.915 --> 01:23:12.074
<v Speaker 1>graduate school, I definitely also did not go

01:23:12.074 --> 01:23:13.835
<v Speaker 1>to medical school. So, you know, you put

01:23:13.835 --> 01:23:15.114
<v Speaker 1>those two things together.

01:23:16.155 --> 01:23:17.594
<v Speaker 1>So it's gonna be a nightmare for you

01:23:17.594 --> 01:23:19.034
<v Speaker 1>and me over at the hospital, and some

01:23:19.034 --> 01:23:20.074
<v Speaker 1>people are gonna die.

01:23:20.635 --> 01:23:22.875
<v Speaker 1>Alright. So what am I doing here? This

01:23:22.875 --> 01:23:25.130
<v Speaker 1>is how we use Keras to,

01:23:25.449 --> 01:23:28.650
<v Speaker 1>construct a model. So we're creating a variable

01:23:28.650 --> 01:23:31.290
<v Speaker 1>model. It's going to be a a sequential

01:23:31.290 --> 01:23:32.570
<v Speaker 1>model, a

01:23:33.449 --> 01:23:35.530
<v Speaker 1>a a type Keras models.

01:23:35.929 --> 01:23:36.409
<v Speaker 1>And,

01:23:36.810 --> 01:23:37.610
<v Speaker 1>what we're,

01:23:38.090 --> 01:23:39.449
<v Speaker 1>what we're defining

01:23:39.449 --> 01:23:39.929
<v Speaker 1>here

01:23:40.395 --> 01:23:44.234
<v Speaker 1>is a couple of things. The first is

01:23:44.474 --> 01:23:46.715
<v Speaker 1>first thing we need to do is give

01:23:46.715 --> 01:23:47.675
<v Speaker 1>instructions

01:23:47.755 --> 01:23:49.594
<v Speaker 1>to the model

01:23:49.675 --> 01:23:52.155
<v Speaker 1>about what kind of data it can expect.

01:23:52.640 --> 01:23:55.200
<v Speaker 1>So oh, these are, three color channels. My

01:23:55.200 --> 01:23:57.120
<v Speaker 1>bad. Okay. So these are color images.

01:23:57.280 --> 01:23:58.800
<v Speaker 1>So what the first thing that we're gonna

01:23:58.800 --> 01:24:01.040
<v Speaker 1>do is we're telling the model, hey. You're

01:24:01.040 --> 01:24:02.480
<v Speaker 1>gonna get an image. It's gonna be a

01:24:02.480 --> 01:24:05.600
<v Speaker 1>50 by a 50 pixels, and there's gonna

01:24:05.600 --> 01:24:08.625
<v Speaker 1>be three color channels. So for every pixel,

01:24:08.625 --> 01:24:10.704
<v Speaker 1>there'll be a a value,

01:24:11.425 --> 01:24:12.945
<v Speaker 1>for each of the color channels.

01:24:13.344 --> 01:24:13.905
<v Speaker 1>Then,

01:24:14.625 --> 01:24:17.025
<v Speaker 1>what we're what so what you're gonna need

01:24:17.025 --> 01:24:18.064
<v Speaker 1>to do is,

01:24:18.465 --> 01:24:20.304
<v Speaker 1>sort of

01:24:19.610 --> 01:24:21.929
<v Speaker 1>unravel that. Right? And so it's a a

01:24:21.929 --> 01:24:23.050
<v Speaker 1>a flat thing.

01:24:23.770 --> 01:24:25.770
<v Speaker 1>But the first thing that we're gonna do

01:24:25.770 --> 01:24:27.369
<v Speaker 1>is we're gonna do a this is a

01:24:27.369 --> 01:24:30.010
<v Speaker 1>convolutional neural network. So what's a convolutional neural

01:24:30.010 --> 01:24:32.409
<v Speaker 1>network? Basically, it's like applying a filter. I'm

01:24:32.409 --> 01:24:33.610
<v Speaker 1>gonna show you an example of what the

01:24:33.610 --> 01:24:35.644
<v Speaker 1>model sees a little bit later later on.

01:24:35.644 --> 01:24:37.085
<v Speaker 1>It's very similar. You think of it very

01:24:37.085 --> 01:24:39.164
<v Speaker 1>similarly to, like, the way that your phone,

01:24:39.405 --> 01:24:41.804
<v Speaker 1>you know, will put a an image, will

01:24:41.804 --> 01:24:43.644
<v Speaker 1>put a filter on an image. Right? We're

01:24:43.644 --> 01:24:45.485
<v Speaker 1>we're looking at the pixels. We're seeing the

01:24:45.485 --> 01:24:47.405
<v Speaker 1>values for each of the color channels, for

01:24:47.405 --> 01:24:49.480
<v Speaker 1>each of the pixels, and we're making some

01:24:49.480 --> 01:24:52.600
<v Speaker 1>decision about how to adjust it based on

01:24:52.600 --> 01:24:55.959
<v Speaker 1>its the the pixels that surround it. Okay?

01:24:56.119 --> 01:24:58.840
<v Speaker 1>So you can imagine there's lots of different

01:24:58.840 --> 01:25:01.400
<v Speaker 1>types of they're called kernels that lots of

01:25:01.400 --> 01:25:03.755
<v Speaker 1>different types of filters. Right? So here we

01:25:03.755 --> 01:25:05.835
<v Speaker 1>have a three by three. So we're passing

01:25:05.994 --> 01:25:07.195
<v Speaker 1>you can think of it like,

01:25:07.755 --> 01:25:10.155
<v Speaker 1>you know, when when folks used to look

01:25:10.155 --> 01:25:12.074
<v Speaker 1>at slides over a light box, you know,

01:25:12.074 --> 01:25:13.594
<v Speaker 1>and they would scrunch in, you know, to

01:25:13.594 --> 01:25:15.514
<v Speaker 1>look and then they would go, you know,

01:25:15.514 --> 01:25:17.594
<v Speaker 1>across it to really look very closely at

01:25:17.594 --> 01:25:19.730
<v Speaker 1>a at a slide image or a photo

01:25:19.730 --> 01:25:22.130
<v Speaker 1>negative. This is a very similar idea.

01:25:22.530 --> 01:25:26.210
<v Speaker 1>And, here, we're gonna do, 16 different filters,

01:25:26.530 --> 01:25:28.690
<v Speaker 1>and the filters will be,

01:25:29.090 --> 01:25:31.730
<v Speaker 1>three by three. And then based off of

01:25:31.730 --> 01:25:32.610
<v Speaker 1>the

01:25:33.775 --> 01:25:36.255
<v Speaker 1>output that we get where where we we

01:25:36.255 --> 01:25:38.495
<v Speaker 1>adjust the input, we'll come in with its

01:25:38.495 --> 01:25:41.615
<v Speaker 1>own, values for those those pixels, and then

01:25:41.615 --> 01:25:43.295
<v Speaker 1>the output will be,

01:25:43.775 --> 01:25:46.895
<v Speaker 1>based off of, how those pixels relate to

01:25:46.895 --> 01:25:49.130
<v Speaker 1>each other. So here we're doing, for example,

01:25:49.130 --> 01:25:51.610
<v Speaker 1>max pooling. It's a two dimensional image. We're

01:25:51.610 --> 01:25:54.409
<v Speaker 1>doing max pooling, which means that it's gonna

01:25:54.409 --> 01:25:55.449
<v Speaker 1>evaluate

01:25:55.929 --> 01:25:58.090
<v Speaker 1>the the filtered

01:25:58.330 --> 01:26:00.730
<v Speaker 1>result. Right? So it might say, you know,

01:26:00.730 --> 01:26:02.725
<v Speaker 1>whatever the algorithm is that's applying to that

01:26:02.725 --> 01:26:05.205
<v Speaker 1>that three by three, those nine pixels. And

01:26:05.205 --> 01:26:07.925
<v Speaker 1>it's saying, you know, take the max two

01:26:07.925 --> 01:26:10.804
<v Speaker 1>by two of those. Find the max values,

01:26:10.805 --> 01:26:13.285
<v Speaker 1>right, for those for for in a two

01:26:13.285 --> 01:26:14.005
<v Speaker 1>by two

01:26:14.405 --> 01:26:17.640
<v Speaker 1>for that and use only that. Then we

01:26:17.640 --> 01:26:19.880
<v Speaker 1>pass it into another layer where we're actually,

01:26:20.040 --> 01:26:22.520
<v Speaker 1>doing another layer of of convolution.

01:26:22.600 --> 01:26:25.720
<v Speaker 1>Right? So here we're doing 32 filters. Again,

01:26:25.720 --> 01:26:26.680
<v Speaker 1>three by three,

01:26:27.160 --> 01:26:28.760
<v Speaker 1>and then we're gonna pull it down to

01:26:28.760 --> 01:26:30.520
<v Speaker 1>a two by two. And we go through

01:26:30.520 --> 01:26:31.240
<v Speaker 1>that one more time.

01:26:33.645 --> 01:26:35.565
<v Speaker 1>After we get through we'll talk about activation

01:26:35.565 --> 01:26:36.925
<v Speaker 1>in a second. After we get through all

01:26:36.925 --> 01:26:39.485
<v Speaker 1>of that, what I wanna do is then

01:26:39.565 --> 01:26:42.125
<v Speaker 1>flatten this out. So I'm getting a a

01:26:42.125 --> 01:26:43.324
<v Speaker 1>a a

01:26:44.010 --> 01:26:45.129
<v Speaker 1>an array

01:26:46.409 --> 01:26:48.329
<v Speaker 1>of of values,

01:26:48.329 --> 01:26:50.329
<v Speaker 1>right, that are, you know, between

01:26:50.730 --> 01:26:53.769
<v Speaker 1>zero and one typically, some normalized

01:26:53.929 --> 01:26:54.889
<v Speaker 1>values.

01:26:55.130 --> 01:26:56.809
<v Speaker 1>And then I'm going to

01:26:57.975 --> 01:26:59.814
<v Speaker 1>then I am going to,

01:27:00.614 --> 01:27:01.974
<v Speaker 1>put those into

01:27:02.135 --> 01:27:05.094
<v Speaker 1>a neural network with 512,

01:27:05.574 --> 01:27:07.335
<v Speaker 1>neurons. So you you can think of this

01:27:07.335 --> 01:27:07.735
<v Speaker 1>as,

01:27:08.455 --> 01:27:10.375
<v Speaker 1>every neuron is a dense network, so every

01:27:10.375 --> 01:27:13.100
<v Speaker 1>neuron is connected to every other neuron. And,

01:27:13.100 --> 01:27:13.500
<v Speaker 1>essentially,

01:27:14.060 --> 01:27:16.940
<v Speaker 1>the, the way that machine learning works is

01:27:16.940 --> 01:27:17.500
<v Speaker 1>it'll,

01:27:17.820 --> 01:27:19.340
<v Speaker 1>push it through, observe,

01:27:19.580 --> 01:27:21.020
<v Speaker 1>which of the neurons,

01:27:21.260 --> 01:27:23.420
<v Speaker 1>contributed the most to,

01:27:24.700 --> 01:27:27.195
<v Speaker 1>the error that was observed. Right? So, you

01:27:27.195 --> 01:27:29.995
<v Speaker 1>know, which neuron was responsible for calling this

01:27:30.315 --> 01:27:31.755
<v Speaker 1>know, if it makes a mistake and says,

01:27:31.755 --> 01:27:33.595
<v Speaker 1>I think this person is healthy and does

01:27:33.595 --> 01:27:34.635
<v Speaker 1>not have pneumonia,

01:27:34.795 --> 01:27:37.835
<v Speaker 1>it'll the the it'll then recalculate.

01:27:37.835 --> 01:27:39.275
<v Speaker 1>Right? Just when we got a new fork,

01:27:39.275 --> 01:27:41.670
<v Speaker 1>we have to recalculate the mold. It'll recalculate

01:27:41.670 --> 01:27:43.829
<v Speaker 1>in a process called back propagation,

01:27:44.469 --> 01:27:45.270
<v Speaker 1>that

01:27:45.430 --> 01:27:48.949
<v Speaker 1>automatic well, by virtue of, partial differentiation,

01:27:49.190 --> 01:27:50.870
<v Speaker 1>we'll be able to associate

01:27:50.870 --> 01:27:53.510
<v Speaker 1>the end result, namely the error, how bad

01:27:53.590 --> 01:27:55.845
<v Speaker 1>the prediction was, how off it was in

01:27:55.845 --> 01:27:57.925
<v Speaker 1>terms of its confidence that this person was

01:27:59.525 --> 01:28:02.005
<v Speaker 1>symptomatic of of pneumonia or had pneumonia,

01:28:03.445 --> 01:28:04.725
<v Speaker 1>which neurons

01:28:04.725 --> 01:28:06.725
<v Speaker 1>contributed the most to that error. And so

01:28:06.725 --> 01:28:07.365
<v Speaker 1>we're gonna

01:28:08.050 --> 01:28:10.530
<v Speaker 1>change those neurons in the opposite direction the

01:28:10.530 --> 01:28:13.250
<v Speaker 1>most. And which neurons had relatively no impact

01:28:13.250 --> 01:28:15.410
<v Speaker 1>on the decision or on the error, let's

01:28:15.410 --> 01:28:17.890
<v Speaker 1>leave those alone. Right? Does that make sense?

01:28:18.210 --> 01:28:19.090
<v Speaker 0>Yeah. I think so.

01:28:19.745 --> 01:28:20.465
<v Speaker 1>Okay.

01:28:20.625 --> 01:28:23.265
<v Speaker 1>The activation is just what does it take

01:28:23.265 --> 01:28:25.665
<v Speaker 1>for this neuron to actually fire? Right? Like,

01:28:25.665 --> 01:28:27.745
<v Speaker 1>there we don't want every neuron to fire

01:28:27.745 --> 01:28:30.145
<v Speaker 1>all the time. There should be some minimum

01:28:30.225 --> 01:28:33.265
<v Speaker 1>of of signal that the neuron's receiving in

01:28:33.265 --> 01:28:35.800
<v Speaker 1>order for that to even be

01:28:36.440 --> 01:28:37.720
<v Speaker 1>to even be

01:28:39.000 --> 01:28:39.800
<v Speaker 1>considered

01:28:40.360 --> 01:28:42.360
<v Speaker 1>at all by the by the end result.

01:28:42.360 --> 01:28:44.920
<v Speaker 1>So ReLU is a is a contraction

01:28:44.920 --> 01:28:47.400
<v Speaker 1>of a rectified linear unit, if I recall.

01:28:47.400 --> 01:28:49.695
<v Speaker 1>So you just think about, like it

01:28:50.014 --> 01:28:51.375
<v Speaker 1>it almost looks like a,

01:28:52.415 --> 01:28:54.895
<v Speaker 1>like a a call option graph. So, you

01:28:54.895 --> 01:28:55.854
<v Speaker 1>know, nothing.

01:28:56.335 --> 01:28:58.175
<v Speaker 1>Don't give any signal. But if you get

01:28:58.175 --> 01:29:00.574
<v Speaker 1>past this threshold, then have a linear relationship

01:29:00.574 --> 01:29:03.159
<v Speaker 1>with with output to input. Sigmoid,

01:29:03.320 --> 01:29:05.400
<v Speaker 1>if you if you remember from school, is

01:29:05.400 --> 01:29:07.320
<v Speaker 1>gonna give you, like, an s shape. Right?

01:29:07.320 --> 01:29:09.880
<v Speaker 1>So far extremes will never go above two

01:29:09.880 --> 01:29:10.599
<v Speaker 1>bounds.

01:29:10.920 --> 01:29:13.639
<v Speaker 1>But as you approach zero, you start to

01:29:13.639 --> 01:29:15.400
<v Speaker 1>to see

01:29:15.525 --> 01:29:16.644
<v Speaker 1>a significant

01:29:17.125 --> 01:29:19.925
<v Speaker 1>increase and then leveling off of the

01:29:20.885 --> 01:29:23.364
<v Speaker 1>the slope of the curve. Alright? Does that

01:29:23.364 --> 01:29:25.045
<v Speaker 1>make sense? Sort of?

01:29:26.085 --> 01:29:27.765
<v Speaker 0>It's good this is going. Ask me any

01:29:27.765 --> 01:29:28.165
<v Speaker 0>questions.

01:29:31.150 --> 01:29:32.670
<v Speaker 1>No. It's just It'll make a lot more

01:29:32.670 --> 01:29:34.429
<v Speaker 1>sense once we see an an example of

01:29:34.429 --> 01:29:36.349
<v Speaker 1>it. Right? I hope so. What the models

01:29:36.349 --> 01:29:38.030
<v Speaker 1>use. Yeah. So

01:29:38.750 --> 01:29:39.389
<v Speaker 1>sorry.

01:29:39.630 --> 01:29:41.949
<v Speaker 0>No. But it's it's doing stuff. You're explaining

01:29:41.949 --> 01:29:43.865
<v Speaker 0>it well. It's just it's just not something

01:29:43.865 --> 01:29:45.225
<v Speaker 0>that I am familiar with, but I'm looking

01:29:45.225 --> 01:29:46.745
<v Speaker 0>forward to seeing the step by step through

01:29:46.745 --> 01:29:48.425
<v Speaker 0>it. So, you know, keep going. Let's do

01:29:48.505 --> 01:29:50.185
<v Speaker 1>It'll make more sense. This is why I

01:29:50.185 --> 01:29:52.345
<v Speaker 1>picked a a CNN with with images because

01:29:52.345 --> 01:29:54.025
<v Speaker 1>you can see what the model sees in

01:29:54.025 --> 01:29:54.985
<v Speaker 1>a way. Alright?

01:29:55.840 --> 01:29:56.320
<v Speaker 1>So,

01:29:56.880 --> 01:29:59.200
<v Speaker 1>here, we're gonna have I'm gonna create two,

01:30:00.480 --> 01:30:01.920
<v Speaker 1>image data generators.

01:30:02.400 --> 01:30:04.880
<v Speaker 1>This is the the help the handy,

01:30:05.200 --> 01:30:06.800
<v Speaker 1>helper functions I was talking about before.

01:30:07.935 --> 01:30:10.574
<v Speaker 1>And then we're gonna give it some information

01:30:10.574 --> 01:30:12.655
<v Speaker 1>about batch size, how much, you know, we

01:30:12.655 --> 01:30:14.415
<v Speaker 1>want them to we want it to automatically

01:30:14.415 --> 01:30:16.735
<v Speaker 1>resize each each image.

01:30:17.135 --> 01:30:18.414
<v Speaker 1>It's a binary

01:30:19.614 --> 01:30:21.215
<v Speaker 1>class in the sense that you either have

01:30:21.215 --> 01:30:22.255
<v Speaker 1>pneumonia or you don't.

01:30:23.680 --> 01:30:25.840
<v Speaker 1>We're gonna define batch size

01:30:26.080 --> 01:30:26.960
<v Speaker 1>here.

01:30:26.960 --> 01:30:28.560
<v Speaker 1>It's gonna error on me because I did

01:30:28.560 --> 01:30:28.800
<v Speaker 1>not

01:30:30.080 --> 01:30:32.000
<v Speaker 1>in the interest of simplicity, I did not

01:30:32.000 --> 01:30:32.880
<v Speaker 1>include

01:30:32.880 --> 01:30:34.800
<v Speaker 1>this, but we're going to include it.

01:30:35.200 --> 01:30:38.400
<v Speaker 1>Gonna define some some variables known as hyperparameters.

01:30:39.175 --> 01:30:40.935
<v Speaker 1>Let me copy and paste these in. We'll

01:30:40.935 --> 01:30:42.535
<v Speaker 1>talk about these a little later, but I

01:30:42.535 --> 01:30:43.975
<v Speaker 1>just wanted to have these variables,

01:30:44.215 --> 01:30:46.935
<v Speaker 1>in memory so it doesn't whine at me.

01:30:46.935 --> 01:30:48.455
<v Speaker 1>So it's gonna we're gonna define a batch

01:30:48.455 --> 01:30:49.095
<v Speaker 1>size.

01:30:49.495 --> 01:30:50.935
<v Speaker 1>We're gonna define a,

01:30:51.655 --> 01:30:53.735
<v Speaker 1>source directory and so on. Now

01:30:56.330 --> 01:30:59.450
<v Speaker 1>you didn't realize this, but when if I

01:30:59.450 --> 01:31:01.210
<v Speaker 1>may go back to the fork example,

01:31:01.930 --> 01:31:05.290
<v Speaker 1>we made some significant choices when going through

01:31:05.290 --> 01:31:06.170
<v Speaker 1>this whole exercise.

01:31:07.025 --> 01:31:10.624
<v Speaker 1>One of which was that after every fork,

01:31:10.625 --> 01:31:12.864
<v Speaker 1>we made an adjustment to the model. Right?

01:31:12.945 --> 01:31:14.304
<v Speaker 1>Which is,

01:31:15.264 --> 01:31:15.985
<v Speaker 1>okay.

01:31:16.145 --> 01:31:18.784
<v Speaker 1>Right? But may not be actually what we

01:31:18.784 --> 01:31:22.769
<v Speaker 1>want. Right? Like, we may want to average

01:31:22.850 --> 01:31:25.010
<v Speaker 1>all of the forks. Right? All of the

01:31:25.090 --> 01:31:27.330
<v Speaker 1>what let's not change the model. Let's take

01:31:27.330 --> 01:31:29.250
<v Speaker 1>the average of the of the changes to

01:31:29.250 --> 01:31:31.410
<v Speaker 1>the model suggested by the multiple forks that

01:31:31.410 --> 01:31:33.969
<v Speaker 1>we've that we've looked at in a batch

01:31:34.375 --> 01:31:37.094
<v Speaker 1>and then make make changes based on the

01:31:37.094 --> 01:31:39.574
<v Speaker 1>average suggested by that batch. Does that make

01:31:39.574 --> 01:31:41.815
<v Speaker 1>sense? Like, you don't wanna go too overboard.

01:31:41.815 --> 01:31:43.655
<v Speaker 1>Otherwise, I'll get a model that's like, you

01:31:43.655 --> 01:31:45.974
<v Speaker 1>know, Victorian t fork and and and,

01:31:46.295 --> 01:31:48.849
<v Speaker 1>pitchfork. Right? Like, maybe I can average them

01:31:48.849 --> 01:31:50.929
<v Speaker 1>together. That'll give me a healthier sort of

01:31:50.929 --> 01:31:53.650
<v Speaker 1>look. That's that's batch size. Right? The other

01:31:53.650 --> 01:31:55.170
<v Speaker 1>thing that we didn't talk about at all

01:31:55.170 --> 01:31:57.409
<v Speaker 1>is, like, for example, what kind of sand

01:31:57.409 --> 01:31:58.769
<v Speaker 1>are we using in our clay? Clay is

01:31:58.769 --> 01:32:01.185
<v Speaker 1>made from sand. Right? You know, how thick

01:32:01.185 --> 01:32:03.425
<v Speaker 1>are the grains? Right? If they're coarser,

01:32:03.665 --> 01:32:05.025
<v Speaker 1>I will have less

01:32:05.585 --> 01:32:06.864
<v Speaker 1>ability to

01:32:08.145 --> 01:32:10.465
<v Speaker 1>you know, I'll have less ability to to

01:32:11.425 --> 01:32:14.340
<v Speaker 1>create fine detail. But maybe that's good. Right?

01:32:14.340 --> 01:32:17.060
<v Speaker 1>Like, maybe I don't want the model to

01:32:17.060 --> 01:32:20.260
<v Speaker 1>expect, like, you know, these sort of, baroque,

01:32:21.699 --> 01:32:24.260
<v Speaker 1>design features of a of a fork. Right?

01:32:24.260 --> 01:32:26.260
<v Speaker 1>So this the same idea here. This is

01:32:26.260 --> 01:32:27.300
<v Speaker 1>how we define

01:32:27.535 --> 01:32:28.095
<v Speaker 1>the,

01:32:28.735 --> 01:32:31.135
<v Speaker 1>the the the nature of the mold, if

01:32:31.135 --> 01:32:31.775
<v Speaker 1>you will.

01:32:32.495 --> 01:32:33.614
<v Speaker 1>Alright. So

01:32:34.575 --> 01:32:37.455
<v Speaker 1>we've got this going on. Now we need

01:32:37.455 --> 01:32:39.535
<v Speaker 1>to compile our model. Alright.

01:32:40.980 --> 01:32:42.500
<v Speaker 1>And what we'll do here is we'll just

01:32:42.500 --> 01:32:43.860
<v Speaker 1>call the compile function,

01:32:44.180 --> 01:32:44.660
<v Speaker 1>and,

01:32:45.060 --> 01:32:47.220
<v Speaker 1>we'll use an optimizer,

01:32:47.380 --> 01:32:48.980
<v Speaker 1>called RMS prop.

01:32:49.460 --> 01:32:53.300
<v Speaker 1>And, basically, the the optimizer says excuse me.

01:32:55.375 --> 01:32:57.614
<v Speaker 1>The optimizer says, okay.

01:32:57.935 --> 01:32:59.935
<v Speaker 1>I I can calculate you'll tell me how

01:32:59.935 --> 01:33:02.175
<v Speaker 1>I'm gonna calculate loss. Right? Tell me how

01:33:02.175 --> 01:33:04.655
<v Speaker 1>I know how wrong I am. Right? In

01:33:04.655 --> 01:33:07.295
<v Speaker 1>this case, we're gonna use a loss function

01:33:07.295 --> 01:33:09.615
<v Speaker 1>called binary cross entropy, which is a way

01:33:09.615 --> 01:33:10.175
<v Speaker 1>to measure

01:33:10.739 --> 01:33:12.019
<v Speaker 1>how off

01:33:13.139 --> 01:33:14.579
<v Speaker 1>binary classification

01:33:16.099 --> 01:33:17.059
<v Speaker 1>examples are.

01:33:17.380 --> 01:33:19.460
<v Speaker 1>But, like, now tell me, like, how I

01:33:19.460 --> 01:33:22.420
<v Speaker 1>should actually adjust myself based off of that.

01:33:22.705 --> 01:33:25.105
<v Speaker 1>Like, should I go really fast in the

01:33:25.105 --> 01:33:27.905
<v Speaker 1>direction, like, of, of finding a minimum to

01:33:27.905 --> 01:33:29.505
<v Speaker 1>my error? Should I go slower?

01:33:29.665 --> 01:33:31.344
<v Speaker 1>Do I wanna have momentum?

01:33:31.665 --> 01:33:33.905
<v Speaker 1>Right? Like, there's lots of lots of things

01:33:33.905 --> 01:33:35.745
<v Speaker 1>that we can, take into consideration

01:33:36.220 --> 01:33:37.180
<v Speaker 1>for the,

01:33:37.580 --> 01:33:39.100
<v Speaker 1>for the way that the model should update

01:33:39.100 --> 01:33:40.300
<v Speaker 1>itself, for the for the way that the

01:33:40.300 --> 01:33:41.739
<v Speaker 1>mold should update itself.

01:33:42.140 --> 01:33:44.380
<v Speaker 1>Right? Alright. So we'll compile this.

01:33:45.100 --> 01:33:46.860
<v Speaker 1>Now here we go. Now now comes the

01:33:46.860 --> 01:33:47.900
<v Speaker 1>fun part. Alrighty.

01:33:49.125 --> 01:33:49.685
<v Speaker 1>So

01:33:50.485 --> 01:33:52.085
<v Speaker 1>we are going to

01:33:52.405 --> 01:33:54.885
<v Speaker 1>define a variable called history. Looks I I

01:33:54.885 --> 01:33:56.325
<v Speaker 1>remember finding this to be, like, a really

01:33:56.325 --> 01:33:59.284
<v Speaker 1>weird, a really weird sort of thing. But,

01:33:59.285 --> 01:34:00.805
<v Speaker 1>basically, you can think of it as, like,

01:34:00.885 --> 01:34:02.405
<v Speaker 1>like, the tape in a cash register.

01:34:02.820 --> 01:34:04.820
<v Speaker 1>Right? And we're gonna call a fit exercise,

01:34:04.820 --> 01:34:06.820
<v Speaker 1>and what that's gonna do is it's going

01:34:06.820 --> 01:34:08.340
<v Speaker 1>to train on the training data.

01:34:08.660 --> 01:34:12.020
<v Speaker 1>It is going to use the test data

01:34:12.020 --> 01:34:13.620
<v Speaker 1>for validating that,

01:34:13.780 --> 01:34:15.700
<v Speaker 1>and we're gonna train it for a certain

01:34:15.700 --> 01:34:18.345
<v Speaker 1>number of epochs. So how many times through

01:34:18.345 --> 01:34:20.745
<v Speaker 1>the data do we want to,

01:34:21.065 --> 01:34:22.985
<v Speaker 1>do we wanna iterate? And there are

01:34:23.785 --> 01:34:26.425
<v Speaker 1>a bajillion different features, like, ways you can

01:34:26.825 --> 01:34:28.105
<v Speaker 1>things you can specify,

01:34:28.265 --> 01:34:30.025
<v Speaker 1>within this. Like, you can do

01:34:30.660 --> 01:34:32.580
<v Speaker 1>my goodness. There's there's,

01:34:32.660 --> 01:34:35.300
<v Speaker 1>like, an an unknowable amount. You can have

01:34:35.300 --> 01:34:37.380
<v Speaker 1>callbacks to stop training based on something, you

01:34:37.380 --> 01:34:39.060
<v Speaker 1>know, that happened. Let me just kick this

01:34:39.060 --> 01:34:39.540
<v Speaker 1>off.

01:34:39.940 --> 01:34:41.540
<v Speaker 1>You can, you know, have,

01:34:42.020 --> 01:34:43.540
<v Speaker 1>you know, if you if you minimize your

01:34:43.540 --> 01:34:45.565
<v Speaker 1>loss to a certain level, you know, you

01:34:45.565 --> 01:34:46.445
<v Speaker 1>can have,

01:34:48.844 --> 01:34:50.364
<v Speaker 1>you can, you know, you can you can

01:34:50.364 --> 01:34:51.724
<v Speaker 1>introduce a

01:34:52.605 --> 01:34:54.684
<v Speaker 1>skew. You can have a holdout dataset that

01:34:54.684 --> 01:34:56.125
<v Speaker 1>only gets used at the end. I mean,

01:34:56.125 --> 01:34:58.045
<v Speaker 1>there's lots and lots of different things

01:34:58.690 --> 01:35:00.530
<v Speaker 1>that you can do when you're when you're

01:35:00.530 --> 01:35:01.489
<v Speaker 1>fitting a model.

01:35:02.770 --> 01:35:03.329
<v Speaker 1>So

01:35:03.650 --> 01:35:05.090
<v Speaker 1>what are we doing here? So this is

01:35:05.090 --> 01:35:06.530
<v Speaker 1>a this is a training

01:35:08.369 --> 01:35:11.005
<v Speaker 1>process. You're observing it in real time. So

01:35:11.005 --> 01:35:12.925
<v Speaker 1>here are the the number of,

01:35:13.565 --> 01:35:15.805
<v Speaker 1>they're called steps. So the number of of,

01:35:17.725 --> 01:35:20.205
<v Speaker 1>processes that are that are occurring and the

01:35:20.205 --> 01:35:20.765
<v Speaker 1>number of,

01:35:21.885 --> 01:35:23.885
<v Speaker 1>batches that are that are being flowed flowed

01:35:23.885 --> 01:35:24.125
<v Speaker 1>through.

01:35:25.640 --> 01:35:28.040
<v Speaker 1>Here's our loss function. Right? And here's our

01:35:28.040 --> 01:35:31.160
<v Speaker 1>accuracy. So at this point, the model is

01:35:31.160 --> 01:35:32.760
<v Speaker 1>67%

01:35:32.760 --> 01:35:33.640
<v Speaker 1>accurate,

01:35:33.640 --> 01:35:35.480
<v Speaker 1>now going up to 68.

01:35:36.920 --> 01:35:38.200
<v Speaker 1>And

01:35:39.755 --> 01:35:40.635
<v Speaker 1>and

01:35:41.035 --> 01:35:44.555
<v Speaker 1>how many epochs did we decide to lots

01:35:44.555 --> 01:35:45.995
<v Speaker 1>of inch this is the the sort of

01:35:45.995 --> 01:35:48.075
<v Speaker 1>finesse part. So we're doing one epoch here.

01:35:48.075 --> 01:35:50.395
<v Speaker 1>Okay. That's fine. So just in, like, really

01:35:50.395 --> 01:35:52.750
<v Speaker 0>simple terms. That this because this has been

01:35:52.750 --> 01:35:55.469
<v Speaker 0>seeded with images that knows have pneumonia and

01:35:55.469 --> 01:35:58.110
<v Speaker 0>images that knows that doesn't have pneumonia. It's

01:35:58.110 --> 01:36:00.349
<v Speaker 0>a looping over them, applying the model,

01:36:01.150 --> 01:36:02.670
<v Speaker 0>and then the back propagation is when it

01:36:02.670 --> 01:36:04.190
<v Speaker 0>gets one wrong and it knows it's wrong,

01:36:04.190 --> 01:36:05.870
<v Speaker 0>it feeds it back through the model tweaking

01:36:05.870 --> 01:36:08.185
<v Speaker 0>the parameters and tells the accuracy if he

01:36:08.185 --> 01:36:10.985
<v Speaker 1>gets one right. Yes. Exactly right. Exactly right.

01:36:10.985 --> 01:36:12.905
<v Speaker 1>And thanks to the beauty of calculus, we

01:36:12.905 --> 01:36:15.225
<v Speaker 1>know which which neuron,

01:36:16.025 --> 01:36:17.305
<v Speaker 1>which which signal

01:36:18.745 --> 01:36:19.385
<v Speaker 1>propagator

01:36:20.200 --> 01:36:23.720
<v Speaker 1>was the most responsible for the the problems

01:36:23.720 --> 01:36:25.320
<v Speaker 1>and which one was

01:36:25.960 --> 01:36:26.840
<v Speaker 1>irrelevant.

01:36:27.000 --> 01:36:28.920
<v Speaker 1>And so the beauty of

01:36:29.240 --> 01:36:32.679
<v Speaker 1>of tools like RMS prop as the optimizer

01:36:32.760 --> 01:36:35.240
<v Speaker 1>is that they can account for that difference

01:36:35.240 --> 01:36:38.255
<v Speaker 1>in scale, right, that difference in in impact

01:36:38.255 --> 01:36:40.015
<v Speaker 1>in order to adjust

01:36:40.175 --> 01:36:42.655
<v Speaker 1>on a per neuron basis

01:36:42.815 --> 01:36:43.695
<v Speaker 1>exactly

01:36:43.855 --> 01:36:44.575
<v Speaker 1>what

01:36:46.175 --> 01:36:49.775
<v Speaker 1>exactly how much to adjust the the the

01:36:50.150 --> 01:36:53.750
<v Speaker 1>formula for propagating signal for each neuron. Right?

01:36:53.750 --> 01:36:55.830
<v Speaker 1>Right. So I push one through. I it's

01:36:55.830 --> 01:36:57.190
<v Speaker 1>a it's a pneumonia.

01:36:57.190 --> 01:36:59.670
<v Speaker 1>I correctly predict that it's ammonia. Good.

01:36:59.990 --> 01:37:03.095
<v Speaker 1>I wanna encourage my model to use that

01:37:03.095 --> 01:37:04.855
<v Speaker 1>as a as a thumbs up. Like, whatever

01:37:04.855 --> 01:37:06.455
<v Speaker 1>you just did was good. Use that a

01:37:06.455 --> 01:37:08.375
<v Speaker 1>lot. Right? Like, use those are those are

01:37:08.375 --> 01:37:09.815
<v Speaker 1>the signals you gotta be looking for in

01:37:09.815 --> 01:37:12.295
<v Speaker 1>terms of pneumonia. Right? And then it'll go

01:37:12.295 --> 01:37:14.135
<v Speaker 1>back and make those, you know, changes, make

01:37:14.135 --> 01:37:16.560
<v Speaker 1>them more ingrained. Right? Now I go forward.

01:37:16.560 --> 01:37:18.240
<v Speaker 1>I find out that I goofed up. Okay.

01:37:18.240 --> 01:37:20.880
<v Speaker 1>Well, I'm gonna come backwards and adjust that

01:37:20.880 --> 01:37:23.600
<v Speaker 1>so that my loss, my my error

01:37:23.680 --> 01:37:26.400
<v Speaker 1>is smaller. All of machine learning is just

01:37:26.400 --> 01:37:28.684
<v Speaker 1>reducing your loss. Picking a good finding your

01:37:28.684 --> 01:37:31.405
<v Speaker 1>data, picking a good, loss algorithm,

01:37:31.885 --> 01:37:33.324
<v Speaker 1>way to calculate loss,

01:37:33.485 --> 01:37:35.565
<v Speaker 1>and then trying to make that loss smaller.

01:37:35.565 --> 01:37:37.885
<v Speaker 1>That's that's the ballgame. Right? Does that make

01:37:37.885 --> 01:37:42.460
<v Speaker 1>sense? Yes. Yeah. So what we are, observing

01:37:42.460 --> 01:37:43.019
<v Speaker 1>here,

01:37:43.580 --> 01:37:45.500
<v Speaker 1>is highly characteristic

01:37:45.500 --> 01:37:47.980
<v Speaker 1>of, machine learning exercises,

01:37:48.300 --> 01:37:49.980
<v Speaker 1>and that is that we have a loss.

01:37:49.980 --> 01:37:51.420
<v Speaker 1>Let's ignore that for now because it doesn't

01:37:51.420 --> 01:37:52.744
<v Speaker 1>really mean a whole lot. And And we

01:37:52.744 --> 01:37:54.505
<v Speaker 1>have an accuracy with the training data, and

01:37:54.505 --> 01:37:56.905
<v Speaker 1>the the training data is 75%

01:37:56.905 --> 01:37:59.065
<v Speaker 1>accurate. Not bad. Right? I mean, I don't

01:37:59.065 --> 01:38:00.985
<v Speaker 1>know anything about X rays. I don't know

01:38:00.985 --> 01:38:04.184
<v Speaker 1>anything about the the, you know,

01:38:04.585 --> 01:38:05.864
<v Speaker 1>the the

01:38:07.820 --> 01:38:08.619
<v Speaker 1>the

01:38:10.380 --> 01:38:13.740
<v Speaker 1>not abstract algebra, linear algebra that's sitting behind

01:38:13.740 --> 01:38:15.420
<v Speaker 1>this in terms of, like, you know, how

01:38:15.420 --> 01:38:17.100
<v Speaker 1>the the the

01:38:17.180 --> 01:38:19.580
<v Speaker 1>tensor flow is optimizing the tensors,

01:38:19.885 --> 01:38:22.845
<v Speaker 1>you know, to tensors are just, multidimensional

01:38:22.845 --> 01:38:24.845
<v Speaker 1>matrices. You know, how it's doing all of

01:38:24.845 --> 01:38:26.845
<v Speaker 1>that, I have no freaking clue. But I,

01:38:26.845 --> 01:38:29.885
<v Speaker 1>myself, as an end user, have, now created

01:38:29.885 --> 01:38:33.960
<v Speaker 1>a, model that, is not 75%

01:38:33.960 --> 01:38:36.599
<v Speaker 1>accurate, but 70% accurate. So remember, we split

01:38:36.599 --> 01:38:37.959
<v Speaker 1>our data into testing

01:38:38.119 --> 01:38:40.519
<v Speaker 1>to training and testing. And the training data

01:38:40.519 --> 01:38:42.679
<v Speaker 1>was given to the model to, like, you

01:38:42.679 --> 01:38:44.840
<v Speaker 1>know, Victor Rocky, like, okay. I'm gonna learn

01:38:44.840 --> 01:38:46.395
<v Speaker 1>from this. Right? And then we, you know,

01:38:46.395 --> 01:38:48.395
<v Speaker 1>here's the big competition. You know, it's not

01:38:48.395 --> 01:38:50.475
<v Speaker 1>your standard sparring partner. These are images you've

01:38:50.475 --> 01:38:53.435
<v Speaker 1>never seen before. Right? And here, you can

01:38:53.435 --> 01:38:56.155
<v Speaker 1>see that my accuracy on my validation is

01:38:56.155 --> 01:38:57.355
<v Speaker 1>only 70%.

01:38:57.435 --> 01:38:59.450
<v Speaker 1>Right? And so oftentimes,

01:38:59.450 --> 01:39:01.690
<v Speaker 1>what you'll see let's actually run this for

01:39:01.690 --> 01:39:03.530
<v Speaker 1>a a few more epochs,

01:39:03.770 --> 01:39:06.170
<v Speaker 1>to to make the make the point,

01:39:06.490 --> 01:39:09.130
<v Speaker 1>even more apparent, and we'll continue on,

01:39:09.450 --> 01:39:10.730
<v Speaker 1>while this is running.

01:39:11.290 --> 01:39:12.250
<v Speaker 1>We'll do four.

01:39:13.025 --> 01:39:16.225
<v Speaker 1>A GPU would have been nice, but I

01:39:16.225 --> 01:39:17.585
<v Speaker 1>didn't wanna overcomplicate

01:39:17.585 --> 01:39:18.145
<v Speaker 1>things.

01:39:20.145 --> 01:39:22.545
<v Speaker 1>What you'll observe is very common.

01:39:22.785 --> 01:39:24.945
<v Speaker 1>It's known in the if you've ever heard

01:39:24.945 --> 01:39:26.065
<v Speaker 1>this term, overfitting,

01:39:26.300 --> 01:39:29.740
<v Speaker 1>which basically says, I am excellent at predicting

01:39:29.740 --> 01:39:31.820
<v Speaker 1>the four forks that I have seen. You

01:39:31.820 --> 01:39:32.860
<v Speaker 1>give me one of those forks, I'm a

01:39:32.860 --> 01:39:35.020
<v Speaker 1>crush that. Like, no way I'm screwing up

01:39:35.020 --> 01:39:37.100
<v Speaker 1>those four forks. You bring me a rate.

01:39:37.100 --> 01:39:38.540
<v Speaker 1>I've never seen it before. As far as

01:39:38.540 --> 01:39:39.900
<v Speaker 1>I know, it's got the right you know,

01:39:39.900 --> 01:39:42.185
<v Speaker 1>like, the world is different than what I've

01:39:42.185 --> 01:39:45.625
<v Speaker 1>been trained on. Right? So it is highly

01:39:46.265 --> 01:39:48.585
<v Speaker 1>possible. Like, here you can see, like, you

01:39:48.585 --> 01:39:49.065
<v Speaker 1>know,

01:39:49.385 --> 01:39:53.225
<v Speaker 1>it is highly possible to get incredibly

01:39:53.625 --> 01:39:54.905
<v Speaker 1>high accuracy

01:39:55.580 --> 01:39:58.700
<v Speaker 1>in your training data, but it's so specific

01:39:58.700 --> 01:40:01.420
<v Speaker 1>to your training data that, you know,

01:40:01.980 --> 01:40:04.060
<v Speaker 1>I don't know, a a fork from somewhere

01:40:04.060 --> 01:40:05.660
<v Speaker 1>else in the world is not gonna get

01:40:05.660 --> 01:40:07.020
<v Speaker 1>recognized a fork even though it's a fork.

01:40:07.020 --> 01:40:09.260
<v Speaker 1>That makes sense? So so there this is

01:40:09.260 --> 01:40:11.455
<v Speaker 1>where we were talking art and science. This

01:40:11.455 --> 01:40:13.534
<v Speaker 1>is where an an experienced,

01:40:13.855 --> 01:40:16.015
<v Speaker 1>data scientist will be able to, you know,

01:40:16.015 --> 01:40:18.495
<v Speaker 1>see very quickly, like, wait a second. You're

01:40:18.495 --> 01:40:20.815
<v Speaker 1>telling me I got 92% accuracy and I

01:40:20.815 --> 01:40:23.375
<v Speaker 1>have, like, a dataset of 5,000 images? This

01:40:23.375 --> 01:40:27.250
<v Speaker 1>is overfit. This is this is basically memorizing

01:40:27.250 --> 01:40:30.130
<v Speaker 1>this this dataset and not generalizing

01:40:30.130 --> 01:40:30.849
<v Speaker 1>to

01:40:30.930 --> 01:40:33.489
<v Speaker 1>X rays of people with with

01:40:34.050 --> 01:40:36.210
<v Speaker 1>pneumonia or not. Right? Does that make sense?

01:40:36.210 --> 01:40:39.224
<v Speaker 0>It does make sense. Yes. Okay. Cool.

01:40:39.864 --> 01:40:42.184
<v Speaker 1>I may actually want to interrupt

01:40:42.665 --> 01:40:45.065
<v Speaker 1>this because this could take a hot sec,

01:40:45.065 --> 01:40:45.465
<v Speaker 1>but,

01:40:46.665 --> 01:40:48.505
<v Speaker 1>it's okay. We can we can

01:40:48.905 --> 01:40:50.344
<v Speaker 1>we can do other stuff in the meantime.

01:40:50.989 --> 01:40:53.390
<v Speaker 1>Alright. So next up, I am going to

01:40:53.390 --> 01:40:55.469
<v Speaker 1>just copy and paste in some,

01:40:55.710 --> 01:40:58.190
<v Speaker 1>visualization stuff. This is not, you know, overly

01:40:58.190 --> 01:40:58.909
<v Speaker 1>exciting.

01:40:59.630 --> 01:41:01.310
<v Speaker 1>And then once that,

01:41:01.790 --> 01:41:02.510
<v Speaker 1>runs,

01:41:02.989 --> 01:41:05.630
<v Speaker 1>the above cell runs, then, we will be

01:41:05.630 --> 01:41:06.190
<v Speaker 1>able to

01:41:06.925 --> 01:41:08.765
<v Speaker 1>see some output here. So let me let

01:41:08.765 --> 01:41:09.885
<v Speaker 1>me queue this up.

01:41:10.605 --> 01:41:11.405
<v Speaker 1>And then

01:41:12.445 --> 01:41:14.445
<v Speaker 1>here we go. So the first thing we're

01:41:14.445 --> 01:41:16.684
<v Speaker 1>gonna visualize is the relationship between,

01:41:18.284 --> 01:41:18.925
<v Speaker 1>between,

01:41:20.844 --> 01:41:22.045
<v Speaker 1>the

01:41:26.420 --> 01:41:27.379
<v Speaker 1>epoch

01:41:27.860 --> 01:41:30.179
<v Speaker 1>will be our will be our x axis.

01:41:30.260 --> 01:41:32.500
<v Speaker 1>Then we will observe accuracy and loss and

01:41:32.500 --> 01:41:36.095
<v Speaker 1>then validation accuracy and validation loss. Right? And

01:41:36.095 --> 01:41:38.015
<v Speaker 1>so we'll be able to see what we'll

01:41:38.015 --> 01:41:41.215
<v Speaker 1>observe almost assuredly is that the you know,

01:41:41.215 --> 01:41:44.815
<v Speaker 1>look here. Right? Here, I've got validation accuracy

01:41:44.975 --> 01:41:46.415
<v Speaker 1>of 72%,

01:41:46.415 --> 01:41:49.375
<v Speaker 1>and I've got, training accuracy of 93%.

01:41:49.780 --> 01:41:51.780
<v Speaker 1>Right? And what you'll observe is that, you

01:41:51.780 --> 01:41:54.020
<v Speaker 1>know, it'll start to memorize that training dataset,

01:41:54.020 --> 01:41:56.900
<v Speaker 1>but in fact, our validation accuracy, how well

01:41:56.900 --> 01:41:59.220
<v Speaker 1>it works on data it hasn't seen, will

01:41:59.220 --> 01:42:01.060
<v Speaker 1>in fact, at a certain point start to

01:42:01.060 --> 01:42:03.140
<v Speaker 1>go down because the model is is not

01:42:03.185 --> 01:42:05.665
<v Speaker 1>is is overfitting. The model is is too

01:42:05.665 --> 01:42:07.825
<v Speaker 1>specific to the training set, and it is

01:42:07.825 --> 01:42:09.265
<v Speaker 1>picking up on things that are in fact

01:42:09.265 --> 01:42:10.704
<v Speaker 1>not generalized,

01:42:11.025 --> 01:42:13.824
<v Speaker 1>qualities of a of a a pneumonia patient,

01:42:13.825 --> 01:42:14.545
<v Speaker 1>but rather

01:42:15.989 --> 01:42:18.389
<v Speaker 1>these specific 5,000,

01:42:18.389 --> 01:42:19.589
<v Speaker 1>you know, people's

01:42:21.269 --> 01:42:22.469
<v Speaker 1>idiosyncrasies.

01:42:23.030 --> 01:42:24.710
<v Speaker 0>Is it fair to say then that the

01:42:24.710 --> 01:42:27.189
<v Speaker 0>dataset is the most important part of these

01:42:27.349 --> 01:42:31.045
<v Speaker 0>models? Or is Oh, yeah. For sure. For

01:42:31.045 --> 01:42:34.725
<v Speaker 1>sure. The dataset is everything. In fact, there

01:42:34.725 --> 01:42:35.205
<v Speaker 1>are new

01:42:36.005 --> 01:42:38.565
<v Speaker 1>it's it's it's really exciting. I mean, this

01:42:38.565 --> 01:42:40.565
<v Speaker 1>might if we watch this in five years,

01:42:40.565 --> 01:42:42.165
<v Speaker 1>we might be you know, it it'd be

01:42:42.165 --> 01:42:44.460
<v Speaker 1>like trying to encourage someone to program COBOL

01:42:44.460 --> 01:42:46.539
<v Speaker 1>these days. Like, we may we may look

01:42:46.539 --> 01:42:49.260
<v Speaker 1>like absolute medieval, you know, dinosaurs.

01:42:49.260 --> 01:42:50.300
<v Speaker 1>And the reason for that, I mean, there

01:42:50.300 --> 01:42:51.659
<v Speaker 1>are products on the market.

01:42:52.539 --> 01:42:56.139
<v Speaker 1>Apple produced one for for their software development

01:42:56.139 --> 01:42:58.335
<v Speaker 1>kit. I forget what it's called. But, basically,

01:42:58.335 --> 01:43:00.975
<v Speaker 1>the entire thing is a UI. You know,

01:43:00.975 --> 01:43:03.695
<v Speaker 1>it looks like any Apple design product that

01:43:03.695 --> 01:43:06.014
<v Speaker 1>has two

01:43:06.655 --> 01:43:07.454
<v Speaker 1>boxes.

01:43:07.695 --> 01:43:08.494
<v Speaker 1>Drag

01:43:09.135 --> 01:43:12.575
<v Speaker 1>test data. Yeah. Drag, yeah, drag drag category

01:43:12.575 --> 01:43:16.070
<v Speaker 1>one here, drag category two images there. And

01:43:16.070 --> 01:43:17.270
<v Speaker 1>then you don't see

01:43:17.670 --> 01:43:19.830
<v Speaker 1>anything about it, and it produces a model.

01:43:19.830 --> 01:43:22.310
<v Speaker 1>The reality is that even though,

01:43:22.790 --> 01:43:27.510
<v Speaker 1>this type of of a very specific

01:43:26.685 --> 01:43:29.005
<v Speaker 1>evaluate you know, the the the tuning,

01:43:29.005 --> 01:43:31.645
<v Speaker 1>the the model structure, how many layers, what

01:43:31.645 --> 01:43:33.245
<v Speaker 1>kinda convolutions,

01:43:33.245 --> 01:43:35.005
<v Speaker 1>should it be dense, should it be RELU,

01:43:35.005 --> 01:43:37.885
<v Speaker 1>sigma, all these sorts of details are far

01:43:38.445 --> 01:43:40.045
<v Speaker 1>less

01:43:39.470 --> 01:43:41.390
<v Speaker 1>important than the dataset, which is to say

01:43:41.390 --> 01:43:43.710
<v Speaker 1>that you could have way more

01:43:45.710 --> 01:43:46.989
<v Speaker 1>performant models

01:43:47.070 --> 01:43:49.150
<v Speaker 1>with a bigger dataset as a you know,

01:43:49.150 --> 01:43:51.150
<v Speaker 1>with as opposed to, like, what is the

01:43:51.150 --> 01:43:53.070
<v Speaker 1>impact of, like, fiddling with your model architecture

01:43:53.070 --> 01:43:55.645
<v Speaker 1>or, like, the the associated stuff. Now these

01:43:55.725 --> 01:43:58.045
<v Speaker 1>it's still valuable areas of research, but, you

01:43:58.045 --> 01:43:58.445
<v Speaker 1>know,

01:43:58.925 --> 01:44:01.565
<v Speaker 1>it's it's it re it is really, really,

01:44:01.565 --> 01:44:03.565
<v Speaker 1>really all about the dataset. So another one

01:44:03.565 --> 01:44:05.324
<v Speaker 1>that I I saw recently, I think it's

01:44:05.324 --> 01:44:06.364
<v Speaker 1>called MindsDB,

01:44:07.220 --> 01:44:09.940
<v Speaker 1>where it's a imagine a SQL database

01:44:10.020 --> 01:44:11.060
<v Speaker 1>where you say,

01:44:11.380 --> 01:44:12.980
<v Speaker 1>okay. I made a table,

01:44:13.700 --> 01:44:16.420
<v Speaker 1>and here are the the features. So the

01:44:16.420 --> 01:44:18.980
<v Speaker 1>the parameters that or the the details about

01:44:18.980 --> 01:44:21.264
<v Speaker 1>the the row, And here's the outcome. Right?

01:44:21.264 --> 01:44:23.025
<v Speaker 1>So, you know, think of a silly example,

01:44:23.025 --> 01:44:25.264
<v Speaker 1>like an ecommerce example. Here's, you know,

01:44:27.505 --> 01:44:29.905
<v Speaker 1>the SKU or the the the

01:44:31.105 --> 01:44:33.664
<v Speaker 1>the product ID of the first thing this

01:44:33.664 --> 01:44:35.025
<v Speaker 1>person bought, second, third, fourth,

01:44:36.050 --> 01:44:36.770
<v Speaker 1>and,

01:44:37.330 --> 01:44:39.570
<v Speaker 1>you know, here's what they bought fifth. So

01:44:39.570 --> 01:44:41.010
<v Speaker 1>I wanna be able to predict with four

01:44:41.010 --> 01:44:42.450
<v Speaker 1>what the fifth one is gonna be. So

01:44:42.450 --> 01:44:44.530
<v Speaker 1>you just, like, tell it, like, give me

01:44:44.530 --> 01:44:46.850
<v Speaker 1>another column that is predict five.

01:44:47.455 --> 01:44:49.695
<v Speaker 1>Like and it'll it'll just do this all

01:44:49.695 --> 01:44:51.775
<v Speaker 1>behind the scenes. And in particular, you know,

01:44:51.775 --> 01:44:53.935
<v Speaker 1>there's in Kubeflow, there's some great automation around

01:44:53.935 --> 01:44:54.735
<v Speaker 1>this as well,

01:44:55.775 --> 01:44:57.295
<v Speaker 1>which we'll see in a second, to be

01:44:57.295 --> 01:44:58.335
<v Speaker 1>able to,

01:44:58.975 --> 01:44:59.695
<v Speaker 1>evaluate,

01:45:00.094 --> 01:45:01.215
<v Speaker 1>things programmatically.

01:45:01.500 --> 01:45:03.900
<v Speaker 1>That's why I've defined things like,

01:45:04.700 --> 01:45:06.860
<v Speaker 1>you know, epochs, learning rate, and batch size

01:45:06.860 --> 01:45:07.980
<v Speaker 1>as hyperparameters

01:45:07.980 --> 01:45:10.220
<v Speaker 1>to to fiddle with that. And I'd it

01:45:10.220 --> 01:45:12.540
<v Speaker 1>is I really wanna do an a demo

01:45:12.540 --> 01:45:14.300
<v Speaker 1>of this, but it's possible to to fiddle

01:45:14.300 --> 01:45:15.660
<v Speaker 1>with your your

01:45:17.505 --> 01:45:19.905
<v Speaker 1>model architecture too. Right? Like, you could say

01:45:19.905 --> 01:45:21.985
<v Speaker 1>put in another layer, remove a layer, add

01:45:21.985 --> 01:45:23.905
<v Speaker 1>a, you know, more neurons, less neurons. Those

01:45:23.905 --> 01:45:26.065
<v Speaker 1>could be variables that you could experiment with

01:45:26.065 --> 01:45:28.465
<v Speaker 1>also. How specific can you scroll back up

01:45:28.465 --> 01:45:30.945
<v Speaker 0>to the convolution and the the thing? Like,

01:45:30.945 --> 01:45:33.010
<v Speaker 0>see, there's, 12 lines of code there. Is

01:45:33.010 --> 01:45:34.770
<v Speaker 0>this the main bulk of our model and

01:45:34.770 --> 01:45:37.250
<v Speaker 0>how specific is that to detect a pneumonia?

01:45:37.250 --> 01:45:38.530
<v Speaker 0>Like, if I were to throw a different

01:45:38.530 --> 01:45:40.210
<v Speaker 0>set of images at it, like,

01:45:40.610 --> 01:45:42.930
<v Speaker 0>you know, a football and, you know, a

01:45:42.930 --> 01:45:44.715
<v Speaker 0>golf ball, Is it still gonna be the

01:45:44.715 --> 01:45:46.315
<v Speaker 0>same pattern? Do I have to tweak what

01:45:46.315 --> 01:45:48.315
<v Speaker 0>I'm changing in the code? Like, how does

01:45:48.315 --> 01:45:48.955
<v Speaker 0>that work?

01:45:49.675 --> 01:45:52.475
<v Speaker 1>Yes. So you would not have to

01:45:53.995 --> 01:45:55.435
<v Speaker 1>you could you could throw

01:45:55.835 --> 01:45:58.075
<v Speaker 1>any any binary image classification,

01:45:58.430 --> 01:46:00.590
<v Speaker 1>you know, that has three channels and could

01:46:00.590 --> 01:46:02.830
<v Speaker 1>be, you know, resized reasonably to one fifty,

01:46:02.830 --> 01:46:05.310
<v Speaker 1>one 50 into this. There's there's nothing at

01:46:05.310 --> 01:46:06.510
<v Speaker 1>all special about it.

01:46:09.470 --> 01:46:10.990
<v Speaker 1>After all, if I did it, it can't

01:46:10.990 --> 01:46:12.670
<v Speaker 1>be that special. Right? Like, I I literally

01:46:12.750 --> 01:46:14.705
<v Speaker 1>and, like, I'm not a specialist on this.

01:46:15.745 --> 01:46:16.304
<v Speaker 1>But

01:46:17.425 --> 01:46:19.825
<v Speaker 1>you would have to retrain the model. Right?

01:46:19.825 --> 01:46:22.065
<v Speaker 1>So you couldn't take an an an extant

01:46:22.065 --> 01:46:22.784
<v Speaker 1>model

01:46:22.945 --> 01:46:25.825
<v Speaker 1>and and use it for

01:46:26.730 --> 01:46:27.770
<v Speaker 1>as is

01:46:27.930 --> 01:46:29.930
<v Speaker 1>for footballs and and

01:46:32.330 --> 01:46:34.969
<v Speaker 1>I wanted to say, like, footballs and and

01:46:35.130 --> 01:46:37.610
<v Speaker 1>soccer balls, but I think you probably meant

01:46:37.610 --> 01:46:39.155
<v Speaker 1>a soccer ball in the first place. So

01:46:39.155 --> 01:46:41.075
<v Speaker 1>one, footballs and baseballs.

01:46:41.715 --> 01:46:42.355
<v Speaker 1>And

01:46:42.915 --> 01:46:43.715
<v Speaker 1>and

01:46:44.195 --> 01:46:46.275
<v Speaker 1>and you would have to then do you

01:46:46.275 --> 01:46:47.955
<v Speaker 1>have two options. Either you can just take

01:46:47.955 --> 01:46:49.555
<v Speaker 1>the raw model and

01:46:50.275 --> 01:46:53.235
<v Speaker 1>and just train it again. Just basically point

01:46:53.235 --> 01:46:56.559
<v Speaker 1>this notebook to a different set of directories.

01:46:56.640 --> 01:46:58.960
<v Speaker 1>Or, you can do what's called transfer learning,

01:46:58.960 --> 01:47:00.239
<v Speaker 1>which is, in many cases,

01:47:00.800 --> 01:47:02.719
<v Speaker 1>what we're doing here is nothing more than

01:47:02.719 --> 01:47:05.520
<v Speaker 1>passing a series of filters over stuff. Right?

01:47:06.000 --> 01:47:07.920
<v Speaker 1>And then observing the output. So then with

01:47:07.920 --> 01:47:09.920
<v Speaker 1>transfer learning and this can be very expensive.

01:47:09.920 --> 01:47:11.745
<v Speaker 1>Right? With transfer learning, what we do is

01:47:11.745 --> 01:47:13.585
<v Speaker 1>imagine you just stuck another layer on the

01:47:13.585 --> 01:47:14.145
<v Speaker 1>bottom,

01:47:14.385 --> 01:47:16.785
<v Speaker 1>right, that said, yeah. Okay. Start with the

01:47:16.785 --> 01:47:18.785
<v Speaker 1>model as it exists. Right? Because it's a

01:47:18.785 --> 01:47:21.345
<v Speaker 1>pretty good model for for two dimensional images.

01:47:21.345 --> 01:47:22.865
<v Speaker 1>I like it a lot. I don't wanna

01:47:22.865 --> 01:47:25.025
<v Speaker 1>pay the compute and time and hassle to

01:47:25.025 --> 01:47:27.480
<v Speaker 1>redo everything associated with them. I might not

01:47:27.480 --> 01:47:28.920
<v Speaker 1>even have a chance to. It might not

01:47:28.920 --> 01:47:30.760
<v Speaker 1>be possible for me. I might not have

01:47:30.760 --> 01:47:32.199
<v Speaker 1>access to the source data.

01:47:32.760 --> 01:47:34.440
<v Speaker 1>But I have this new dataset, and I

01:47:34.600 --> 01:47:36.760
<v Speaker 1>and it is a binary image classification.

01:47:36.760 --> 01:47:37.400
<v Speaker 1>So,

01:47:37.960 --> 01:47:41.225
<v Speaker 1>I'm gonna have it hold this set of

01:47:44.025 --> 01:47:45.065
<v Speaker 1>manipulations

01:47:45.625 --> 01:47:46.425
<v Speaker 1>constant,

01:47:46.425 --> 01:47:47.865
<v Speaker 1>and then just fiddle with the the new

01:47:47.865 --> 01:47:50.025
<v Speaker 1>stuff that's that's underneath. Don't only change that.

01:47:50.025 --> 01:47:51.145
<v Speaker 1>That's called transfer learning.

01:47:51.880 --> 01:47:53.080
<v Speaker 0>Okay. Awesome.

01:47:53.480 --> 01:47:55.240
<v Speaker 0>Yeah. We've got a a question there, which

01:47:55.240 --> 01:47:56.440
<v Speaker 0>I'll throw up just now. You know, I

01:47:56.440 --> 01:47:58.440
<v Speaker 0>think our epochs are just about done.

01:47:58.920 --> 01:48:02.200
<v Speaker 0>Yep. Alvin asks, how did the 512 neurons

01:48:02.200 --> 01:48:04.280
<v Speaker 0>get matched to the flatten out pixel array?

01:48:04.280 --> 01:48:06.520
<v Speaker 0>Do each neurons get assigned some pixels?

01:48:08.014 --> 01:48:08.814
<v Speaker 1>Ah.

01:48:13.054 --> 01:48:14.974
<v Speaker 1>Let me show you. So you see here,

01:48:14.974 --> 01:48:16.334
<v Speaker 1>there's a flattened layer.

01:48:16.735 --> 01:48:19.295
<v Speaker 1>That's that's what did it. And yes. So

01:48:19.295 --> 01:48:20.895
<v Speaker 1>so it got flattened out.

01:48:21.690 --> 01:48:24.170
<v Speaker 1>It basically just, you know, take,

01:48:24.490 --> 01:48:25.770
<v Speaker 1>I'm trying to think what was, like, a

01:48:25.770 --> 01:48:27.450
<v Speaker 1>Lego, basically. Take a block off the top,

01:48:27.450 --> 01:48:28.730
<v Speaker 1>put it over here, take the next block

01:48:28.730 --> 01:48:32.490
<v Speaker 1>off, put it next to it, but flattens

01:48:32.490 --> 01:48:33.930
<v Speaker 1>it all out, just a bunch of numbers.

01:48:34.265 --> 01:48:36.505
<v Speaker 1>Those numbers go into a neuron. A neuron

01:48:36.505 --> 01:48:38.985
<v Speaker 1>is just a formula, like a y equals

01:48:38.985 --> 01:48:41.225
<v Speaker 1>m x plus b type type of thing.

01:48:41.385 --> 01:48:44.185
<v Speaker 1>The the b is your bias.

01:48:44.505 --> 01:48:47.545
<v Speaker 1>The y is your or excuse me. The

01:48:47.545 --> 01:48:49.385
<v Speaker 1>m is your

01:48:49.680 --> 01:48:50.640
<v Speaker 1>is the,

01:48:50.880 --> 01:48:51.840
<v Speaker 1>is your

01:48:52.640 --> 01:48:53.360
<v Speaker 1>slope,

01:48:54.160 --> 01:48:56.160
<v Speaker 1>and then the x is your input value.

01:48:56.400 --> 01:48:59.120
<v Speaker 1>And, then all of the the neurons are

01:48:59.120 --> 01:49:01.360
<v Speaker 1>connected to all of the other neurons. So

01:49:02.585 --> 01:49:04.665
<v Speaker 1>based on the back propagation,

01:49:04.665 --> 01:49:06.105
<v Speaker 1>some will be elevated,

01:49:06.105 --> 01:49:08.425
<v Speaker 1>some in terms of their signal amplification, some

01:49:08.425 --> 01:49:09.624
<v Speaker 1>will be muted.

01:49:09.625 --> 01:49:11.144
<v Speaker 1>Right? And,

01:49:11.545 --> 01:49:13.144
<v Speaker 1>as a result of that,

01:49:14.025 --> 01:49:16.344
<v Speaker 1>the the model learns

01:49:16.585 --> 01:49:18.790
<v Speaker 1>how to what neurons

01:49:18.790 --> 01:49:21.830
<v Speaker 1>indicate what outcome and and at what to

01:49:21.830 --> 01:49:22.630
<v Speaker 1>what degree.

01:49:23.190 --> 01:49:24.469
<v Speaker 0>Nice. Thank you.

01:49:24.949 --> 01:49:25.590
<v Speaker 0>Mhmm.

01:49:26.070 --> 01:49:28.310
<v Speaker 0>Do we have some visuals? YouTube video. I'm

01:49:28.310 --> 01:49:29.750
<v Speaker 0>sorry to go. No.

01:49:29.989 --> 01:49:31.350
<v Speaker 1>No. There's a great YouTube video

01:49:31.845 --> 01:49:34.885
<v Speaker 1>that that does a fantastic job visually animating

01:49:34.885 --> 01:49:37.205
<v Speaker 1>all of this process. So so anyways, here

01:49:37.205 --> 01:49:38.725
<v Speaker 1>we go. Let's let's take a look at

01:49:38.725 --> 01:49:40.485
<v Speaker 1>some visualization. So we started off

01:49:41.125 --> 01:49:43.925
<v Speaker 1>unusually high. The the seed obviously updated as

01:49:43.925 --> 01:49:45.365
<v Speaker 1>this was our second time running through it.

01:49:46.550 --> 01:49:47.269
<v Speaker 1>And

01:49:47.510 --> 01:49:48.869
<v Speaker 1>but what you observe is that there is

01:49:48.869 --> 01:49:51.590
<v Speaker 1>a significant delta. Right? And and we got

01:49:51.590 --> 01:49:53.349
<v Speaker 1>very lucky. On this fourth run through, we

01:49:53.349 --> 01:49:55.269
<v Speaker 1>got a higher accuracy than

01:49:55.510 --> 01:49:58.070
<v Speaker 1>than in any previous. But, typically, what you

01:49:58.070 --> 01:50:00.309
<v Speaker 1>see is that, you know, there is a

01:50:00.309 --> 01:50:01.269
<v Speaker 1>a decline

01:50:01.685 --> 01:50:02.645
<v Speaker 1>over time.

01:50:03.845 --> 01:50:05.205
<v Speaker 1>And this is the loss, so just the

01:50:05.205 --> 01:50:07.925
<v Speaker 1>inverse of the accuracy. Not the exact inverse,

01:50:07.925 --> 01:50:09.605
<v Speaker 1>but, you know, accuracy

01:50:09.605 --> 01:50:11.845
<v Speaker 1>is success, loss is failure.

01:50:12.245 --> 01:50:13.605
<v Speaker 1>So, you know, you can see that the

01:50:13.605 --> 01:50:15.525
<v Speaker 1>curves point in the the mirror image way.

01:50:15.800 --> 01:50:18.760
<v Speaker 1>That make sense? It does. Alright. Great. So

01:50:18.760 --> 01:50:20.680
<v Speaker 1>now let's let's get to sort of a

01:50:20.680 --> 01:50:22.920
<v Speaker 1>a a look at what is actually,

01:50:23.800 --> 01:50:25.560
<v Speaker 1>what is the model actually seeing?

01:50:25.960 --> 01:50:28.440
<v Speaker 1>So here we go. So here's this is

01:50:28.600 --> 01:50:31.640
<v Speaker 1>these map to our our layers. Right? So

01:50:30.785 --> 01:50:32.945
<v Speaker 1>what do we say? We wanted 16 different

01:50:32.945 --> 01:50:35.824
<v Speaker 1>filters passed over the image. Okay?

01:50:36.065 --> 01:50:37.665
<v Speaker 1>And here we can see that this is

01:50:37.665 --> 01:50:39.905
<v Speaker 1>a pneumonia example. Alright.

01:50:40.145 --> 01:50:42.065
<v Speaker 1>So what we're doing, we're passing a filter

01:50:42.065 --> 01:50:44.465
<v Speaker 1>over it. And then we're passing

01:50:45.030 --> 01:50:47.349
<v Speaker 1>we're taking the the max pool of that

01:50:47.349 --> 01:50:48.550
<v Speaker 1>and then passing,

01:50:49.510 --> 01:50:52.070
<v Speaker 1>that, 32 filters over it, if I recall

01:50:52.070 --> 01:50:54.309
<v Speaker 1>correctly. So let's see what we're what, you

01:50:54.309 --> 01:50:56.309
<v Speaker 1>know, what happens. Here, you can see that

01:50:56.309 --> 01:50:59.590
<v Speaker 1>the the pixel height here is, like, 75

01:50:59.590 --> 01:51:00.824
<v Speaker 1>or something. Right?

01:51:01.545 --> 01:51:03.945
<v Speaker 1>Then when we condense it, when we pool

01:51:03.945 --> 01:51:04.425
<v Speaker 1>it,

01:51:04.825 --> 01:51:06.985
<v Speaker 1>we're only picking the loudest

01:51:06.985 --> 01:51:08.824
<v Speaker 1>of all the pixels in that filter.

01:51:09.145 --> 01:51:12.105
<v Speaker 1>And, as a result, our image shrinks.

01:51:12.730 --> 01:51:14.970
<v Speaker 1>And here you can see that I've got

01:51:14.970 --> 01:51:17.850
<v Speaker 1>32 filters running across this,

01:51:18.410 --> 01:51:20.650
<v Speaker 1>and it but it's a smaller image.

01:51:20.970 --> 01:51:23.449
<v Speaker 1>And then I'm going to,

01:51:23.930 --> 01:51:25.450
<v Speaker 1>do that exercise again.

01:51:25.895 --> 01:51:27.175
<v Speaker 1>And now you can see that it's getting

01:51:27.255 --> 01:51:28.775
<v Speaker 1>the scale is getting smaller.

01:51:29.815 --> 01:51:31.975
<v Speaker 1>Here's the max pooling result of that layer

01:51:31.975 --> 01:51:34.295
<v Speaker 1>above. Right? And what you notice in this

01:51:34.455 --> 01:51:36.455
<v Speaker 1>in the same same way that the that

01:51:36.455 --> 01:51:37.335
<v Speaker 1>the fork,

01:51:38.215 --> 01:51:40.860
<v Speaker 1>mold changed over time by virtue of what

01:51:40.860 --> 01:51:42.620
<v Speaker 1>you plowed into it, you see sort of

01:51:42.620 --> 01:51:46.460
<v Speaker 1>the same concept here, right, where we're observing

01:51:46.460 --> 01:51:47.180
<v Speaker 1>certain

01:51:47.340 --> 01:51:50.540
<v Speaker 1>commonalities among these things where the the it

01:51:50.540 --> 01:51:52.300
<v Speaker 1>seems as though, for example, if I were

01:51:52.300 --> 01:51:54.140
<v Speaker 1>to summarize, you know, there's a there's a

01:51:54.140 --> 01:51:55.420
<v Speaker 1>certain vertical pattern,

01:51:55.885 --> 01:51:57.565
<v Speaker 1>right, that is associated,

01:51:58.605 --> 01:52:00.605
<v Speaker 1>in these examples. And and and in some

01:52:00.605 --> 01:52:01.245
<v Speaker 1>cases,

01:52:01.405 --> 01:52:03.405
<v Speaker 1>they're they're vertical on the side. In some

01:52:03.405 --> 01:52:05.565
<v Speaker 1>cases, they're vertical in the center.

01:52:06.045 --> 01:52:08.605
<v Speaker 1>And in some cases, they're completely blank. That's

01:52:08.605 --> 01:52:10.590
<v Speaker 1>also helpful to know. Let's let's,

01:52:10.989 --> 01:52:12.670
<v Speaker 1>is this using I think it's using a

01:52:12.670 --> 01:52:14.429
<v Speaker 1>random input. Let's just make sure.

01:52:15.070 --> 01:52:16.989
<v Speaker 1>Yes. Random choice. Alright. Let's run this again.

01:52:16.989 --> 01:52:18.270
<v Speaker 1>Let's see if we can get a a

01:52:18.270 --> 01:52:20.110
<v Speaker 1>normal. Okay. So here's a normal.

01:52:20.429 --> 01:52:22.110
<v Speaker 1>Okay. So what do we notice here at

01:52:22.110 --> 01:52:23.710
<v Speaker 1>the very bottom layer? I hope it's it's

01:52:23.710 --> 01:52:25.735
<v Speaker 1>big enough for folks to see. But but

01:52:25.735 --> 01:52:28.615
<v Speaker 1>what I see here is that rather than

01:52:28.615 --> 01:52:31.015
<v Speaker 1>the vertical line standing out quite so much,

01:52:31.015 --> 01:52:32.455
<v Speaker 1>I'm starting to see,

01:52:33.495 --> 01:52:36.295
<v Speaker 1>more horizontal lines that that seem to sort

01:52:36.295 --> 01:52:37.815
<v Speaker 1>of line up with the,

01:52:38.215 --> 01:52:40.880
<v Speaker 1>with the ribs, right, with the rib cage.

01:52:40.960 --> 01:52:43.760
<v Speaker 1>And and it's certainly not nearly as pronounced,

01:52:43.760 --> 01:52:44.880
<v Speaker 1>the the vertical

01:52:46.960 --> 01:52:49.360
<v Speaker 1>lines in here. So so this is what

01:52:49.360 --> 01:52:51.119
<v Speaker 1>the model is seeing, and this is what

01:52:51.119 --> 01:52:53.440
<v Speaker 1>it's using to make a determination based on

01:52:53.440 --> 01:52:55.445
<v Speaker 1>all of the the outputs that it sees

01:52:55.445 --> 01:52:56.084
<v Speaker 1>here,

01:52:56.324 --> 01:52:56.885
<v Speaker 1>what

01:52:57.364 --> 01:52:59.684
<v Speaker 1>class of classification it it should be in.

01:52:59.684 --> 01:53:00.164
<v Speaker 1>So

01:53:02.565 --> 01:53:05.204
<v Speaker 1>so, yeah, that's the that's the ballgame.

01:53:05.605 --> 01:53:08.405
<v Speaker 1>It's this is actually using the model that

01:53:08.405 --> 01:53:10.530
<v Speaker 1>we just trained. Let me find it for

01:53:10.530 --> 01:53:12.130
<v Speaker 1>you. It's in here somewhere.

01:53:13.410 --> 01:53:15.250
<v Speaker 1>We

01:53:17.810 --> 01:53:20.130
<v Speaker 1>are actually plugging this into

01:53:20.130 --> 01:53:23.489
<v Speaker 1>the model if I could just find the

01:53:23.570 --> 01:53:26.685
<v Speaker 1>line that is doing it. Oh,

01:53:30.765 --> 01:53:32.045
<v Speaker 1>it's here somewhere.

01:53:34.125 --> 01:53:36.045
<v Speaker 1>It's so zoomed in. Oh, here we go.

01:53:36.045 --> 01:53:38.610
<v Speaker 1>Successive feature visualization model. So we we got

01:53:38.610 --> 01:53:40.690
<v Speaker 1>the model, and we're asking it to predict

01:53:40.690 --> 01:53:41.409
<v Speaker 1>x.

01:53:41.570 --> 01:53:43.809
<v Speaker 1>Right? So it's it's taking an image example,

01:53:43.889 --> 01:53:46.769
<v Speaker 1>manipulating it, normalizing it, doing everything we did,

01:53:46.850 --> 01:53:48.290
<v Speaker 1>and then it's plowing it through the model

01:53:48.290 --> 01:53:49.809
<v Speaker 1>itself. And this is what,

01:53:50.370 --> 01:53:52.929
<v Speaker 1>this is is, what the model is seeing.

01:53:52.929 --> 01:53:54.765
<v Speaker 1>So you're really, you know, quite literally seeing

01:53:54.765 --> 01:53:56.765
<v Speaker 1>what the model is sealing seeing. I know

01:53:56.765 --> 01:53:58.125
<v Speaker 1>we've we've we've kind of been on the

01:53:58.125 --> 01:53:59.085
<v Speaker 1>air for a long time.

01:53:59.645 --> 01:54:00.844
<v Speaker 1>I could show you how to turn this

01:54:00.844 --> 01:54:02.765
<v Speaker 1>into a pipeline. This has been sort of

01:54:02.765 --> 01:54:04.284
<v Speaker 1>a data science primer,

01:54:04.445 --> 01:54:06.844
<v Speaker 1>less so a a Kubeflow primer.

01:54:07.085 --> 01:54:07.565
<v Speaker 1>Up to you.

01:54:08.880 --> 01:54:10.480
<v Speaker 0>If you have the time, yeah, we can

01:54:10.480 --> 01:54:12.000
<v Speaker 0>do that next step. Let let's see how

01:54:12.000 --> 01:54:13.039
<v Speaker 0>we move this over.

01:54:13.520 --> 01:54:14.559
<v Speaker 1>Sure. Yeah.

01:54:15.120 --> 01:54:16.559
<v Speaker 1>In the words of

01:54:16.880 --> 01:54:17.920
<v Speaker 1>the late

01:54:19.760 --> 01:54:21.935
<v Speaker 1>oh, goodness. Come on. Not not now. I'm

01:54:21.935 --> 01:54:23.295
<v Speaker 1>trying to remember his name.

01:54:23.775 --> 01:54:26.095
<v Speaker 1>Mitch Hedberg. Anything's in walking distance if you've

01:54:26.095 --> 01:54:26.895
<v Speaker 1>got the time.

01:54:27.535 --> 01:54:28.815
<v Speaker 1>Okay. So

01:54:29.295 --> 01:54:31.614
<v Speaker 1>this is Kail. Kail is an open source

01:54:32.655 --> 01:54:33.215
<v Speaker 1>tool

01:54:34.060 --> 01:54:37.580
<v Speaker 1>that basically instead normally, the workflow, you know,

01:54:37.580 --> 01:54:38.620
<v Speaker 1>what you would have to do is you'd

01:54:38.620 --> 01:54:39.980
<v Speaker 1>have to take all this code. You'd have

01:54:39.980 --> 01:54:41.580
<v Speaker 1>to take it basically, take it out of

01:54:41.580 --> 01:54:44.300
<v Speaker 1>the notebook, move your imports into every cell,

01:54:44.300 --> 01:54:46.220
<v Speaker 1>define make each cell its own function,

01:54:46.825 --> 01:54:48.985
<v Speaker 1>you know, then use pipeline

01:54:49.225 --> 01:54:52.345
<v Speaker 1>Kubeflow pipelines, domain specific language, DSL code to

01:54:52.345 --> 01:54:54.505
<v Speaker 1>write the pipeline. Kale says, you don't wanna

01:54:54.505 --> 01:54:55.785
<v Speaker 1>do any of that. We'll give you a

01:54:55.785 --> 01:54:57.785
<v Speaker 1>button. You click the button. This is what's

01:54:57.785 --> 01:54:59.625
<v Speaker 1>happening here. So you'll notice I have this,

01:54:59.625 --> 01:55:02.730
<v Speaker 1>like, handy dandy little pencil icon That's an

01:55:02.730 --> 01:55:05.289
<v Speaker 1>overlay. So I can call this. I can

01:55:05.289 --> 01:55:07.050
<v Speaker 1>define what's going on. So this is an

01:55:07.050 --> 01:55:08.010
<v Speaker 1>import step.

01:55:08.170 --> 01:55:09.369
<v Speaker 1>Right? Okay.

01:55:10.010 --> 01:55:12.329
<v Speaker 1>Now in a pipeline,

01:55:12.889 --> 01:55:14.889
<v Speaker 1>I do not need to do any kind

01:55:14.889 --> 01:55:17.485
<v Speaker 1>of, printing of output. Right? So this will

01:55:17.485 --> 01:55:20.125
<v Speaker 1>skip this. This is my hyperparameter

01:55:20.125 --> 01:55:22.285
<v Speaker 1>cell, so I'm gonna call this my pipeline

01:55:22.285 --> 01:55:25.325
<v Speaker 1>parameters, aka I want it to, like, goof

01:55:25.325 --> 01:55:27.165
<v Speaker 1>around with this. Right? Like, I want it

01:55:27.165 --> 01:55:27.645
<v Speaker 1>to

01:55:29.150 --> 01:55:30.510
<v Speaker 1>I want it to

01:55:31.070 --> 01:55:33.709
<v Speaker 1>adjust this, to know to adjust this automatically.

01:55:33.710 --> 01:55:35.790
<v Speaker 1>We'll see how how that goes. Again, batch

01:55:35.790 --> 01:55:37.389
<v Speaker 1>size, how many forks do I wanna flow

01:55:37.389 --> 01:55:39.550
<v Speaker 1>through the mold before I make changes on

01:55:39.550 --> 01:55:40.110
<v Speaker 1>my

01:55:41.389 --> 01:55:43.389
<v Speaker 1>model? Alright. And we're gonna put this down

01:55:43.389 --> 01:55:44.989
<v Speaker 1>to one epoch just because

01:55:45.755 --> 01:55:46.715
<v Speaker 1>time purposes,

01:55:47.035 --> 01:55:49.435
<v Speaker 1>train faster. Alright. So now I'm come to

01:55:49.435 --> 01:55:51.915
<v Speaker 1>my first pipeline step. Not a super exciting

01:55:51.915 --> 01:55:54.395
<v Speaker 1>step, but we'll call it something like preprocess

01:55:54.555 --> 01:55:55.355
<v Speaker 1>data.

01:55:55.915 --> 01:55:58.150
<v Speaker 1>And it doesn't depend on anything. You can

01:55:58.150 --> 01:56:01.030
<v Speaker 1>specify, you know, resource dependencies also, but it

01:56:01.030 --> 01:56:03.030
<v Speaker 1>doesn't depend on any other pipeline steps because

01:56:03.030 --> 01:56:05.110
<v Speaker 1>guess what? It's the first pipeline step.

01:56:05.430 --> 01:56:09.190
<v Speaker 1>Next up, Matplotlib inline. This is definitely a

01:56:09.190 --> 01:56:09.510
<v Speaker 1>skip.

01:56:10.165 --> 01:56:13.205
<v Speaker 1>The pipeline Kubernetes doesn't care about seeing a

01:56:13.205 --> 01:56:15.124
<v Speaker 1>picture, so we're gonna remove these.

01:56:16.645 --> 01:56:19.445
<v Speaker 1>Yep. Okay. Then we've got

01:56:20.085 --> 01:56:22.324
<v Speaker 1>why don't we call this the compile model

01:56:22.324 --> 01:56:22.645
<v Speaker 1>step?

01:56:23.450 --> 01:56:25.370
<v Speaker 1>After all, we are compiling

01:56:25.370 --> 01:56:26.250
<v Speaker 1>the model,

01:56:26.730 --> 01:56:29.930
<v Speaker 1>and it depends on preprocessing the data. No

01:56:29.930 --> 01:56:31.050
<v Speaker 1>great surprise there.

01:56:31.610 --> 01:56:32.410
<v Speaker 1>Okay.

01:56:32.970 --> 01:56:35.130
<v Speaker 1>Now we move right along

01:56:35.770 --> 01:56:36.650
<v Speaker 1>to

01:56:36.650 --> 01:56:38.514
<v Speaker 1>our training step.

01:56:38.755 --> 01:56:41.155
<v Speaker 1>So we'll call this train,

01:56:41.395 --> 01:56:42.675
<v Speaker 1>and it depends on

01:56:43.075 --> 01:56:43.875
<v Speaker 1>compile.

01:56:44.915 --> 01:56:45.715
<v Speaker 1>Woo hoo.

01:56:46.355 --> 01:56:47.395
<v Speaker 1>Alright.

01:56:48.035 --> 01:56:48.675
<v Speaker 1>And

01:56:49.235 --> 01:56:50.515
<v Speaker 1>then below,

01:56:50.515 --> 01:56:52.550
<v Speaker 1>I just wanna make sure I remove all

01:56:52.550 --> 01:56:54.469
<v Speaker 1>of these and just skip them

01:56:54.950 --> 01:56:57.590
<v Speaker 1>so that we don't end up with,

01:56:59.110 --> 01:56:59.829
<v Speaker 1>complaints

01:57:00.150 --> 01:57:00.869
<v Speaker 1>from

01:57:01.430 --> 01:57:02.150
<v Speaker 1>the

01:57:03.510 --> 01:57:05.750
<v Speaker 1>scheduler. Alright. Now the last thing I wanna

01:57:05.750 --> 01:57:07.945
<v Speaker 1>do because I do wanna use hyper parameter

01:57:07.945 --> 01:57:10.744
<v Speaker 1>optimization, automatic hyper parameter optimization,

01:57:10.905 --> 01:57:12.585
<v Speaker 1>is I have to tell the

01:57:12.905 --> 01:57:13.465
<v Speaker 1>you know,

01:57:13.785 --> 01:57:16.105
<v Speaker 1>it it the the the, the hyper parameter

01:57:16.105 --> 01:57:16.985
<v Speaker 1>optimization

01:57:18.105 --> 01:57:20.709
<v Speaker 1>software that comes with Kubeflow needs

01:57:20.790 --> 01:57:24.469
<v Speaker 1>something to needs something to shoot for. So

01:57:24.469 --> 01:57:26.869
<v Speaker 1>what do we wanna do? Rule number one,

01:57:26.869 --> 01:57:29.269
<v Speaker 1>we wanna minimize our loss.

01:57:29.510 --> 01:57:31.750
<v Speaker 1>Cut down on the loss. If we've got

01:57:31.750 --> 01:57:33.670
<v Speaker 1>loss, it means we're doing something wrong. So

01:57:33.670 --> 01:57:36.455
<v Speaker 1>we wanna find the the version of this

01:57:36.455 --> 01:57:39.255
<v Speaker 1>story, the version of the model that has

01:57:39.255 --> 01:57:40.295
<v Speaker 1>the most

01:57:41.655 --> 01:57:43.014
<v Speaker 1>that has the least loss.

01:57:43.255 --> 01:57:45.095
<v Speaker 1>So I'm gonna give this a name. I'm

01:57:45.095 --> 01:57:46.054
<v Speaker 1>gonna call it

01:57:46.535 --> 01:57:49.780
<v Speaker 1>X-ray. So these are all Kubeflow CRDs, actually,

01:57:49.780 --> 01:57:52.020
<v Speaker 1>for your ops folks on the on the

01:57:52.020 --> 01:57:52.500
<v Speaker 1>line.

01:57:53.380 --> 01:57:56.340
<v Speaker 1>So an experiment is a CRD. A pipeline

01:57:56.340 --> 01:57:57.940
<v Speaker 1>is a is a CRD.

01:57:58.100 --> 01:57:59.940
<v Speaker 1>Give it a an ex a description, and

01:57:59.940 --> 01:58:01.985
<v Speaker 1>they have relationships with one another on one

01:58:01.985 --> 01:58:04.465
<v Speaker 1>another like an experiment, may have many pipelines,

01:58:04.465 --> 01:58:05.344
<v Speaker 1>that kind of thing.

01:58:05.985 --> 01:58:08.145
<v Speaker 1>Or a pipeline may have many experiments.

01:58:08.385 --> 01:58:10.465
<v Speaker 1>I have to I I don't know. It's

01:58:10.465 --> 01:58:12.465
<v Speaker 1>all that's the problem with visual tools. You

01:58:12.465 --> 01:58:13.985
<v Speaker 1>never know what acts things are actually called.

01:58:14.750 --> 01:58:17.390
<v Speaker 1>Alright. So now what I wanna enable is

01:58:17.390 --> 01:58:19.469
<v Speaker 1>hyperparameter tuning with Katib.

01:58:19.790 --> 01:58:20.429
<v Speaker 1>So

01:58:21.150 --> 01:58:22.909
<v Speaker 1>what I will do is

01:58:24.910 --> 01:58:26.269
<v Speaker 1>define the

01:58:26.510 --> 01:58:29.415
<v Speaker 1>search space. So it noticed that learning rate

01:58:29.415 --> 01:58:32.374
<v Speaker 1>was something that I had, defined.

01:58:32.534 --> 01:58:34.215
<v Speaker 1>Right? So that was one of the hyperparameters.

01:58:34.215 --> 01:58:35.574
<v Speaker 1>Let me close this and take you right

01:58:35.574 --> 01:58:37.415
<v Speaker 1>back up. Where did I define this? Right

01:58:37.415 --> 01:58:40.054
<v Speaker 1>up here in the pipeline parameters. Right here.

01:58:40.054 --> 01:58:42.139
<v Speaker 1>Right? So it's gonna automatically pick that up

01:58:42.139 --> 01:58:43.099
<v Speaker 1>from that cell,

01:58:43.500 --> 01:58:45.900
<v Speaker 1>and it's gonna be arranged. Let's say, on

01:58:45.900 --> 01:58:48.619
<v Speaker 1>the one hand, point zero zero

01:58:48.860 --> 01:58:49.499
<v Speaker 1>one,

01:58:49.820 --> 01:58:52.139
<v Speaker 1>and max will say, I don't know, point

01:58:52.139 --> 01:58:52.380
<v Speaker 1>one.

01:58:52.975 --> 01:58:55.614
<v Speaker 1>And let's, you know, let's go crazy. Let's

01:58:55.614 --> 01:58:58.574
<v Speaker 1>say that we go by in steps of

01:58:58.574 --> 01:58:59.855
<v Speaker 1>point o one.

01:59:00.015 --> 01:59:02.094
<v Speaker 1>Alright? So the learning rate says

01:59:02.574 --> 01:59:05.135
<v Speaker 1>okay. Okay. Okay. Once you figure out how

01:59:05.135 --> 01:59:08.390
<v Speaker 1>to change the mold, don't go crazy with

01:59:08.390 --> 01:59:09.430
<v Speaker 1>changing the mold.

01:59:09.990 --> 01:59:11.670
<v Speaker 1>Figure out how much you think you should

01:59:11.670 --> 01:59:13.430
<v Speaker 1>change the mold and then divide that by

01:59:13.430 --> 01:59:15.670
<v Speaker 1>a hundred, right, or or a thousand in

01:59:15.670 --> 01:59:17.910
<v Speaker 1>this case, and and go incrementally from there

01:59:17.910 --> 01:59:20.535
<v Speaker 1>because it is very easy to overshoot the

01:59:20.535 --> 01:59:22.055
<v Speaker 1>runway, so to speak, on that and and

01:59:22.055 --> 01:59:22.614
<v Speaker 1>end up in

01:59:24.295 --> 01:59:25.815
<v Speaker 1>on the wrong side of a of a

01:59:25.815 --> 01:59:26.855
<v Speaker 1>gradient descent.

01:59:27.175 --> 01:59:28.135
<v Speaker 1>Epochs,

01:59:28.375 --> 01:59:31.335
<v Speaker 1>we can manipulate this. We're not going to

01:59:31.574 --> 01:59:33.415
<v Speaker 1>because we don't wanna change the amount of

01:59:33.415 --> 01:59:35.094
<v Speaker 1>time it takes to run this thing.

01:59:35.940 --> 01:59:38.420
<v Speaker 1>We're gonna have a batch size min of

01:59:38.420 --> 01:59:39.940
<v Speaker 1>eight. Let's call it a max of one

01:59:39.940 --> 01:59:42.420
<v Speaker 1>twenty eight, and let's go crazy and

01:59:42.900 --> 01:59:45.700
<v Speaker 1>say, I don't know, 32 is the step.

01:59:45.700 --> 01:59:48.020
<v Speaker 1>So let's go that way. We can define

01:59:48.020 --> 01:59:50.585
<v Speaker 1>the algorithm for how it should pick different,

01:59:50.745 --> 01:59:51.945
<v Speaker 1>hyperparameters,

01:59:52.745 --> 01:59:54.185
<v Speaker 1>and it's smart enough to sort of look

01:59:54.185 --> 01:59:55.545
<v Speaker 1>back and see what's what seems to be

01:59:55.545 --> 01:59:57.465
<v Speaker 1>working. And then what's our objective? We wanna

01:59:57.465 --> 01:59:58.344
<v Speaker 1>minimize

01:59:58.344 --> 01:59:58.824
<v Speaker 1>the,

01:59:59.465 --> 02:00:01.624
<v Speaker 1>the validation loss. Alright?

02:00:01.945 --> 02:00:04.905
<v Speaker 1>So I'm gonna dial this down to 6.

02:00:05.010 --> 02:00:07.010
<v Speaker 1>We'll have three parallel trials.

02:00:07.170 --> 02:00:09.489
<v Speaker 1>Again, Kubernetes.

02:00:09.489 --> 02:00:11.250
<v Speaker 1>This is where we get all of the

02:00:11.250 --> 02:00:13.730
<v Speaker 1>the Kubernetes goodness coming to life. But, you

02:00:13.730 --> 02:00:16.210
<v Speaker 1>know, thank goodness someone who's not familiar with

02:00:16.210 --> 02:00:17.730
<v Speaker 1>that and doesn't wanna learn it doesn't have

02:00:17.730 --> 02:00:18.530
<v Speaker 1>to to do their job.

02:00:19.285 --> 02:00:21.925
<v Speaker 1>And now it's what, Kata or excuse me.

02:00:21.925 --> 02:00:23.525
<v Speaker 1>Now what Kaila is doing is validating the

02:00:23.525 --> 02:00:24.244
<v Speaker 1>notebook.

02:00:26.565 --> 02:00:29.445
<v Speaker 1>The back end I'm using for for snapshotting

02:00:29.445 --> 02:00:31.205
<v Speaker 1>with Kaila is, is Rawk.

02:00:33.020 --> 02:00:33.660
<v Speaker 1>And

02:00:35.180 --> 02:00:37.660
<v Speaker 1>once this, snapshot completes,

02:00:37.740 --> 02:00:40.300
<v Speaker 1>it's a fairly sizable dataset, so it may

02:00:40.300 --> 02:00:41.180
<v Speaker 1>take a

02:00:41.980 --> 02:00:44.700
<v Speaker 1>second. There's quite a bit of, blocks to

02:00:44.700 --> 02:00:46.700
<v Speaker 1>look at. What it's gonna do is it's

02:00:46.700 --> 02:00:47.180
<v Speaker 1>going to

02:00:48.205 --> 02:00:51.885
<v Speaker 1>compile the notebook into a Kubeflow DSL

02:00:52.285 --> 02:00:55.485
<v Speaker 1>code for me so that the Kubeflow pipelines

02:00:55.485 --> 02:00:57.725
<v Speaker 1>knows what to do with it. Then it

02:00:57.725 --> 02:00:59.005
<v Speaker 1>is going to

02:01:00.445 --> 02:01:03.159
<v Speaker 1>upload the pipeline for me, hopefully. Then it's

02:01:03.159 --> 02:01:05.880
<v Speaker 1>going to create an experiment around that, and

02:01:05.880 --> 02:01:07.880
<v Speaker 1>then it is going to create a content

02:01:07.880 --> 02:01:08.439
<v Speaker 1>experiment

02:01:08.760 --> 02:01:11.639
<v Speaker 1>whereby it breaks out each of the different

02:01:11.800 --> 02:01:13.239
<v Speaker 1>you'll see it. For each run, it's gonna

02:01:13.239 --> 02:01:15.400
<v Speaker 1>pick, okay, try batch size this, learning rate

02:01:15.400 --> 02:01:15.559
<v Speaker 1>that.

02:01:17.285 --> 02:01:19.285
<v Speaker 1>It'll pick the the,

02:01:19.525 --> 02:01:20.325
<v Speaker 1>it'll

02:01:20.325 --> 02:01:23.285
<v Speaker 1>determine which are the the the combinations

02:01:23.285 --> 02:01:25.445
<v Speaker 1>it's gonna run with, first. So here we

02:01:25.445 --> 02:01:26.645
<v Speaker 1>go. It compiled.

02:01:26.725 --> 02:01:27.845
<v Speaker 0>Oh. Uh-oh.

02:01:31.590 --> 02:01:33.830
<v Speaker 1>API. Oh, I know. I Why

02:01:34.470 --> 02:01:35.510
<v Speaker 1>don't we give this

02:01:36.070 --> 02:01:37.030
<v Speaker 1>different

02:01:37.670 --> 02:01:38.310
<v Speaker 1>yeah.

02:01:39.110 --> 02:01:39.510
<v Speaker 1>The

02:01:40.390 --> 02:01:42.150
<v Speaker 1>let's make it a new experiment.

02:01:42.310 --> 02:01:45.485
<v Speaker 1>X-ray two, pipeline description, X-ray two. Let me

02:01:45.485 --> 02:01:48.044
<v Speaker 1>close this. Let me compile and run.

02:01:48.605 --> 02:01:49.724
<v Speaker 1>Naming things.

02:01:50.844 --> 02:01:53.004
<v Speaker 1>What a what a disaster. Alright.

02:01:53.244 --> 02:01:56.124
<v Speaker 1>And then we'll be able to observe this

02:01:56.284 --> 02:01:58.364
<v Speaker 1>running. Does it matter that your new experiment

02:01:58.364 --> 02:01:59.165
<v Speaker 0>doesn't have a name?

02:02:01.040 --> 02:02:01.920
<v Speaker 1>Probably.

02:02:01.920 --> 02:02:03.120
<v Speaker 1>Yeah. I

02:02:04.640 --> 02:02:06.640
<v Speaker 1>I thought I saw it had a name.

02:02:06.640 --> 02:02:08.400
<v Speaker 1>Alright. Let's let's third does.

02:02:14.905 --> 02:02:16.345
<v Speaker 1>Does it matter that it doesn't have a

02:02:16.345 --> 02:02:18.585
<v Speaker 1>name? Yes. It matters, David. Would have been

02:02:18.585 --> 02:02:20.665
<v Speaker 1>very helpful if you'd include me into this.

02:02:21.225 --> 02:02:23.305
<v Speaker 0>I I'm just watching. I'm just here to

02:02:23.545 --> 02:02:25.705
<v Speaker 1>Oh, yeah. This is great. Oh, look at

02:02:25.705 --> 02:02:28.505
<v Speaker 1>this. This this has never happened before. I'm

02:02:28.505 --> 02:02:29.545
<v Speaker 1>so glad it's happening now.

02:02:30.270 --> 02:02:32.110
<v Speaker 1>It's a little little jitter here. I don't

02:02:32.110 --> 02:02:33.949
<v Speaker 1>think it likes being blown up to this

02:02:33.949 --> 02:02:36.349
<v Speaker 1>extent. I'm not surprised. I mean, it looks

02:02:36.349 --> 02:02:38.269
<v Speaker 0>great on our side, just FYI.

02:02:39.550 --> 02:02:40.189
<v Speaker 1>Good.

02:02:40.510 --> 02:02:41.229
<v Speaker 1>Good.

02:02:42.190 --> 02:02:44.510
<v Speaker 0>Okay. So what's this gathering suggestions stage?

02:02:45.215 --> 02:02:46.894
<v Speaker 1>Uh-huh. So this is what I meant before

02:02:46.894 --> 02:02:48.734
<v Speaker 1>when it's, like, making,

02:02:49.375 --> 02:02:51.054
<v Speaker 1>it has to make a decision. Right? We're

02:02:51.054 --> 02:02:52.574
<v Speaker 1>doing three parallel trials.

02:02:52.735 --> 02:02:55.375
<v Speaker 1>No trials have have run yet. Right? So

02:02:55.375 --> 02:02:56.254
<v Speaker 1>what

02:02:56.574 --> 02:02:57.934
<v Speaker 1>should I use as my

02:02:58.579 --> 02:03:01.219
<v Speaker 1>wacko combination of hyperparameters to kick this bad

02:03:01.219 --> 02:03:03.300
<v Speaker 1>boy off? Right? I have to have to

02:03:03.300 --> 02:03:04.499
<v Speaker 1>make a decision on that.

02:03:05.460 --> 02:03:08.260
<v Speaker 1>Okay. So this I'm gonna zoom out just

02:03:08.260 --> 02:03:10.340
<v Speaker 1>a scooch here because it's a little aggressive.

02:03:10.340 --> 02:03:12.435
<v Speaker 1>Here we go. Alright. So what is it

02:03:12.435 --> 02:03:13.395
<v Speaker 1>doing? So,

02:03:13.955 --> 02:03:16.755
<v Speaker 1>these for these three trials, it is gonna

02:03:16.755 --> 02:03:18.995
<v Speaker 1>vary the batch size from eight

02:03:19.155 --> 02:03:22.195
<v Speaker 1>to, whatever this is. Let's find out.

02:03:22.515 --> 02:03:25.490
<v Speaker 1>From eight to 40 to 72. Alright? And

02:03:25.490 --> 02:03:27.570
<v Speaker 1>each one of these will be,

02:03:28.050 --> 02:03:30.770
<v Speaker 1>its own pipeline. So I can go ahead

02:03:30.770 --> 02:03:33.410
<v Speaker 1>as a data scientist or data engineer.

02:03:33.570 --> 02:03:34.530
<v Speaker 1>I can,

02:03:35.570 --> 02:03:36.210
<v Speaker 1>click on this.

02:03:39.465 --> 02:03:41.945
<v Speaker 1>And here you can see my pipeline is

02:03:41.945 --> 02:03:44.105
<v Speaker 1>running. So the first thing it did was

02:03:44.105 --> 02:03:46.425
<v Speaker 1>the create volume step. I can click on

02:03:46.425 --> 02:03:48.905
<v Speaker 1>any of these steps and see the logs

02:03:49.385 --> 02:03:51.385
<v Speaker 1>for the the pod. I can see the

02:03:51.385 --> 02:03:52.825
<v Speaker 1>pod spec, the pod YAML.

02:03:53.869 --> 02:03:56.909
<v Speaker 1>You know, one area that I think folks

02:03:57.710 --> 02:03:59.789
<v Speaker 1>who are looking for ways to contribute,

02:04:00.909 --> 02:04:03.469
<v Speaker 1>you know, please jump in is to sort

02:04:03.469 --> 02:04:04.349
<v Speaker 1>of simplify

02:04:04.510 --> 02:04:05.949
<v Speaker 1>a lot of the stuff that gets thrown

02:04:05.949 --> 02:04:06.270
<v Speaker 1>in here.

02:04:07.264 --> 02:04:10.224
<v Speaker 1>And you'll also note that, you know, the

02:04:10.224 --> 02:04:10.945
<v Speaker 1>the

02:04:12.385 --> 02:04:14.385
<v Speaker 1>the way that it's the way that it's

02:04:14.385 --> 02:04:17.744
<v Speaker 1>containerized is just powering this all through to,

02:04:17.744 --> 02:04:18.304
<v Speaker 1>you

02:04:19.505 --> 02:04:21.420
<v Speaker 1>know, as as a as a plain as

02:04:21.420 --> 02:04:25.180
<v Speaker 1>a text file to the, to the, underlying

02:04:25.180 --> 02:04:27.020
<v Speaker 1>image. It's like maybe

02:04:27.180 --> 02:04:29.660
<v Speaker 1>not, like, long term. You know, it might

02:04:29.660 --> 02:04:31.420
<v Speaker 1>be something that that we wanna, as a

02:04:31.420 --> 02:04:33.045
<v Speaker 1>community, sort of work on.

02:04:33.925 --> 02:04:35.605
<v Speaker 1>But we're waiting for the pods to come

02:04:35.605 --> 02:04:38.085
<v Speaker 1>up. I can actually show you what this

02:04:38.085 --> 02:04:39.925
<v Speaker 1>looks like from the terminal. So let me

02:04:39.925 --> 02:04:41.284
<v Speaker 1>do a clear on this.

02:04:41.685 --> 02:04:43.205
<v Speaker 1>I know it's a little bit smaller. Bear

02:04:43.205 --> 02:04:44.965
<v Speaker 1>with me. Let me do a watch. Kube

02:04:44.965 --> 02:04:47.910
<v Speaker 1>CTO get PO is gonna be launching in

02:04:47.910 --> 02:04:48.869
<v Speaker 1>my namespace.

02:04:49.030 --> 02:04:50.790
<v Speaker 1>So here you can see these are the

02:04:50.790 --> 02:04:52.070
<v Speaker 1>the pipelines

02:04:53.430 --> 02:04:54.230
<v Speaker 1>that have

02:04:55.110 --> 02:04:56.869
<v Speaker 1>that are waiting to get scheduled.

02:04:57.030 --> 02:05:00.150
<v Speaker 1>Here are the ones that are running X-ray

02:05:00.150 --> 02:05:00.390
<v Speaker 1>two.

02:05:00.955 --> 02:05:03.355
<v Speaker 1>This, set of hyperparameters will get its own

02:05:03.355 --> 02:05:04.715
<v Speaker 1>sort of identifier.

02:05:05.594 --> 02:05:08.235
<v Speaker 1>And then here are the ones that

02:05:09.195 --> 02:05:12.554
<v Speaker 1>that are, waiting to run. So each of

02:05:12.554 --> 02:05:14.795
<v Speaker 1>these, is a pod. You know, you'll see

02:05:14.795 --> 02:05:15.594
<v Speaker 1>similarities

02:05:16.170 --> 02:05:17.929
<v Speaker 1>between the the

02:05:18.330 --> 02:05:19.769
<v Speaker 1>unique identifiers.

02:05:19.770 --> 02:05:21.769
<v Speaker 1>That's because a lot of the

02:05:22.650 --> 02:05:24.090
<v Speaker 1>you know, for this one, it might be

02:05:24.090 --> 02:05:26.570
<v Speaker 1>that that only one hyper you know, only

02:05:26.570 --> 02:05:28.810
<v Speaker 1>one parameter has changed. So for this first

02:05:28.810 --> 02:05:30.410
<v Speaker 1>batch of three, they're gonna have the same

02:05:30.410 --> 02:05:33.304
<v Speaker 1>five character identifier in the middle here.

02:05:34.025 --> 02:05:36.505
<v Speaker 1>Where's my pipeline, actually? Here we go.

02:05:37.225 --> 02:05:39.304
<v Speaker 1>You wanna you wanna boot up here, bud?

02:05:39.304 --> 02:05:40.665
<v Speaker 1>Do I have something that's got a little

02:05:40.665 --> 02:05:41.465
<v Speaker 1>more action?

02:05:42.105 --> 02:05:43.224
<v Speaker 1>Experiments,

02:05:43.225 --> 02:05:44.824
<v Speaker 1>HP tuning,

02:05:44.905 --> 02:05:46.025
<v Speaker 1>running three.

02:05:47.820 --> 02:05:48.860
<v Speaker 1>Trials

02:05:49.420 --> 02:05:50.300
<v Speaker 1>running.

02:05:50.699 --> 02:05:51.579
<v Speaker 1>Are you, though?

02:05:52.060 --> 02:05:52.539
<v Speaker 1>Am.

02:05:54.619 --> 02:05:57.820
<v Speaker 0>Kubernetes lying to you. Maybe yeah. Welcome to

02:05:57.820 --> 02:05:58.459
<v Speaker 1>my life.

02:05:59.099 --> 02:06:01.099
<v Speaker 1>Let's let's let's go back and just, like,

02:06:01.099 --> 02:06:02.860
<v Speaker 1>let's look at one that actually ran before,

02:06:02.860 --> 02:06:05.144
<v Speaker 1>which I deleted so that I looked cool.

02:06:05.304 --> 02:06:06.584
<v Speaker 1>That was a mistake.

02:06:06.985 --> 02:06:08.744
<v Speaker 1>Alright. Here we go. Here's here's one that

02:06:08.744 --> 02:06:10.425
<v Speaker 1>I didn't delete from that UI. Okay. So

02:06:10.425 --> 02:06:12.584
<v Speaker 1>here's my DAG. I'm gonna simplify it.

02:06:13.465 --> 02:06:15.320
<v Speaker 1>So, yeah, here's all my steps. So I

02:06:15.320 --> 02:06:17.160
<v Speaker 1>can click into them. I can see the

02:06:17.160 --> 02:06:19.640
<v Speaker 1>logs. I can see, you know, all the

02:06:19.640 --> 02:06:23.400
<v Speaker 1>other stuff. And here is my, training exercise.

02:06:24.120 --> 02:06:27.720
<v Speaker 1>You can see the same, loss and and

02:06:28.155 --> 02:06:31.195
<v Speaker 1>and accuracy metrics that we had before. So

02:06:31.355 --> 02:06:34.474
<v Speaker 1>suffice it to say, the the operational

02:06:34.474 --> 02:06:36.074
<v Speaker 1>benefit

02:06:36.074 --> 02:06:38.875
<v Speaker 1>of using a tool like Kubeflow, and Kubeflow

02:06:38.875 --> 02:06:42.235
<v Speaker 1>is the the leading open source Kubernetes native

02:06:42.880 --> 02:06:45.680
<v Speaker 1>platform for this type of work is that

02:06:45.680 --> 02:06:49.360
<v Speaker 1>now, as a data scientist using

02:06:49.360 --> 02:06:50.080
<v Speaker 1>Kail,

02:06:51.040 --> 02:06:54.000
<v Speaker 1>rather than delivering a Jupyter Notebook, which is

02:06:54.000 --> 02:06:55.760
<v Speaker 1>sort of like like a jail for my

02:06:55.760 --> 02:06:57.440
<v Speaker 1>code. Right? It needs to come out of

02:06:57.440 --> 02:06:58.985
<v Speaker 1>there to be to be useful.

02:06:59.625 --> 02:07:01.465
<v Speaker 1>Instead, I can deliver

02:07:01.704 --> 02:07:04.824
<v Speaker 1>a a scalable and repeatable pipeline that can

02:07:04.824 --> 02:07:07.784
<v Speaker 1>then be iterated upon, chained onto, branched off

02:07:07.784 --> 02:07:08.344
<v Speaker 1>of

02:07:08.824 --> 02:07:11.385
<v Speaker 1>to to advance the project. And in fact,

02:07:11.385 --> 02:07:13.145
<v Speaker 1>we could have a a serving component

02:07:13.659 --> 02:07:15.419
<v Speaker 1>at the end of it as well.

02:07:16.139 --> 02:07:17.579
<v Speaker 1>And I you know, in that

02:07:18.460 --> 02:07:21.099
<v Speaker 1>here's a an example is a different different

02:07:21.099 --> 02:07:22.619
<v Speaker 1>model. But here,

02:07:22.860 --> 02:07:25.419
<v Speaker 1>I have a model that's that's being served

02:07:26.059 --> 02:07:28.059
<v Speaker 1>just off the the end of a a

02:07:28.059 --> 02:07:28.539
<v Speaker 1>pipeline.

02:07:29.155 --> 02:07:31.315
<v Speaker 1>And, I can see the logs for it.

02:07:31.315 --> 02:07:33.395
<v Speaker 1>I can see the the predictions,

02:07:34.035 --> 02:07:35.395
<v Speaker 1>that are coming out as well as the

02:07:35.395 --> 02:07:36.915
<v Speaker 1>input data that's coming in.

02:07:38.355 --> 02:07:40.995
<v Speaker 1>And I have metrics. This is all new

02:07:40.995 --> 02:07:41.795
<v Speaker 1>in one dot three.

02:07:42.820 --> 02:07:44.020
<v Speaker 1>My colleague,

02:07:44.180 --> 02:07:46.180
<v Speaker 1>Kimonis, and and some of the other

02:07:46.820 --> 02:07:48.820
<v Speaker 1>folks in in the working group

02:07:50.100 --> 02:07:52.660
<v Speaker 1>contributed this. So, yeah, this is

02:07:52.980 --> 02:07:55.620
<v Speaker 1>this is what greets the the eager data

02:07:55.620 --> 02:07:56.500
<v Speaker 1>scientist

02:07:56.895 --> 02:07:58.415
<v Speaker 1>looking for adventure.

02:07:59.695 --> 02:08:00.495
<v Speaker 0>Awesome.

02:08:00.495 --> 02:08:01.614
<v Speaker 0>Thank you very much.

02:08:02.735 --> 02:08:05.455
<v Speaker 0>Will I pop us back over to video

02:08:05.455 --> 02:08:06.735
<v Speaker 0>mode? Yeah. Awesome.

02:08:09.760 --> 02:08:11.520
<v Speaker 0>Can you still hear me?

02:08:12.560 --> 02:08:14.160
<v Speaker 0>Can I still hear you actually? That should

02:08:14.160 --> 02:08:15.680
<v Speaker 0>be the question based on earlier.

02:08:18.320 --> 02:08:19.440
<v Speaker 0>No. I can't hear you.

02:08:30.775 --> 02:08:31.735
<v Speaker 0>Oh, you're muted.

02:08:42.830 --> 02:08:44.349
<v Speaker 0>No. You're gone.

02:08:51.070 --> 02:08:53.070
<v Speaker 0>Is it your end? What do you think?

02:09:01.125 --> 02:09:03.125
<v Speaker 0>Alright. But I can't hear you.

02:09:05.445 --> 02:09:06.900
<v Speaker 0>You know what? Okay.

02:09:07.380 --> 02:09:09.620
<v Speaker 0>That's frustrating, but we are at the end

02:09:09.620 --> 02:09:11.140
<v Speaker 0>of our session. I just want to say

02:09:11.140 --> 02:09:12.820
<v Speaker 0>thank you very much. I think that was

02:09:12.820 --> 02:09:15.300
<v Speaker 0>amazing how you managed to take such a

02:09:15.300 --> 02:09:16.260
<v Speaker 0>complex

02:09:16.340 --> 02:09:18.500
<v Speaker 0>subject and, you know, you didn't just introduce

02:09:18.500 --> 02:09:20.020
<v Speaker 0>us to Kubeflow and the new features, but

02:09:20.020 --> 02:09:22.420
<v Speaker 0>you actually took us on a full journey

02:09:21.555 --> 02:09:23.555
<v Speaker 0>of data science and how we could apply

02:09:23.555 --> 02:09:26.435
<v Speaker 0>that to real world situations like detecting pneumonia

02:09:26.435 --> 02:09:28.195
<v Speaker 0>and X rays. I found the whole thing

02:09:28.195 --> 02:09:30.515
<v Speaker 0>riveting. I've learned so, so much. Thank you

02:09:30.515 --> 02:09:32.035
<v Speaker 0>very much for that. Kubeflow

02:09:32.195 --> 02:09:34.595
<v Speaker 0>looks amazing. I hope other people have really

02:09:34.595 --> 02:09:36.195
<v Speaker 0>enjoyed today's session and we'll take a look

02:09:36.195 --> 02:09:38.150
<v Speaker 0>at it too. So, Michael,

02:09:38.470 --> 02:09:40.710
<v Speaker 0>although you can't say goodbye, you there we

02:09:40.710 --> 02:09:42.390
<v Speaker 0>go. We salute. We'll do it perfectly. Thank

02:09:42.390 --> 02:09:43.750
<v Speaker 0>you very much for joining me today. I

02:09:43.750 --> 02:09:45.190
<v Speaker 0>will speak to you soon. Have a good

02:09:45.190 --> 02:09:45.350
<v Speaker 0>one.
