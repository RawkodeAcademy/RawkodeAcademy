WEBVTT

NOTE
Transcription provided by Deepgram
Request Id: 833ff397-6f8f-489f-a475-a0eeced30546
Created: 2025-06-05T21:57:10.182Z
Duration: 3994.9846
Channels: 1

00:00:02.159 --> 00:00:05.840
<v Speaker 0>Alright. Alright. Welcome back. You know the score.

00:00:07.279 --> 00:00:08.160
<v Speaker 0>Rawkode

00:00:08.160 --> 00:00:09.200
<v Speaker 0>Academy's

00:00:09.200 --> 00:00:11.200
<v Speaker 0>live. We're knocking at your door.

00:00:13.455 --> 00:00:16.974
<v Speaker 0>With knowledge bombs and tech that's red hot.

00:00:18.335 --> 00:00:20.335
<v Speaker 0>Cloud native AI,

00:00:20.415 --> 00:00:22.414
<v Speaker 0>yeah, we've got a lot.

00:00:23.935 --> 00:00:25.855
<v Speaker 0>From ours to OCI,

00:00:25.935 --> 00:00:28.410
<v Speaker 0>the future's in our sights,

00:00:29.770 --> 00:00:31.130
<v Speaker 0>managing models

00:00:31.210 --> 00:00:33.290
<v Speaker 0>day and through the night.

00:00:33.770 --> 00:00:34.250
<v Speaker 0>Kubernetes

00:00:36.170 --> 00:00:36.970
<v Speaker 0>clusters

00:00:36.970 --> 00:00:38.809
<v Speaker 0>and registry so grand,

00:00:39.225 --> 00:00:40.585
<v Speaker 0>we're

00:00:40.585 --> 00:00:42.745
<v Speaker 0>taking AIML,

00:00:42.745 --> 00:00:44.265
<v Speaker 0>putting it in your hand.

00:00:45.465 --> 00:00:47.705
<v Speaker 0>Today we're diving

00:00:47.705 --> 00:00:49.625
<v Speaker 0>deep. No time to delay

00:01:21.770 --> 00:01:22.490
<v Speaker 0>stop.

00:01:22.970 --> 00:01:23.450
<v Speaker 0>Cloud

00:01:24.170 --> 00:01:25.690
<v Speaker 0>native AI,

00:01:25.850 --> 00:01:27.930
<v Speaker 0>gonna go the extra mile.

00:01:29.210 --> 00:01:31.290
<v Speaker 0>So buckle up, get

00:01:31.610 --> 00:01:32.570
<v Speaker 0>ready to learn.

00:02:19.070 --> 00:02:21.550
<v Speaker 1>Hello and welcome back to the Rawkode Academy.

00:02:21.550 --> 00:02:23.790
<v Speaker 1>I'm your host, David Flanagan, also known across

00:02:23.790 --> 00:02:25.230
<v Speaker 1>the Internet as Rawkode.

00:02:25.470 --> 00:02:27.550
<v Speaker 1>In today's session, we're gonna take a look

00:02:27.550 --> 00:02:30.830
<v Speaker 1>at running AI ML workloads on Kubernetes and

00:02:30.830 --> 00:02:31.710
<v Speaker 1>all of the fun,

00:02:32.515 --> 00:02:34.675
<v Speaker 1>interesting aspects of doing so.

00:02:35.075 --> 00:02:36.355
<v Speaker 1>There's a lot to learn here today and

00:02:36.355 --> 00:02:38.355
<v Speaker 1>we've got two fantastic demos from two fantastic

00:02:38.355 --> 00:02:41.155
<v Speaker 1>people from Microsoft. So let's move over there

00:02:41.155 --> 00:02:42.435
<v Speaker 1>and meet them now.

00:02:44.880 --> 00:02:47.280
<v Speaker 1>Hey, everybody. Hey, Fenman. How are you? Good.

00:02:47.280 --> 00:02:48.880
<v Speaker 2>Good. I just have to say to start,

00:02:49.120 --> 00:02:51.680
<v Speaker 2>that is probably the coolest intro music that

00:02:51.680 --> 00:02:54.080
<v Speaker 2>I've had or I've seen. So props.

00:02:54.800 --> 00:02:56.480
<v Speaker 1>Yeah. Well, you know, it's only fitting that

00:02:56.480 --> 00:02:58.240
<v Speaker 1>we're doing an AI ML episode. We have

00:02:58.240 --> 00:03:00.935
<v Speaker 1>some AI generated music, and I love that

00:03:00.935 --> 00:03:03.335
<v Speaker 1>you can just I mean, it's just so

00:03:03.335 --> 00:03:05.095
<v Speaker 1>available these days. It's amazing what AI can

00:03:05.095 --> 00:03:06.855
<v Speaker 1>do for us. And there's

00:03:06.855 --> 00:03:10.215
<v Speaker 1>a lot of cloud infrastructure, CPU, GPUs working

00:03:10.215 --> 00:03:12.135
<v Speaker 1>behind the scenes. And hopefully, today, we can

00:03:12.135 --> 00:03:13.495
<v Speaker 1>give people a bit of insight on how

00:03:13.495 --> 00:03:16.390
<v Speaker 1>to do this correctly, properly, safely. I'm not

00:03:16.390 --> 00:03:18.630
<v Speaker 1>sure, but I'm interested to find out.

00:03:19.430 --> 00:03:20.950
<v Speaker 1>Could you both please take a moment to

00:03:20.950 --> 00:03:22.950
<v Speaker 1>introduce yourself to the audience and share a

00:03:22.950 --> 00:03:24.870
<v Speaker 1>little bit about you, please? Sure. I'll go

00:03:24.870 --> 00:03:27.110
<v Speaker 2>first. So my name is Josh Stephanie. I

00:03:27.110 --> 00:03:29.115
<v Speaker 2>am a senior cloud advocate on the cloud

00:03:29.115 --> 00:03:30.795
<v Speaker 2>native team inside Microsoft.

00:03:30.875 --> 00:03:32.635
<v Speaker 2>Been in the role a couple years.

00:03:33.115 --> 00:03:36.075
<v Speaker 2>Before that, I was, NSRE at Stack Overflow,

00:03:36.635 --> 00:03:38.715
<v Speaker 2>and then a DevOps lead in previous roles.

00:03:38.715 --> 00:03:39.995
<v Speaker 2>So it it was kind of a good

00:03:39.995 --> 00:03:41.995
<v Speaker 2>natural progression and and fit for me, but

00:03:41.995 --> 00:03:44.220
<v Speaker 2>I really enjoy enjoy the work and then

00:03:44.220 --> 00:03:45.819
<v Speaker 2>kind of, you know, just a little bit

00:03:45.819 --> 00:03:48.300
<v Speaker 2>more background on me. Mostly writing Go, but

00:03:48.300 --> 00:03:50.700
<v Speaker 2>starting to write in Rust and kind of

00:03:50.700 --> 00:03:52.860
<v Speaker 2>float around a lot of CNCF projects and

00:03:52.860 --> 00:03:55.260
<v Speaker 2>contribute and do conference talks and stuff like

00:03:55.260 --> 00:03:56.860
<v Speaker 2>that. But that's kind of like a a

00:03:56.860 --> 00:03:59.775
<v Speaker 2>TLDR on on me. Feynman, over to you.

00:04:00.495 --> 00:04:01.295
<v Speaker 3>Yeah.

00:04:01.615 --> 00:04:04.015
<v Speaker 3>My name is Feynman. I'm a CNCF project

00:04:04.015 --> 00:04:08.815
<v Speaker 3>maintainer and currently maintaining CNCF Notary Project, Auras,

00:04:09.135 --> 00:04:09.935
<v Speaker 3>and RADIFY.

00:04:10.380 --> 00:04:13.660
<v Speaker 3>Notar project and Auras will be the major

00:04:13.660 --> 00:04:16.140
<v Speaker 3>focus today because we're going to share how

00:04:16.140 --> 00:04:17.580
<v Speaker 3>to manage and run

00:04:18.459 --> 00:04:21.500
<v Speaker 3>AI and machine learning models as OCR artifact

00:04:21.500 --> 00:04:24.460
<v Speaker 3>with Auras and also

00:04:23.885 --> 00:04:25.565
<v Speaker 3>verify it with notation.

00:04:27.485 --> 00:04:30.205
<v Speaker 3>I'm also a product manager for Microsoft

00:04:30.205 --> 00:04:32.365
<v Speaker 3>Azure. I have been working

00:04:33.245 --> 00:04:36.365
<v Speaker 3>on the secure supply chain over the past

00:04:36.365 --> 00:04:38.980
<v Speaker 3>three years, and I enjoy the work

00:04:39.300 --> 00:04:42.260
<v Speaker 3>including open source and securing supply chain.

00:04:44.260 --> 00:04:46.420
<v Speaker 1>All right, awesome. Thank you both so much.

00:04:46.820 --> 00:04:48.980
<v Speaker 1>Let's start off with a couple of questions

00:04:48.980 --> 00:04:50.420
<v Speaker 1>and then I will ease into the demo

00:04:50.420 --> 00:04:53.115
<v Speaker 1>today. Well, you know, I've been in this

00:04:53.115 --> 00:04:55.275
<v Speaker 1>Kubernetes space for a while. AI and ML

00:04:55.275 --> 00:04:57.595
<v Speaker 1>workloads are are very new to me.

00:04:58.074 --> 00:05:00.715
<v Speaker 1>I'm gonna say running them on Kubernetes does

00:05:00.715 --> 00:05:02.794
<v Speaker 1>fill me with a little bit of fear

00:05:02.794 --> 00:05:05.194
<v Speaker 1>because when I think of Kubernetes, I think

00:05:05.194 --> 00:05:06.955
<v Speaker 1>of stateless services, small containers,

00:05:07.510 --> 00:05:10.790
<v Speaker 1>low memory and CPU footprint and been packing

00:05:10.790 --> 00:05:12.550
<v Speaker 1>as much stuff into a single machine as

00:05:12.550 --> 00:05:13.190
<v Speaker 1>I can.

00:05:13.590 --> 00:05:15.510
<v Speaker 1>But everything I know about AI and ML

00:05:15.510 --> 00:05:16.150
<v Speaker 1>is,

00:05:16.870 --> 00:05:20.310
<v Speaker 1>gigs, terabytes, petabytes of data being shifted about.

00:05:20.310 --> 00:05:21.510
<v Speaker 1>I've seen some crazy

00:05:21.990 --> 00:05:24.685
<v Speaker 1>container image sizes that I don't even want

00:05:24.685 --> 00:05:25.485
<v Speaker 1>to think about.

00:05:25.965 --> 00:05:27.485
<v Speaker 1>Is Kubernetes

00:05:28.205 --> 00:05:30.685
<v Speaker 1>important in AI and ML workloads? And how

00:05:30.685 --> 00:05:32.605
<v Speaker 1>do we make that sensible for people that

00:05:32.605 --> 00:05:33.325
<v Speaker 1>are watching?

00:05:35.085 --> 00:05:35.965
<v Speaker 1>It's really brave.

00:05:36.400 --> 00:05:37.840
<v Speaker 2>Do you wanna take a a stab? I

00:05:37.840 --> 00:05:39.120
<v Speaker 2>I can I can take a stab if

00:05:39.120 --> 00:05:41.440
<v Speaker 2>you want, Feyman? Yeah. You can. Go ahead.

00:05:42.320 --> 00:05:44.320
<v Speaker 2>For for me, it just kinda brings me

00:05:44.320 --> 00:05:46.480
<v Speaker 2>back. You know, containers started about that the

00:05:46.480 --> 00:05:48.160
<v Speaker 2>image size. You know, if you look if

00:05:48.160 --> 00:05:49.840
<v Speaker 2>you look back, like, even the Windows containers,

00:05:49.840 --> 00:05:51.520
<v Speaker 2>I know they're not as popular as the

00:05:51.165 --> 00:05:52.925
<v Speaker 2>Linux containers, but they they started around that

00:05:52.925 --> 00:05:55.245
<v Speaker 2>same that same size. So Kubernetes as as

00:05:55.245 --> 00:05:57.485
<v Speaker 2>a platform, so per so to speak, can

00:05:57.485 --> 00:05:58.845
<v Speaker 2>handle that type of size.

00:05:59.085 --> 00:06:01.485
<v Speaker 2>I think where it's most appealing for me

00:06:01.485 --> 00:06:04.760
<v Speaker 2>to use Kubernetes is just the orchestration

00:06:05.080 --> 00:06:07.000
<v Speaker 2>and the abstractions that it gives you and

00:06:07.000 --> 00:06:09.000
<v Speaker 2>being able to move components around.

00:06:10.120 --> 00:06:11.320
<v Speaker 2>So I I would hate to give up

00:06:11.320 --> 00:06:13.480
<v Speaker 2>that flexibility of the orchestrator from a deployment

00:06:13.480 --> 00:06:15.640
<v Speaker 2>perspective and then being able to have everything

00:06:15.720 --> 00:06:17.720
<v Speaker 2>in YAML as much as YAML is a

00:06:17.720 --> 00:06:18.600
<v Speaker 2>pain to work with

00:06:19.534 --> 00:06:21.775
<v Speaker 2>From that the CICD perspective

00:06:21.854 --> 00:06:24.014
<v Speaker 2>and the and the velocity that you can

00:06:24.014 --> 00:06:25.215
<v Speaker 2>achieve with those systems,

00:06:25.615 --> 00:06:27.294
<v Speaker 2>I think, is still pretty important.

00:06:27.694 --> 00:06:30.254
<v Speaker 2>Granted, our image sizes are increasing again, but

00:06:30.254 --> 00:06:32.655
<v Speaker 2>it's really not too different from a recent

00:06:32.655 --> 00:06:33.294
<v Speaker 2>past,

00:06:33.534 --> 00:06:34.014
<v Speaker 2>to be honest.

00:06:36.500 --> 00:06:37.700
<v Speaker 1>Alright. Awesome.

00:06:38.180 --> 00:06:39.140
<v Speaker 1>Yeah. I mean,

00:06:39.620 --> 00:06:41.780
<v Speaker 1>we've already gotten out ten years of expertise

00:06:41.780 --> 00:06:43.620
<v Speaker 1>of Kubernetes under our belt. And as we

00:06:43.620 --> 00:06:44.980
<v Speaker 1>explore these

00:06:44.980 --> 00:06:47.915
<v Speaker 1>new workloads, which are AI and ML based

00:06:47.915 --> 00:06:49.275
<v Speaker 1>at the moment, I mean, everything seems to

00:06:49.275 --> 00:06:52.235
<v Speaker 1>be going this way, with agentic workflows now.

00:06:52.235 --> 00:06:54.155
<v Speaker 1>You know, there is a potential future where

00:06:54.395 --> 00:06:56.155
<v Speaker 1>we don't even write software anymore. We're just

00:06:56.155 --> 00:06:58.155
<v Speaker 1>writing LLM agents and then having them talk

00:06:58.155 --> 00:06:59.930
<v Speaker 1>to each other. Like, I I I don't

00:06:59.930 --> 00:07:01.370
<v Speaker 1>know how far away that is, but the

00:07:01.370 --> 00:07:02.970
<v Speaker 1>AI buzz would tell us that it's next

00:07:02.970 --> 00:07:04.410
<v Speaker 1>week or it was last week and we're

00:07:04.410 --> 00:07:06.570
<v Speaker 1>just not. Yeah. It's hard to tell. But,

00:07:06.570 --> 00:07:08.410
<v Speaker 1>yeah, I'm very excited for today's session.

00:07:08.970 --> 00:07:10.410
<v Speaker 1>Can you both take a minute just to

00:07:10.410 --> 00:07:11.850
<v Speaker 1>tell us what you're going to be showing

00:07:11.850 --> 00:07:13.930
<v Speaker 1>the audience today and what they're gonna walk

00:07:13.930 --> 00:07:16.225
<v Speaker 1>away with? Sure. I'll let Fei Men go

00:07:16.225 --> 00:07:18.065
<v Speaker 2>first because he's doing the first demo.

00:07:18.385 --> 00:07:21.825
<v Speaker 3>Yeah. Today, we're going to walk through the

00:07:21.825 --> 00:07:25.345
<v Speaker 3>challenges of managing AI and machine learning models

00:07:25.345 --> 00:07:27.905
<v Speaker 3>in cloud native world, especially on Kubernetes.

00:07:28.430 --> 00:07:31.710
<v Speaker 3>And then we're gonna briefly share what is

00:07:31.710 --> 00:07:35.310
<v Speaker 3>OCI, the OCI standard, open container initiatives,

00:07:35.470 --> 00:07:38.190
<v Speaker 3>and also what is the CNCF ORAAS project.

00:07:38.750 --> 00:07:41.895
<v Speaker 3>And next, we're gonna briefly share the Notre

00:07:41.895 --> 00:07:45.655
<v Speaker 3>project. I remember we have another fellow, Yi,

00:07:45.655 --> 00:07:48.935
<v Speaker 3>who delved into the Notre project and ratified

00:07:48.935 --> 00:07:52.375
<v Speaker 3>for signing the verification. But today, we're gonna

00:07:52.375 --> 00:07:55.255
<v Speaker 3>demonstrate Notre project in another aspect,

00:07:55.335 --> 00:07:57.560
<v Speaker 3>which is sign and verification

00:07:57.960 --> 00:07:59.800
<v Speaker 3>of the AI models.

00:08:00.120 --> 00:08:00.520
<v Speaker 3>And

00:08:01.159 --> 00:08:03.080
<v Speaker 3>we will have two demos today.

00:08:04.039 --> 00:08:07.160
<v Speaker 3>The first one is to package and run

00:08:07.319 --> 00:08:10.545
<v Speaker 3>AI models as an OCI artifact, and we

00:08:10.545 --> 00:08:12.945
<v Speaker 3>can push it to the OCR registry.

00:08:13.105 --> 00:08:14.945
<v Speaker 3>And the second demo will be taken by

00:08:14.945 --> 00:08:15.745
<v Speaker 3>Josh

00:08:16.305 --> 00:08:17.425
<v Speaker 3>to demonstrate

00:08:17.745 --> 00:08:20.705
<v Speaker 3>how can you sign and verify your AI

00:08:20.705 --> 00:08:23.025
<v Speaker 3>models locally and distribute it

00:08:23.419 --> 00:08:25.020
<v Speaker 3>via OSA registries.

00:08:26.860 --> 00:08:28.140
<v Speaker 1>All right, awesome.

00:08:28.699 --> 00:08:30.699
<v Speaker 1>Well, thank you for sharing. I think it's

00:08:30.699 --> 00:08:32.620
<v Speaker 1>about time we share a screen, get hands

00:08:32.620 --> 00:08:34.380
<v Speaker 1>on, and show off some pretty cool open

00:08:34.380 --> 00:08:35.580
<v Speaker 1>source technologies. So

00:08:36.535 --> 00:08:39.575
<v Speaker 1>let's jump over to the screen share.

00:08:43.415 --> 00:08:45.335
<v Speaker 1>Alright. Take it away, Venkman.

00:08:46.375 --> 00:08:47.815
<v Speaker 3>Awesome. Thank you, David.

00:08:48.610 --> 00:08:49.170
<v Speaker 3>So

00:08:50.610 --> 00:08:54.290
<v Speaker 3>when we're thinking about managing AI or machine

00:08:54.290 --> 00:08:55.569
<v Speaker 3>learning models,

00:08:55.569 --> 00:08:56.850
<v Speaker 3>what's the challenges

00:08:57.410 --> 00:08:58.529
<v Speaker 3>coming to your mind?

00:08:59.170 --> 00:08:59.810
<v Speaker 3>Actually,

00:09:01.170 --> 00:09:03.725
<v Speaker 3>not an AI expert. I'm also quite new

00:09:03.725 --> 00:09:05.085
<v Speaker 3>to AI, but

00:09:05.645 --> 00:09:07.245
<v Speaker 3>what attracts my interest?

00:09:07.725 --> 00:09:08.285
<v Speaker 3>Actually,

00:09:08.605 --> 00:09:11.965
<v Speaker 3>have seen a lot of customers and community

00:09:11.965 --> 00:09:12.925
<v Speaker 3>fellows

00:09:12.925 --> 00:09:13.965
<v Speaker 3>who are asking

00:09:14.365 --> 00:09:15.725
<v Speaker 3>questions like, hey,

00:09:16.490 --> 00:09:18.650
<v Speaker 3>we have a very large size

00:09:18.970 --> 00:09:20.330
<v Speaker 3>LM models.

00:09:20.490 --> 00:09:23.450
<v Speaker 3>How can we run it in a container?

00:09:23.450 --> 00:09:25.930
<v Speaker 3>How can we containerize it and make sure

00:09:25.930 --> 00:09:27.050
<v Speaker 3>they can be

00:09:27.450 --> 00:09:28.810
<v Speaker 3>stored

00:09:28.805 --> 00:09:32.404
<v Speaker 3>in a centralized place, just like OSAT registry?

00:09:32.725 --> 00:09:35.925
<v Speaker 3>And how can we distribute it to different

00:09:35.925 --> 00:09:39.365
<v Speaker 3>platform and also from dev to production?

00:09:40.005 --> 00:09:42.805
<v Speaker 3>And eventually, Devon built a central

00:09:43.204 --> 00:09:47.660
<v Speaker 3>platform to host those models and also securely

00:09:47.660 --> 00:09:51.100
<v Speaker 3>distribute it from on premise to multi cloud

00:09:51.100 --> 00:09:51.900
<v Speaker 3>environment.

00:09:52.940 --> 00:09:56.140
<v Speaker 3>That is the questions come from our real

00:09:56.140 --> 00:09:58.940
<v Speaker 3>customers and the real world. We have seen

00:09:59.575 --> 00:10:01.415
<v Speaker 3>users like Bloomberg,

00:10:02.055 --> 00:10:02.935
<v Speaker 3>Red Hat,

00:10:03.575 --> 00:10:05.735
<v Speaker 3>and also a lot of end users, they

00:10:05.735 --> 00:10:06.855
<v Speaker 3>are trying to

00:10:07.815 --> 00:10:11.015
<v Speaker 3>store their AI models in the Container Registry.

00:10:11.560 --> 00:10:14.040
<v Speaker 3>That's very magic, right? So previously,

00:10:15.560 --> 00:10:17.879
<v Speaker 3>our awareness about the Container Registry is that

00:10:17.879 --> 00:10:21.480
<v Speaker 3>we just use it to store container images

00:10:21.639 --> 00:10:23.800
<v Speaker 3>and maybe Helm charts, right?

00:10:24.279 --> 00:10:25.879
<v Speaker 3>But

00:10:25.135 --> 00:10:28.495
<v Speaker 3>with the new standard such as OCR 1.1,

00:10:28.654 --> 00:10:30.175
<v Speaker 3>we are able to store

00:10:30.975 --> 00:10:33.295
<v Speaker 3>anything in OCR registries,

00:10:34.015 --> 00:10:35.615
<v Speaker 3>such as arbitrary files,

00:10:36.415 --> 00:10:39.295
<v Speaker 3>supply chain artifacts like SBONG and

00:10:39.774 --> 00:10:40.415
<v Speaker 3>signature,

00:10:41.320 --> 00:10:44.440
<v Speaker 3>and also maybe even AI models in a

00:10:44.440 --> 00:10:45.800
<v Speaker 3>central place, right?

00:10:46.920 --> 00:10:49.240
<v Speaker 3>So here's the thing. So we have seen

00:10:49.240 --> 00:10:52.360
<v Speaker 3>a lot of customers and industries are complaining

00:10:52.360 --> 00:10:54.279
<v Speaker 3>about lack of a

00:10:55.315 --> 00:10:57.475
<v Speaker 3>unified standard to manage

00:10:57.555 --> 00:10:59.795
<v Speaker 3>and distribute AI models in a cloud native

00:10:59.795 --> 00:11:02.595
<v Speaker 3>world. So basically, the lack of the

00:11:02.995 --> 00:11:04.115
<v Speaker 3>standard to

00:11:04.275 --> 00:11:05.875
<v Speaker 3>make the model management

00:11:06.755 --> 00:11:09.155
<v Speaker 3>have versioning and reproducibility

00:11:10.700 --> 00:11:11.420
<v Speaker 3>because

00:11:12.060 --> 00:11:14.700
<v Speaker 3>AI models is evolving very fast. They may

00:11:14.700 --> 00:11:18.300
<v Speaker 3>have multiple versions, but they didn't use Git

00:11:18.300 --> 00:11:18.940
<v Speaker 3>and

00:11:19.180 --> 00:11:21.420
<v Speaker 3>OCI to manage those versions.

00:11:22.140 --> 00:11:24.315
<v Speaker 3>So versioning and the reproducibility

00:11:24.315 --> 00:11:27.515
<v Speaker 3>might be the first challenge for the industry.

00:11:28.235 --> 00:11:28.954
<v Speaker 3>Second,

00:11:29.834 --> 00:11:31.274
<v Speaker 3>as we all know that

00:11:31.915 --> 00:11:33.834
<v Speaker 3>the AI models

00:11:36.490 --> 00:11:38.090
<v Speaker 3>sometimes have more than

00:11:38.570 --> 00:11:42.010
<v Speaker 3>at least one gigabyte, right? It's very large.

00:11:42.250 --> 00:11:44.730
<v Speaker 3>So it's a big challenge for them to

00:11:44.730 --> 00:11:47.770
<v Speaker 3>distribute it from their local to the remote

00:11:47.770 --> 00:11:48.330
<v Speaker 3>securely.

00:11:48.845 --> 00:11:50.445
<v Speaker 3>How can they secure the

00:11:51.485 --> 00:11:53.165
<v Speaker 3>AI model distribution?

00:11:53.805 --> 00:11:55.325
<v Speaker 3>That's another challenge.

00:11:56.605 --> 00:11:59.165
<v Speaker 3>And how can they transfer those models from

00:11:59.165 --> 00:12:02.765
<v Speaker 3>their local environment to maybe different

00:12:02.765 --> 00:12:05.870
<v Speaker 3>cloud platform and eventually running

00:12:06.190 --> 00:12:07.950
<v Speaker 3>it on Kubernetes.

00:12:10.190 --> 00:12:12.430
<v Speaker 3>Even more, they are thinking about how can

00:12:12.430 --> 00:12:13.710
<v Speaker 3>they deploy it

00:12:14.190 --> 00:12:14.750
<v Speaker 3>in

00:12:15.230 --> 00:12:18.384
<v Speaker 3>an efficient way. So those are the challenges

00:12:18.384 --> 00:12:20.464
<v Speaker 3>that we have been observed from the industry

00:12:20.464 --> 00:12:23.824
<v Speaker 3>and also from our communication with the customers,

00:12:23.904 --> 00:12:25.185
<v Speaker 3>with our communities.

00:12:28.464 --> 00:12:29.105
<v Speaker 3>Okay,

00:12:29.425 --> 00:12:32.720
<v Speaker 3>so the AI or AI infra, machine learning

00:12:32.720 --> 00:12:34.000
<v Speaker 3>infra developers,

00:12:34.079 --> 00:12:36.720
<v Speaker 3>they may want to use the same tools

00:12:36.720 --> 00:12:38.160
<v Speaker 3>without any change.

00:12:38.880 --> 00:12:40.480
<v Speaker 3>They want to have

00:12:41.680 --> 00:12:44.905
<v Speaker 3>even minimal change in their workflow to achieve

00:12:44.905 --> 00:12:46.985
<v Speaker 3>a unified management

00:12:46.985 --> 00:12:49.705
<v Speaker 3>norm in their AI or machine learning

00:12:50.345 --> 00:12:51.145
<v Speaker 3>standard,

00:12:51.385 --> 00:12:52.025
<v Speaker 3>right?

00:12:52.745 --> 00:12:55.305
<v Speaker 3>They want to have easy mode evaluation and

00:12:55.305 --> 00:12:55.785
<v Speaker 3>deployment.

00:12:57.029 --> 00:12:59.029
<v Speaker 3>Those are the real requirements that we heard

00:12:59.029 --> 00:13:00.630
<v Speaker 3>from the communities.

00:13:01.590 --> 00:13:02.470
<v Speaker 3>But from

00:13:03.029 --> 00:13:04.550
<v Speaker 3>the engineering perspective,

00:13:04.550 --> 00:13:07.030
<v Speaker 3>so we may receive the request from

00:13:07.270 --> 00:13:10.155
<v Speaker 3>the engineering team that they want to ensure

00:13:10.155 --> 00:13:13.355
<v Speaker 3>the software best practice by following the engineering

00:13:13.355 --> 00:13:14.155
<v Speaker 3>conventions.

00:13:14.715 --> 00:13:16.795
<v Speaker 3>For example, they want to have the model

00:13:16.795 --> 00:13:17.915
<v Speaker 3>files management

00:13:19.035 --> 00:13:19.995
<v Speaker 3>immutable,

00:13:20.235 --> 00:13:22.875
<v Speaker 3>and they want to have very strict versioning

00:13:22.875 --> 00:13:24.900
<v Speaker 3>for the model development.

00:13:25.620 --> 00:13:28.660
<v Speaker 3>Because in their mind, models are also just

00:13:28.660 --> 00:13:30.180
<v Speaker 3>normal software.

00:13:30.340 --> 00:13:32.260
<v Speaker 3>There's no big difference between

00:13:33.940 --> 00:13:35.860
<v Speaker 3>other software and models.

00:13:36.404 --> 00:13:38.964
<v Speaker 3>So they want to have very strict

00:13:39.845 --> 00:13:41.925
<v Speaker 3>immusability and versioning,

00:13:41.925 --> 00:13:45.845
<v Speaker 3>as well as proper release process and DevOps.

00:13:46.005 --> 00:13:48.644
<v Speaker 3>They want to automate everything, right? Because they

00:13:48.644 --> 00:13:50.485
<v Speaker 3>are facing a bunch of

00:13:51.350 --> 00:13:54.710
<v Speaker 3>pain points to manage thousands of the software

00:13:54.710 --> 00:13:55.590
<v Speaker 3>delivery

00:13:55.990 --> 00:13:57.030
<v Speaker 3>in the company.

00:13:57.670 --> 00:13:59.110
<v Speaker 3>And also they want to make sure the

00:13:59.110 --> 00:14:00.550
<v Speaker 3>model distribution

00:14:00.630 --> 00:14:03.430
<v Speaker 3>and deployment made the security and the vulnerability

00:14:03.430 --> 00:14:06.675
<v Speaker 3>checks and eventually meet the company compliance

00:14:06.675 --> 00:14:08.035
<v Speaker 3>criteria.

00:14:09.075 --> 00:14:10.915
<v Speaker 3>So that comes to a problem.

00:14:11.714 --> 00:14:14.755
<v Speaker 3>Should the ML or AI developers

00:14:14.755 --> 00:14:16.834
<v Speaker 3>host those models

00:14:17.579 --> 00:14:18.380
<v Speaker 3>on a

00:14:18.779 --> 00:14:20.540
<v Speaker 3>separate model registry,

00:14:20.700 --> 00:14:22.620
<v Speaker 3>such as OLAMA registry,

00:14:22.620 --> 00:14:23.980
<v Speaker 3>or they want to build

00:14:24.620 --> 00:14:25.899
<v Speaker 3>an additional

00:14:25.980 --> 00:14:26.940
<v Speaker 3>Snowflake.

00:14:29.180 --> 00:14:31.725
<v Speaker 3>But from the engineering point of view, they

00:14:31.725 --> 00:14:34.045
<v Speaker 3>want to have a unified platform.

00:14:34.045 --> 00:14:35.885
<v Speaker 3>Maybe it's an OCR registry.

00:14:36.445 --> 00:14:37.165
<v Speaker 3>Maybe

00:14:39.245 --> 00:14:40.445
<v Speaker 1>it's an S3

00:14:41.805 --> 00:14:44.925
<v Speaker 3>bucket or is a blob storage.

00:14:47.870 --> 00:14:49.710
<v Speaker 3>So the thing is too,

00:14:50.350 --> 00:14:52.350
<v Speaker 3>people want to unify model

00:14:52.750 --> 00:14:54.190
<v Speaker 3>management and

00:14:56.350 --> 00:14:57.950
<v Speaker 3>also the model distribution

00:14:58.190 --> 00:14:59.310
<v Speaker 3>in a central way.

00:15:02.805 --> 00:15:03.445
<v Speaker 3>Okay.

00:15:04.085 --> 00:15:06.245
<v Speaker 3>I heard a practice from Bloomberg.

00:15:06.245 --> 00:15:08.645
<v Speaker 3>They demonstrated how they currently

00:15:08.645 --> 00:15:11.605
<v Speaker 3>manage thousands of AI models in an OSAT

00:15:11.605 --> 00:15:12.405
<v Speaker 3>registry

00:15:13.045 --> 00:15:15.365
<v Speaker 3>because they noticed

00:15:16.165 --> 00:15:19.290
<v Speaker 3>there are several benefits of using OCI registries

00:15:19.290 --> 00:15:21.050
<v Speaker 3>as model registry.

00:15:21.370 --> 00:15:22.010
<v Speaker 3>First,

00:15:22.250 --> 00:15:24.250
<v Speaker 3>they can easily standardize the

00:15:25.530 --> 00:15:26.650
<v Speaker 3>packaging process.

00:15:27.130 --> 00:15:28.570
<v Speaker 3>So let's say, for example,

00:15:29.130 --> 00:15:32.055
<v Speaker 3>they can package the AI models as OCI

00:15:32.055 --> 00:15:33.015
<v Speaker 3>artifacts.

00:15:33.335 --> 00:15:35.415
<v Speaker 3>With OCI 1.1 standard,

00:15:35.655 --> 00:15:37.495
<v Speaker 3>there's

00:15:37.495 --> 00:15:40.775
<v Speaker 3>a property artifact type. They can easily define

00:15:40.775 --> 00:15:43.655
<v Speaker 3>the type of the AI models and package

00:15:43.655 --> 00:15:46.215
<v Speaker 3>it into an OCI artifact,

00:15:46.779 --> 00:15:49.339
<v Speaker 3>eventually store the OCI artifact in the Container

00:15:49.339 --> 00:15:50.140
<v Speaker 3>Registry.

00:15:51.020 --> 00:15:54.779
<v Speaker 3>This should enable consistent distribution across different cloud

00:15:54.779 --> 00:15:55.580
<v Speaker 3>environments

00:15:55.580 --> 00:15:58.380
<v Speaker 3>because the OCI artifact will be stored in

00:15:58.380 --> 00:16:00.380
<v Speaker 3>a central Container Registry.

00:16:00.700 --> 00:16:02.540
<v Speaker 3>Then users can pull

00:16:03.235 --> 00:16:04.675
<v Speaker 3>the image

00:16:05.314 --> 00:16:07.875
<v Speaker 3>or the OCI artifact from the registry and

00:16:07.875 --> 00:16:10.915
<v Speaker 3>easily distribute it across different environments.

00:16:11.875 --> 00:16:14.194
<v Speaker 3>And also, all of those dependencies

00:16:14.850 --> 00:16:17.890
<v Speaker 3>can also be packaged together with the AI

00:16:17.890 --> 00:16:18.610
<v Speaker 3>models

00:16:19.089 --> 00:16:20.850
<v Speaker 3>in an OCI artifact.

00:16:20.930 --> 00:16:23.570
<v Speaker 3>They can be distributed together with the

00:16:23.810 --> 00:16:24.690
<v Speaker 3>AI models.

00:16:28.425 --> 00:16:31.785
<v Speaker 3>The second benefit is that users can leverage

00:16:31.785 --> 00:16:35.065
<v Speaker 3>the registry of efficient storage

00:16:35.305 --> 00:16:36.904
<v Speaker 3>because the

00:16:36.904 --> 00:16:38.825
<v Speaker 3>Container Registry use

00:16:39.225 --> 00:16:39.945
<v Speaker 3>the

00:16:40.105 --> 00:16:42.345
<v Speaker 3>content addressable storage

00:16:43.560 --> 00:16:44.920
<v Speaker 3>to store

00:16:45.240 --> 00:16:46.600
<v Speaker 3>the contained images.

00:16:46.920 --> 00:16:49.320
<v Speaker 3>And if you look at the model file

00:16:49.320 --> 00:16:50.280
<v Speaker 3>and the

00:16:51.240 --> 00:16:53.960
<v Speaker 3>OSAT image, you will find the directory structure

00:16:53.960 --> 00:16:54.840
<v Speaker 3>looks quite similar.

00:16:55.585 --> 00:16:57.185
<v Speaker 3>I will have another

00:16:57.425 --> 00:16:59.825
<v Speaker 3>we will have another picture to showcase

00:17:00.465 --> 00:17:01.105
<v Speaker 3>the

00:17:01.505 --> 00:17:04.625
<v Speaker 3>structure of between AI models and also the

00:17:04.625 --> 00:17:05.425
<v Speaker 3>OCI image.

00:17:07.530 --> 00:17:10.570
<v Speaker 3>Obviously, if you have anything in your Container

00:17:10.570 --> 00:17:11.369
<v Speaker 3>Registry,

00:17:12.090 --> 00:17:14.730
<v Speaker 3>you will have a centralized version control,

00:17:14.810 --> 00:17:16.330
<v Speaker 3>and it will be easy to roll back

00:17:16.330 --> 00:17:18.810
<v Speaker 3>the OAI model. If you find there's any

00:17:18.810 --> 00:17:19.690
<v Speaker 3>vulnerability

00:17:19.770 --> 00:17:21.905
<v Speaker 3>or there's any unexpected

00:17:21.905 --> 00:17:23.905
<v Speaker 3>change, you can roll back to the last

00:17:23.905 --> 00:17:24.544
<v Speaker 3>version.

00:17:24.944 --> 00:17:26.864
<v Speaker 3>And you can also reproduce

00:17:26.865 --> 00:17:29.745
<v Speaker 3>the change for different environment,

00:17:29.745 --> 00:17:30.304
<v Speaker 3>right?

00:17:32.065 --> 00:17:34.785
<v Speaker 3>And obviously, you will also have a unified

00:17:35.580 --> 00:17:38.299
<v Speaker 3>access control because you can leverage the role

00:17:38.299 --> 00:17:41.820
<v Speaker 3>based access control for AI models and container

00:17:41.820 --> 00:17:44.380
<v Speaker 3>images in a central place. And you can

00:17:44.380 --> 00:17:47.179
<v Speaker 3>also enhance your supply chain security

00:17:47.260 --> 00:17:49.179
<v Speaker 3>for your AI models

00:17:49.575 --> 00:17:51.575
<v Speaker 3>by attaching signatures,

00:17:52.054 --> 00:17:53.975
<v Speaker 3>S bombs, attestations

00:17:53.975 --> 00:17:56.934
<v Speaker 3>with the model files in the OCI artifact.

00:17:59.414 --> 00:18:01.735
<v Speaker 3>That is the benefits of using OCI Registry

00:18:01.735 --> 00:18:04.930
<v Speaker 3>as Model Registry to distribute and store your

00:18:04.930 --> 00:18:05.970
<v Speaker 3>AI models.

00:18:07.090 --> 00:18:08.049
<v Speaker 3>So go ahead.

00:18:09.250 --> 00:18:10.929
<v Speaker 3>So we're going to deep dive

00:18:11.650 --> 00:18:13.490
<v Speaker 3>into the OCI standard.

00:18:13.490 --> 00:18:15.330
<v Speaker 3>So Josh, would you want to take

00:18:15.810 --> 00:18:15.970
<v Speaker 3>it?

00:18:16.765 --> 00:18:18.684
<v Speaker 2>Yeah. Of course. And apologies if I went

00:18:18.684 --> 00:18:19.885
<v Speaker 2>a little bit darker. It looks like my

00:18:19.885 --> 00:18:21.405
<v Speaker 2>my light died, and I don't know where

00:18:21.405 --> 00:18:22.525
<v Speaker 2>the cord is to plug it in. So

00:18:22.525 --> 00:18:23.644
<v Speaker 2>apologies. But, anyway,

00:18:24.845 --> 00:18:25.965
<v Speaker 2>so, yeah, we're gonna take a look at

00:18:25.965 --> 00:18:28.125
<v Speaker 2>the OCI specification here and what this looks

00:18:28.125 --> 00:18:30.044
<v Speaker 2>like. You might have seen this already.

00:18:30.285 --> 00:18:33.490
<v Speaker 2>Most likely, you've kind of inadvertently seen this

00:18:33.490 --> 00:18:35.570
<v Speaker 2>in GitHub or whatever your repository looks like,

00:18:35.570 --> 00:18:37.330
<v Speaker 2>but you've probably not really taken a close

00:18:37.330 --> 00:18:37.890
<v Speaker 2>look

00:18:38.370 --> 00:18:41.090
<v Speaker 2>at what the metadata is. And what was

00:18:41.090 --> 00:18:42.690
<v Speaker 2>interesting so I don't know. Was probably a

00:18:42.690 --> 00:18:43.970
<v Speaker 2>year ago. I just decided to go on

00:18:43.970 --> 00:18:46.475
<v Speaker 2>a little programming adventure and figure out, like,

00:18:46.475 --> 00:18:48.075
<v Speaker 2>how could I like, what actually makes a

00:18:48.075 --> 00:18:48.715
<v Speaker 2>container?

00:18:48.955 --> 00:18:50.955
<v Speaker 2>What would I need to do to create

00:18:50.955 --> 00:18:53.355
<v Speaker 2>my own, like, Go runtime and and Go

00:18:53.355 --> 00:18:55.275
<v Speaker 2>packaging for a container? And I ran into

00:18:55.275 --> 00:18:56.875
<v Speaker 2>this layout. I started to use the OCI

00:18:56.875 --> 00:19:00.089
<v Speaker 2>and realized why every every registry uses this.

00:19:00.169 --> 00:19:01.289
<v Speaker 2>But if we just take a look at

00:19:01.289 --> 00:19:02.889
<v Speaker 2>this real quick I don't know if I

00:19:02.889 --> 00:19:04.409
<v Speaker 2>have a mark or anything, but I'll just

00:19:04.409 --> 00:19:06.250
<v Speaker 2>kind of call it out. But if you

00:19:06.250 --> 00:19:08.809
<v Speaker 2>look at it, there's kind of this bigger

00:19:08.809 --> 00:19:10.169
<v Speaker 2>frame that you need to look at or

00:19:10.169 --> 00:19:12.250
<v Speaker 2>a bucket called the manifest. And inside the

00:19:12.250 --> 00:19:14.414
<v Speaker 2>manifest has the config, and then it has

00:19:14.414 --> 00:19:15.134
<v Speaker 2>the layers.

00:19:15.375 --> 00:19:17.455
<v Speaker 2>And then those layers are actually, in the

00:19:17.455 --> 00:19:18.975
<v Speaker 2>case of a container, gonna be the file

00:19:18.975 --> 00:19:21.855
<v Speaker 2>system that are gonna be archived and compressed

00:19:21.855 --> 00:19:23.855
<v Speaker 2>into a particular layer. And those are all

00:19:23.855 --> 00:19:25.054
<v Speaker 2>the layers. So, like, the first time you

00:19:25.054 --> 00:19:26.429
<v Speaker 2>build it, you get your one layer. The

00:19:26.429 --> 00:19:28.029
<v Speaker 2>next time you build the next one. And

00:19:28.029 --> 00:19:29.629
<v Speaker 2>then when it runs a container, it extracts

00:19:29.629 --> 00:19:31.789
<v Speaker 2>them all out into a unified file system

00:19:32.269 --> 00:19:33.710
<v Speaker 2>that gives you all the files. So, like,

00:19:33.710 --> 00:19:35.870
<v Speaker 2>layer two might just have, you know, foo

00:19:35.870 --> 00:19:38.269
<v Speaker 2>dot t x t in that layer, and

00:19:38.269 --> 00:19:39.710
<v Speaker 2>the rest of it has the operating system,

00:19:39.710 --> 00:19:42.225
<v Speaker 2>the root file system. And then the config

00:19:42.305 --> 00:19:44.225
<v Speaker 2>is what would be passed to the runtime

00:19:44.225 --> 00:19:46.225
<v Speaker 2>to modify that container. So if you had

00:19:46.225 --> 00:19:48.145
<v Speaker 2>any kind of runtime constraints,

00:19:49.105 --> 00:19:49.985
<v Speaker 2>like like

00:19:50.145 --> 00:19:52.305
<v Speaker 2>privilege or CPU limitations,

00:19:52.880 --> 00:19:54.800
<v Speaker 2>any of those different things are gonna be

00:19:54.800 --> 00:19:56.080
<v Speaker 2>inside the configuration.

00:19:56.160 --> 00:19:57.680
<v Speaker 2>And so what the manifest does is it

00:19:57.680 --> 00:20:00.640
<v Speaker 2>puts those together in in this metadata layout

00:20:00.640 --> 00:20:02.240
<v Speaker 2>here that you see. So you you can

00:20:02.240 --> 00:20:03.680
<v Speaker 2>see in here we have the media type

00:20:03.680 --> 00:20:05.200
<v Speaker 2>that it's an image manifest,

00:20:05.280 --> 00:20:06.800
<v Speaker 2>and that's more of a generic container than

00:20:06.800 --> 00:20:08.815
<v Speaker 2>you might think. It's not just for containers.

00:20:08.815 --> 00:20:11.135
<v Speaker 2>It's like any OCI artifact can be used

00:20:11.135 --> 00:20:12.415
<v Speaker 2>and then bundled in there.

00:20:12.735 --> 00:20:15.135
<v Speaker 2>And then each one of those things, each

00:20:15.135 --> 00:20:16.815
<v Speaker 2>item in here, the configuration,

00:20:16.895 --> 00:20:18.735
<v Speaker 2>which you see that next block down below,

00:20:18.895 --> 00:20:21.055
<v Speaker 2>that has a media type of config, but

00:20:21.055 --> 00:20:22.460
<v Speaker 2>then it has a digest. So each of

00:20:22.460 --> 00:20:24.060
<v Speaker 2>these has a digest. It's just a unique

00:20:24.060 --> 00:20:24.700
<v Speaker 2>address

00:20:25.260 --> 00:20:26.940
<v Speaker 2>for all that content.

00:20:27.260 --> 00:20:29.420
<v Speaker 2>And then if we go down to layers,

00:20:29.420 --> 00:20:32.299
<v Speaker 2>that's gonna be what's actually stored in there.

00:20:32.780 --> 00:20:34.540
<v Speaker 2>And then annotations are actually what you'd see

00:20:34.540 --> 00:20:37.345
<v Speaker 2>in GitHub if you're pushing to, like, GHCR.

00:20:37.345 --> 00:20:38.545
<v Speaker 2>You can you can take it with different

00:20:38.545 --> 00:20:40.385
<v Speaker 2>stuff. Like, here's gonna be the URL for

00:20:40.385 --> 00:20:42.305
<v Speaker 2>the project and all that good stuff. So

00:20:42.305 --> 00:20:44.465
<v Speaker 2>that's kinda just like a a quick rundown

00:20:44.785 --> 00:20:47.745
<v Speaker 2>of what the OCI specification is. But if

00:20:47.745 --> 00:20:49.105
<v Speaker 2>we can adhere to this standard,

00:20:49.679 --> 00:20:52.080
<v Speaker 2>then we can push the models to any

00:20:52.080 --> 00:20:54.399
<v Speaker 2>registry. We don't need to have a special

00:20:56.159 --> 00:20:58.320
<v Speaker 2>models registry for it, and then it can

00:20:58.320 --> 00:21:00.320
<v Speaker 2>work straight into all of our clusters or

00:21:00.320 --> 00:21:03.105
<v Speaker 2>any of our existing CICD pipelines because we're

00:21:03.105 --> 00:21:04.385
<v Speaker 2>using the standard.

00:21:04.705 --> 00:21:06.225
<v Speaker 2>So go ahead, Faiman. Go to the next

00:21:06.225 --> 00:21:07.345
<v Speaker 2>slide, and I'll I'll dive in a little

00:21:07.345 --> 00:21:07.985
<v Speaker 2>bit more.

00:21:09.985 --> 00:21:11.665
<v Speaker 2>So I guess I should have waited for

00:21:11.665 --> 00:21:12.945
<v Speaker 2>this slide. But if we look at this,

00:21:12.945 --> 00:21:14.545
<v Speaker 2>this is a a deeper dive into all

00:21:14.545 --> 00:21:16.305
<v Speaker 2>these. So we can see down in the

00:21:16.305 --> 00:21:17.585
<v Speaker 2>layers, we're actually replacing.

00:21:17.980 --> 00:21:21.419
<v Speaker 2>Instead of using container layers and archiving compressing,

00:21:21.500 --> 00:21:23.980
<v Speaker 2>we can actually replace the layers with files

00:21:23.980 --> 00:21:24.779
<v Speaker 2>themselves.

00:21:25.100 --> 00:21:26.380
<v Speaker 2>So this would this is gonna be a

00:21:26.380 --> 00:21:27.899
<v Speaker 2>way how we can take those models and

00:21:27.899 --> 00:21:30.380
<v Speaker 2>put them into OCI by using files instead

00:21:30.380 --> 00:21:32.460
<v Speaker 2>of the the compressed layers themselves.

00:21:33.005 --> 00:21:34.525
<v Speaker 2>And you just see that underneath kind of

00:21:34.525 --> 00:21:36.365
<v Speaker 2>like the middle of the screen layers. You

00:21:36.365 --> 00:21:38.125
<v Speaker 2>see the media media type there that is

00:21:38.125 --> 00:21:40.045
<v Speaker 2>considered a layer, but then its reference is

00:21:40.045 --> 00:21:41.965
<v Speaker 2>gonna be the foo dot t x t

00:21:41.965 --> 00:21:43.565
<v Speaker 2>and then the bar t x t in

00:21:43.565 --> 00:21:44.525
<v Speaker 2>in the end there.

00:21:44.845 --> 00:21:46.045
<v Speaker 2>So this is how we can use the

00:21:46.045 --> 00:21:49.049
<v Speaker 2>image manifest to not only store container images

00:21:49.049 --> 00:21:50.970
<v Speaker 2>with their layers, but also files.

00:21:51.210 --> 00:21:53.450
<v Speaker 2>And that'll be more important, later on. Let's

00:21:53.450 --> 00:21:54.649
<v Speaker 2>go ahead and move to the next one.

00:21:56.809 --> 00:21:59.530
<v Speaker 2>So there's two ways to refer. So this

00:21:59.530 --> 00:22:01.129
<v Speaker 2>is a relatively recent,

00:22:01.610 --> 00:22:03.690
<v Speaker 2>development in the OCI standard before. It was

00:22:03.690 --> 00:22:05.585
<v Speaker 2>just we're gonna push a container. It has

00:22:05.585 --> 00:22:07.745
<v Speaker 2>a configuration. It has layers. We're gonna pull

00:22:07.745 --> 00:22:08.384
<v Speaker 2>it down,

00:22:08.945 --> 00:22:11.105
<v Speaker 2>extract them out so Docker can run it

00:22:11.105 --> 00:22:13.904
<v Speaker 2>and other run times can run it. But

00:22:14.705 --> 00:22:16.865
<v Speaker 2>with the the supply chain work with, like,

00:22:16.865 --> 00:22:18.225
<v Speaker 2>signatures and SBOMs,

00:22:18.409 --> 00:22:21.210
<v Speaker 2>it became important to be able to refer

00:22:21.210 --> 00:22:22.570
<v Speaker 2>to other artifacts.

00:22:22.649 --> 00:22:24.409
<v Speaker 2>So this is a signature. I'm just gonna

00:22:24.409 --> 00:22:26.169
<v Speaker 2>push it up to the registry. How do

00:22:26.169 --> 00:22:28.649
<v Speaker 2>I know that it ties into this container

00:22:28.649 --> 00:22:30.490
<v Speaker 2>image? How do I know it's related? So

00:22:30.490 --> 00:22:31.130
<v Speaker 2>referrers,

00:22:31.305 --> 00:22:32.985
<v Speaker 2>there's two different ways to refer. There's a

00:22:32.985 --> 00:22:34.985
<v Speaker 2>referrer's API, which is newer, and then there's

00:22:34.985 --> 00:22:36.185
<v Speaker 2>just a referrer.

00:22:36.585 --> 00:22:38.585
<v Speaker 2>And I'll go into both of those. So

00:22:38.585 --> 00:22:41.385
<v Speaker 2>we'll we'll go into referrer first. Referrer would

00:22:41.385 --> 00:22:43.705
<v Speaker 2>use a subject section, so you can see

00:22:43.705 --> 00:22:45.720
<v Speaker 2>that on the right side there, where it

00:22:45.720 --> 00:22:47.800
<v Speaker 2>says, okay, here are the subjects that are

00:22:47.800 --> 00:22:51.720
<v Speaker 2>referring to this other referring to this image

00:22:51.720 --> 00:22:53.639
<v Speaker 2>or this artifact.

00:22:53.720 --> 00:22:56.520
<v Speaker 2>And so then you can, with ORAZ Discover

00:22:56.520 --> 00:22:59.045
<v Speaker 2>and other tools, you can use those links

00:22:59.045 --> 00:23:01.684
<v Speaker 2>because those digests, unique addresses

00:23:01.685 --> 00:23:03.765
<v Speaker 2>between things that are pushed to the registry

00:23:03.765 --> 00:23:06.805
<v Speaker 2>can now have relationships built. The Referrer's API

00:23:06.805 --> 00:23:09.205
<v Speaker 2>lets basically gives you an API endpoint that

00:23:09.205 --> 00:23:11.205
<v Speaker 2>you can relate to, and it keeps the

00:23:11.205 --> 00:23:13.960
<v Speaker 2>manifest the same. There's no changes to your

00:23:13.960 --> 00:23:15.400
<v Speaker 2>actual manifest,

00:23:15.400 --> 00:23:17.240
<v Speaker 2>but through the referrer API, you can link

00:23:17.240 --> 00:23:19.160
<v Speaker 2>them. And you can see that metadata with

00:23:19.160 --> 00:23:20.279
<v Speaker 2>different network calls

00:23:20.600 --> 00:23:22.760
<v Speaker 2>to the referrer's API. So that that is

00:23:22.760 --> 00:23:24.840
<v Speaker 2>important for my part of the demo that

00:23:24.840 --> 00:23:27.255
<v Speaker 2>I'll be doing with the signature, which is

00:23:27.255 --> 00:23:28.854
<v Speaker 2>how can we relate

00:23:28.934 --> 00:23:32.854
<v Speaker 2>or show relationship between and connect OCI artifacts.

00:23:37.735 --> 00:23:39.495
<v Speaker 2>And then for the OCI

00:23:39.495 --> 00:23:41.890
<v Speaker 2>artifact format in the model so if we

00:23:41.890 --> 00:23:42.610
<v Speaker 2>look at

00:23:43.570 --> 00:23:45.410
<v Speaker 2>the container let's see. I'm just trying to

00:23:45.410 --> 00:23:46.610
<v Speaker 2>refresh on the slide.

00:23:47.090 --> 00:23:48.610
<v Speaker 2>And, Fengmin, if you have more contacts for

00:23:48.610 --> 00:23:49.330
<v Speaker 2>the slide,

00:23:49.890 --> 00:23:51.170
<v Speaker 2>let me know. But it looks like

00:23:51.890 --> 00:23:53.490
<v Speaker 2>yeah. I'll actually let Fengmin take on this

00:23:53.490 --> 00:23:55.010
<v Speaker 2>one because I think oh, this is more

00:23:55.010 --> 00:23:56.654
<v Speaker 2>relevant. Yeah. Go ahead and and take it

00:23:56.654 --> 00:23:57.934
<v Speaker 3>very well. Do you wanna go do

00:23:58.174 --> 00:23:59.454
<v Speaker 3>you wanna go this slide?

00:23:59.934 --> 00:24:01.615
<v Speaker 2>I'm

00:24:01.615 --> 00:24:03.774
<v Speaker 2>trying to recall here. Oh, this is just

00:24:03.774 --> 00:24:07.214
<v Speaker 2>the layout. Right? Yeah. So okay. Yes. Absolutely.

00:24:07.215 --> 00:24:09.054
<v Speaker 2>So on the top here, we can see

00:24:09.294 --> 00:24:11.160
<v Speaker 2>so if we were to pull down this

00:24:11.160 --> 00:24:13.000
<v Speaker 2>one makes much more sense to me. Thanks,

00:24:13.000 --> 00:24:14.040
<v Speaker 2>Raymond, for switching.

00:24:14.840 --> 00:24:17.320
<v Speaker 2>Yeah. I wanna compare. Like, there's actually not

00:24:17.320 --> 00:24:18.920
<v Speaker 2>a lot of difference between

00:24:20.040 --> 00:24:20.760
<v Speaker 2>the

00:24:21.480 --> 00:24:24.120
<v Speaker 2>model registry format and the OCI format. And

00:24:24.120 --> 00:24:26.215
<v Speaker 2>if you look at it, the the model

00:24:26.215 --> 00:24:28.934
<v Speaker 2>registry is actually using a version of OCI

00:24:28.934 --> 00:24:31.495
<v Speaker 2>in in this metadata here. It's just changing

00:24:31.495 --> 00:24:33.654
<v Speaker 2>the format how it is, enough that it

00:24:33.654 --> 00:24:34.134
<v Speaker 2>is

00:24:34.695 --> 00:24:36.695
<v Speaker 2>you can't just take an existing tool for

00:24:36.695 --> 00:24:38.934
<v Speaker 2>an OCI registry and use it. But we

00:24:38.934 --> 00:24:40.809
<v Speaker 2>can we'll walk through changing that in this

00:24:40.809 --> 00:24:42.330
<v Speaker 2>in this talk. But if we look at

00:24:42.330 --> 00:24:43.129
<v Speaker 2>the top part,

00:24:43.370 --> 00:24:45.370
<v Speaker 2>this would be the equivalent if you were

00:24:45.370 --> 00:24:47.690
<v Speaker 2>to point ORAS, the tool we're about to

00:24:47.690 --> 00:24:49.610
<v Speaker 2>talk to, and pull down the artifact, and

00:24:49.610 --> 00:24:50.970
<v Speaker 2>we're gonna pull down the files that it

00:24:50.970 --> 00:24:53.285
<v Speaker 2>has. We're gonna extract it out. So it's

00:24:53.285 --> 00:24:55.845
<v Speaker 2>not just some nebulous thing up up in

00:24:55.845 --> 00:24:56.644
<v Speaker 2>the registry.

00:24:56.805 --> 00:24:58.245
<v Speaker 2>This is actually what would happen if you

00:24:58.245 --> 00:24:59.684
<v Speaker 2>pulled it on on the cluster, and it's

00:24:59.684 --> 00:25:01.285
<v Speaker 2>gonna extract out and run it. So we

00:25:01.285 --> 00:25:02.565
<v Speaker 2>have the container

00:25:02.645 --> 00:25:05.044
<v Speaker 2>container decontext v one content,

00:25:05.125 --> 00:25:06.965
<v Speaker 2>then we have the blobs. The blobs then

00:25:06.965 --> 00:25:09.350
<v Speaker 2>have a SHA, and then inside that SHA

00:25:09.350 --> 00:25:12.230
<v Speaker 2>is gonna be the the digest itself minus

00:25:12.230 --> 00:25:14.070
<v Speaker 2>the SHA. And so those are gonna be

00:25:14.070 --> 00:25:15.990
<v Speaker 2>all the layers of that image. And if

00:25:15.990 --> 00:25:17.509
<v Speaker 2>we go into manifests,

00:25:17.669 --> 00:25:20.630
<v Speaker 2>there would be the overall manifest

00:25:20.355 --> 00:25:22.275
<v Speaker 2>that would have the config and then have

00:25:22.275 --> 00:25:24.595
<v Speaker 2>the layers inside of that that bundle it.

00:25:24.835 --> 00:25:26.674
<v Speaker 2>And one of those layers in there would

00:25:26.674 --> 00:25:29.235
<v Speaker 2>actually be the config JSON as well. And

00:25:29.235 --> 00:25:30.995
<v Speaker 2>then Ollama just it's a little bit different.

00:25:30.995 --> 00:25:32.915
<v Speaker 2>It actually splits out. It says, here's gonna

00:25:32.915 --> 00:25:34.195
<v Speaker 2>be your manifest directory

00:25:34.490 --> 00:25:37.130
<v Speaker 2>and for each one, so instead of each

00:25:37.370 --> 00:25:41.050
<v Speaker 2>artifact having the manifest with the layers, it

00:25:41.050 --> 00:25:43.370
<v Speaker 2>splits it out and says, here is the

00:25:43.370 --> 00:25:45.690
<v Speaker 2>manifest, and then here's all the blobs for

00:25:45.690 --> 00:25:47.929
<v Speaker 2>all the models. So they're disconnected.

00:25:47.930 --> 00:25:48.810
<v Speaker 2>The manifest

00:25:49.065 --> 00:25:51.304
<v Speaker 2>that has the configuration for it and then

00:25:51.304 --> 00:25:53.705
<v Speaker 2>the actual layer that holds the model

00:25:54.264 --> 00:25:55.864
<v Speaker 2>are in separate directories.

00:25:56.264 --> 00:25:56.825
<v Speaker 2>So

00:26:02.789 --> 00:26:04.950
<v Speaker 3>Okay, back to me. Yep.

00:26:05.990 --> 00:26:08.389
<v Speaker 3>So as Josh just shared,

00:26:09.029 --> 00:26:10.710
<v Speaker 3>the structure, the directory

00:26:11.269 --> 00:26:12.789
<v Speaker 3>structure between

00:26:13.110 --> 00:26:16.375
<v Speaker 3>AI model, just like the OLAMA model and

00:26:16.375 --> 00:26:18.934
<v Speaker 3>also the OCI image, you will find

00:26:19.175 --> 00:26:21.895
<v Speaker 3>they are quite similar because they both use

00:26:21.895 --> 00:26:23.655
<v Speaker 3>the content addressable

00:26:23.895 --> 00:26:26.855
<v Speaker 3>storage to store the AI models and

00:26:27.975 --> 00:26:29.575
<v Speaker 3>the OCI images in

00:26:31.910 --> 00:26:34.550
<v Speaker 3>AI model registry and also the OCR registry

00:26:34.550 --> 00:26:35.429
<v Speaker 3>respectively.

00:26:35.830 --> 00:26:36.630
<v Speaker 3>So why

00:26:37.190 --> 00:26:39.910
<v Speaker 3>do not unify them in a central place?

00:26:42.230 --> 00:26:44.070
<v Speaker 2>Can I add one thing to this, Feynman?

00:26:44.070 --> 00:26:44.470
<v Speaker 2>Do you mind?

00:26:45.195 --> 00:26:46.955
<v Speaker 3>Yeah. So it's It just popped in my

00:26:46.955 --> 00:26:48.794
<v Speaker 2>head a good analogy. So,

00:26:49.034 --> 00:26:51.195
<v Speaker 2>you know, back when containers started, we

00:26:51.835 --> 00:26:53.434
<v Speaker 2>there was, you know, big awareness of, like,

00:26:53.434 --> 00:26:55.515
<v Speaker 2>don't put your database inside the container image

00:26:55.515 --> 00:26:57.034
<v Speaker 2>mounted as a volume. Right?

00:26:57.990 --> 00:26:59.750
<v Speaker 2>It because it's it's large. Well, the same

00:26:59.750 --> 00:27:01.590
<v Speaker 2>thing's really true with models, and this is

00:27:01.590 --> 00:27:03.909
<v Speaker 2>what Fame is kinda setting up here is,

00:27:04.070 --> 00:27:05.510
<v Speaker 2>well, what if we could store

00:27:05.910 --> 00:27:08.230
<v Speaker 2>the model on the registry? That's cool. We

00:27:08.230 --> 00:27:09.750
<v Speaker 2>we talked about that. It could be on

00:27:09.750 --> 00:27:11.414
<v Speaker 2>a different place. But how do we get

00:27:11.414 --> 00:27:13.015
<v Speaker 2>that and use it inside of our container

00:27:13.015 --> 00:27:14.455
<v Speaker 2>image? It's not gonna be pulled down the

00:27:14.455 --> 00:27:15.975
<v Speaker 2>same way the container image is. It's to

00:27:15.975 --> 00:27:17.975
<v Speaker 2>actually start the thing that's running. But what

00:27:17.975 --> 00:27:19.974
<v Speaker 2>if you could take images

00:27:20.375 --> 00:27:22.215
<v Speaker 2>or things that are on a registry and

00:27:22.215 --> 00:27:23.894
<v Speaker 2>then mount them as volumes just like you

00:27:23.894 --> 00:27:26.000
<v Speaker 2>would a database? Because it's too large to

00:27:26.000 --> 00:27:29.039
<v Speaker 2>completely replicate and bake into each image.

00:27:29.600 --> 00:27:31.840
<v Speaker 2>That's that's exactly what this feature here sets

00:27:31.840 --> 00:27:33.280
<v Speaker 2>up. So I'll let Famey take over that,

00:27:33.280 --> 00:27:34.720
<v Speaker 2>but I just wanna draw that analogy. Like,

00:27:34.720 --> 00:27:36.559
<v Speaker 2>think of it as we had this big

00:27:36.559 --> 00:27:38.480
<v Speaker 2>database file that we wanna mount into our

00:27:38.480 --> 00:27:40.105
<v Speaker 2>container. We don't wanna bake it in and

00:27:40.105 --> 00:27:41.144
<v Speaker 2>copy it everywhere.

00:27:41.625 --> 00:27:43.225
<v Speaker 2>How can we leverage volume mounts for that?

00:27:43.225 --> 00:27:45.225
<v Speaker 2>And there's actually a new alpha feature

00:27:45.625 --> 00:27:47.225
<v Speaker 2>for the and I'll let Feyman take it

00:27:47.225 --> 00:27:48.905
<v Speaker 2>away, so I won't stall the thunder. But

00:27:48.905 --> 00:27:49.544
<v Speaker 2>go ahead.

00:27:50.905 --> 00:27:54.000
<v Speaker 3>That's a good point, Josh. So actually, if

00:27:54.000 --> 00:27:55.360
<v Speaker 3>you're looking at the

00:27:55.840 --> 00:27:58.000
<v Speaker 3>relatively new Kubernetes version,

00:27:58.240 --> 00:28:02.400
<v Speaker 3>for example, Kubernetes v1.31,

00:28:02.800 --> 00:28:05.440
<v Speaker 3>you will find there's a brand new feature,

00:28:05.440 --> 00:28:08.080
<v Speaker 3>an alpha feature introduced in this release, which

00:28:08.080 --> 00:28:10.234
<v Speaker 3>is the OCI image volume.

00:28:10.875 --> 00:28:14.635
<v Speaker 3>The Kubernetes community leveraged the benefits of OCI

00:28:14.635 --> 00:28:15.434
<v Speaker 3>standard

00:28:16.075 --> 00:28:17.034
<v Speaker 3>to make

00:28:17.835 --> 00:28:21.195
<v Speaker 3>the OCI image volume as an OCI artifact

00:28:21.275 --> 00:28:23.995
<v Speaker 3>so that Kubernetes users can mount

00:28:24.610 --> 00:28:25.889
<v Speaker 3>the model

00:28:25.970 --> 00:28:27.969
<v Speaker 3>directory, the file directory,

00:28:27.970 --> 00:28:30.690
<v Speaker 3>into a container and run it in a

00:28:30.690 --> 00:28:31.330
<v Speaker 3>pod.

00:28:31.809 --> 00:28:33.649
<v Speaker 3>That is very efficient, right?

00:28:34.370 --> 00:28:35.889
<v Speaker 3>And you can also take a look at

00:28:35.889 --> 00:28:38.370
<v Speaker 3>the Kubernetes blog post for details and its

00:28:38.370 --> 00:28:38.929
<v Speaker 3>use cases.

00:28:39.875 --> 00:28:42.275
<v Speaker 3>Looking at their blog post, the major use

00:28:42.275 --> 00:28:44.115
<v Speaker 3>case is to resolve the

00:28:44.355 --> 00:28:48.115
<v Speaker 3>AI model and machine learning model management

00:28:48.115 --> 00:28:50.355
<v Speaker 3>and also make users be able to run

00:28:50.355 --> 00:28:51.475
<v Speaker 3>it in

00:28:51.955 --> 00:28:52.435
<v Speaker 3>a container.

00:28:56.640 --> 00:28:59.440
<v Speaker 3>So how can we achieve that? So basically,

00:28:59.440 --> 00:29:02.080
<v Speaker 3>you will need to first push your

00:29:02.560 --> 00:29:04.320
<v Speaker 3>AI model files

00:29:04.800 --> 00:29:07.360
<v Speaker 3>into a container registry or OCR registry.

00:29:08.125 --> 00:29:08.764
<v Speaker 3>So

00:29:09.085 --> 00:29:11.164
<v Speaker 3>to achieve this, we will need

00:29:11.645 --> 00:29:13.085
<v Speaker 3>an artifact tool

00:29:13.485 --> 00:29:15.164
<v Speaker 3>to push your

00:29:16.365 --> 00:29:17.244
<v Speaker 3>from

00:29:18.684 --> 00:29:21.485
<v Speaker 3>local environment to an OCR registry.

00:29:22.940 --> 00:29:25.580
<v Speaker 3>The answer will be ORS. ORS is a

00:29:25.580 --> 00:29:26.700
<v Speaker 3>fully functioning

00:29:26.940 --> 00:29:28.220
<v Speaker 3>OCR management

00:29:28.300 --> 00:29:30.620
<v Speaker 3>tool, and it can be used with any

00:29:30.620 --> 00:29:31.820
<v Speaker 3>OCR registries.

00:29:32.300 --> 00:29:33.100
<v Speaker 3>Today,

00:29:33.340 --> 00:29:35.580
<v Speaker 3>most of the popular Container Registry

00:29:35.740 --> 00:29:37.100
<v Speaker 3>has supported

00:29:36.915 --> 00:29:38.115
<v Speaker 3>OCI Artifact,

00:29:38.275 --> 00:29:39.555
<v Speaker 3>OCI 1.1,

00:29:39.555 --> 00:29:40.674
<v Speaker 3>and also can

00:29:42.595 --> 00:29:45.635
<v Speaker 3>be compatible with ORAs tool. So that means

00:29:45.635 --> 00:29:48.115
<v Speaker 3>you can use ORAs to distribute

00:29:48.195 --> 00:29:49.155
<v Speaker 3>any kinds of

00:29:49.850 --> 00:29:54.330
<v Speaker 3>arbitrary files and AI models across different registries,

00:29:54.410 --> 00:29:55.049
<v Speaker 3>including

00:29:55.610 --> 00:29:57.289
<v Speaker 3>Azure Container Registry,

00:29:57.770 --> 00:29:58.730
<v Speaker 3>Elastic

00:29:59.050 --> 00:30:00.409
<v Speaker 3>AWS ECR,

00:30:00.810 --> 00:30:01.929
<v Speaker 3>Docker Hub,

00:30:02.170 --> 00:30:02.570
<v Speaker 3>Harbor,

00:30:03.795 --> 00:30:04.995
<v Speaker 3>and DOT.

00:30:06.915 --> 00:30:09.875
<v Speaker 3>ORIS is also a CNCF sandbox project.

00:30:10.115 --> 00:30:12.755
<v Speaker 3>You can use it in your on premise

00:30:12.755 --> 00:30:13.555
<v Speaker 3>environment.

00:30:13.955 --> 00:30:17.075
<v Speaker 3>And it is also fully OCI standard compliant.

00:30:18.510 --> 00:30:21.710
<v Speaker 3>We provide CI command line tools and

00:30:22.430 --> 00:30:24.990
<v Speaker 3>libraries in different programming languages.

00:30:27.390 --> 00:30:29.870
<v Speaker 3>And also, we have a very strong community

00:30:29.985 --> 00:30:31.504
<v Speaker 3>back this project.

00:30:31.665 --> 00:30:34.065
<v Speaker 3>And we have the Aura CLI

00:30:34.304 --> 00:30:35.345
<v Speaker 3>supported by

00:30:35.665 --> 00:30:36.624
<v Speaker 3>Microsoft,

00:30:36.865 --> 00:30:38.784
<v Speaker 3>Red Hat, and several

00:30:39.265 --> 00:30:40.784
<v Speaker 3>community organizations.

00:30:40.945 --> 00:30:44.385
<v Speaker 3>We have Aura's Go, Aura's Python, Aura's.net.

00:30:44.800 --> 00:30:46.880
<v Speaker 3>And recently, we have Aura's

00:30:46.880 --> 00:30:48.159
<v Speaker 3>Java SDK.

00:30:48.960 --> 00:30:51.040
<v Speaker 3>You can go to the Aura's website for

00:30:51.040 --> 00:30:54.400
<v Speaker 3>more details. And also, you can install Aura

00:30:54.400 --> 00:30:55.440
<v Speaker 3>CLI

00:30:56.320 --> 00:30:57.680
<v Speaker 3>via different channels.

00:31:00.985 --> 00:31:02.265
<v Speaker 3>Okay, go ahead.

00:31:04.265 --> 00:31:06.665
<v Speaker 3>So as we can see, we have a

00:31:06.665 --> 00:31:09.225
<v Speaker 3>lot of open source projects and

00:31:09.785 --> 00:31:10.665
<v Speaker 3>registries

00:31:10.745 --> 00:31:13.385
<v Speaker 3>embrace AURs and OCI artifacts.

00:31:13.720 --> 00:31:15.320
<v Speaker 3>So let's say, for example,

00:31:15.960 --> 00:31:17.960
<v Speaker 3>Helm has integrated

00:31:18.200 --> 00:31:19.080
<v Speaker 3>auras

00:31:19.080 --> 00:31:21.160
<v Speaker 3>since they are Helm V2.

00:31:21.240 --> 00:31:22.200
<v Speaker 3>And also

00:31:23.480 --> 00:31:26.280
<v Speaker 3>a lot of security projects like Falco

00:31:27.274 --> 00:31:28.554
<v Speaker 3>and policy

00:31:29.115 --> 00:31:29.914
<v Speaker 3>notation.

00:31:32.475 --> 00:31:36.154
<v Speaker 3>They leverage ORANS to authenticate with the registries

00:31:36.154 --> 00:31:38.474
<v Speaker 3>and also manage OCI artifacts

00:31:38.715 --> 00:31:41.914
<v Speaker 3>across container registries and their local file system.

00:31:43.540 --> 00:31:45.860
<v Speaker 3>And as I just shared, most of the

00:31:45.860 --> 00:31:47.060
<v Speaker 3>popular container

00:31:47.860 --> 00:31:48.660
<v Speaker 3>registry

00:31:48.820 --> 00:31:52.260
<v Speaker 3>have been compatible with OCI artifacts.

00:31:52.340 --> 00:31:54.820
<v Speaker 3>That means you can have very good portability

00:31:55.065 --> 00:31:57.544
<v Speaker 3>for your AI models if you install your

00:31:57.544 --> 00:31:59.624
<v Speaker 3>AI models in the OSA registries.

00:32:01.544 --> 00:32:04.264
<v Speaker 3>So here's the list of installing auras

00:32:04.345 --> 00:32:05.704
<v Speaker 3>from different channel.

00:32:05.865 --> 00:32:08.105
<v Speaker 3>On Windows, you can use Wingate.

00:32:08.105 --> 00:32:10.024
<v Speaker 3>On MacOS, you can just use

00:32:10.510 --> 00:32:11.950
<v Speaker 3>Brewing Store Auras.

00:32:12.030 --> 00:32:13.309
<v Speaker 3>That is quite

00:32:13.710 --> 00:32:14.989
<v Speaker 3>straightforward and

00:32:15.150 --> 00:32:16.909
<v Speaker 3>very easy to set up.

00:32:20.110 --> 00:32:23.070
<v Speaker 3>Okay. Let's jump to demo. Talking is cheap,

00:32:23.070 --> 00:32:23.309
<v Speaker 3>right?

00:32:23.965 --> 00:32:26.205
<v Speaker 3>So we can have a live demo right

00:32:26.205 --> 00:32:28.365
<v Speaker 3>now. And I also have a

00:32:29.965 --> 00:32:32.765
<v Speaker 3>step by step hands on article that can

00:32:32.765 --> 00:32:34.205
<v Speaker 3>be shared after

00:32:34.365 --> 00:32:35.325
<v Speaker 3>this session.

00:32:35.965 --> 00:32:37.965
<v Speaker 3>So this is the hands on

00:32:38.765 --> 00:32:39.565
<v Speaker 3>labs

00:32:40.330 --> 00:32:40.969
<v Speaker 3>that

00:32:42.250 --> 00:32:43.769
<v Speaker 3>I'm going to demonstrate.

00:32:44.889 --> 00:32:47.210
<v Speaker 3>As a whole, we will share how to

00:32:47.210 --> 00:32:48.009
<v Speaker 3>package

00:32:49.450 --> 00:32:52.169
<v Speaker 3>an LIM model. I use Olama model as

00:32:52.169 --> 00:32:52.889
<v Speaker 3>a sample

00:32:53.315 --> 00:32:54.914
<v Speaker 3>model and package

00:32:55.075 --> 00:32:56.994
<v Speaker 3>it as an OCR artifact.

00:32:57.635 --> 00:32:58.754
<v Speaker 3>Then I will

00:32:59.155 --> 00:33:00.034
<v Speaker 3>use

00:33:01.075 --> 00:33:02.674
<v Speaker 3>auras to push

00:33:04.035 --> 00:33:06.929
<v Speaker 3>the AI model into an OCI registry.

00:33:08.850 --> 00:33:10.529
<v Speaker 3>And next, I create

00:33:11.330 --> 00:33:14.290
<v Speaker 3>a PV and PVC to mount the OCI

00:33:14.290 --> 00:33:17.250
<v Speaker 3>artifact and some volume into Kubernetes cluster.

00:33:18.465 --> 00:33:20.705
<v Speaker 3>This is just the latest alpha feature in

00:33:20.705 --> 00:33:21.585
<v Speaker 3>Kubernetes.

00:33:22.385 --> 00:33:25.184
<v Speaker 3>And finally, I'm going to deploy

00:33:25.265 --> 00:33:27.665
<v Speaker 3>the AI model in your pod and mount

00:33:27.665 --> 00:33:30.304
<v Speaker 3>the model from the OCI registry and also

00:33:30.304 --> 00:33:31.744
<v Speaker 3>run the AI

00:33:32.065 --> 00:33:33.424
<v Speaker 3>model inside the container.

00:33:35.090 --> 00:33:38.050
<v Speaker 3>The second demo will cover how to sign

00:33:38.050 --> 00:33:41.250
<v Speaker 3>the verified AI models locally and also in

00:33:41.250 --> 00:33:42.610
<v Speaker 3>the Container Registry.

00:33:44.290 --> 00:33:46.210
<v Speaker 3>So this is the high level

00:33:46.654 --> 00:33:47.455
<v Speaker 3>process

00:33:47.455 --> 00:33:50.334
<v Speaker 3>for this demo. So let's jump to

00:33:52.414 --> 00:33:52.974
<v Speaker 3>the

00:33:54.014 --> 00:33:54.894
<v Speaker 3>terminal.

00:33:54.894 --> 00:33:56.975
<v Speaker 3>And I'm going to show you the hands

00:33:56.975 --> 00:33:57.615
<v Speaker 3>on steps.

00:34:07.700 --> 00:34:08.340
<v Speaker 3>Okay,

00:34:08.739 --> 00:34:09.780
<v Speaker 3>first of all,

00:34:10.820 --> 00:34:13.940
<v Speaker 3>assume you already have the tool to manage

00:34:13.940 --> 00:34:17.204
<v Speaker 3>your AI models. Here, I'm using the OLAMA,

00:34:17.204 --> 00:34:18.565
<v Speaker 3>one of the most popular

00:34:18.645 --> 00:34:21.125
<v Speaker 3>AI model management tool.

00:34:21.284 --> 00:34:23.444
<v Speaker 3>So actually, I already have OLAMA

00:34:23.444 --> 00:34:24.645
<v Speaker 3>in my local.

00:34:24.885 --> 00:34:25.445
<v Speaker 3>And

00:34:26.885 --> 00:34:28.484
<v Speaker 3>if I run OLAMA list,

00:34:31.080 --> 00:34:34.200
<v Speaker 3>I already have the tiny LAMA model put

00:34:34.200 --> 00:34:36.120
<v Speaker 3>in my local file system.

00:34:36.520 --> 00:34:39.400
<v Speaker 3>Then I'm going to push these

00:34:39.480 --> 00:34:40.920
<v Speaker 3>OLAMA models

00:34:41.480 --> 00:34:42.840
<v Speaker 3>into a

00:34:43.094 --> 00:34:44.455
<v Speaker 3>OCR registry.

00:34:44.775 --> 00:34:45.655
<v Speaker 3>So here,

00:34:46.295 --> 00:34:49.015
<v Speaker 3>if you look into the models directory,

00:34:52.375 --> 00:34:53.415
<v Speaker 3>you'll find

00:34:53.815 --> 00:34:54.935
<v Speaker 3>there are two

00:34:55.175 --> 00:34:56.054
<v Speaker 3>directories.

00:34:56.135 --> 00:34:58.855
<v Speaker 3>One is blobs. Another one is manifest.

00:34:59.310 --> 00:35:02.590
<v Speaker 3>This is the structure that Josh just shared,

00:35:02.910 --> 00:35:04.990
<v Speaker 3>which is quite similar to OCI images.

00:35:05.390 --> 00:35:08.270
<v Speaker 3>If we dig into the blobs folder,

00:35:12.110 --> 00:35:14.430
<v Speaker 3>you'll find it has a bunch of

00:35:15.095 --> 00:35:17.575
<v Speaker 3>model layers, which is similar to the OCI

00:35:17.575 --> 00:35:18.535
<v Speaker 3>image layers

00:35:18.615 --> 00:35:21.015
<v Speaker 3>in the blobs. And if you're looking

00:35:21.255 --> 00:35:22.694
<v Speaker 3>at the manifest,

00:35:22.694 --> 00:35:23.815
<v Speaker 3>it has a

00:35:24.855 --> 00:35:27.575
<v Speaker 3>AI model manifest inside the manifest folder.

00:35:37.740 --> 00:35:39.180
<v Speaker 3>So here are

00:35:39.420 --> 00:35:40.860
<v Speaker 3>the raw files that

00:35:41.580 --> 00:35:42.300
<v Speaker 3>Ollama

00:35:42.465 --> 00:35:45.105
<v Speaker 3>client tool can be used to run an

00:35:45.105 --> 00:35:46.065
<v Speaker 3>AI model

00:35:46.225 --> 00:35:49.025
<v Speaker 3>in a file system, right? So the goal

00:35:49.025 --> 00:35:51.025
<v Speaker 3>here is to package

00:35:51.105 --> 00:35:51.985
<v Speaker 3>the whole

00:35:52.705 --> 00:35:54.545
<v Speaker 3>models folder into

00:35:55.105 --> 00:35:57.985
<v Speaker 3>an OCI artifact and store it in a

00:35:58.785 --> 00:35:59.880
<v Speaker 3>container, in a container image.

00:36:01.720 --> 00:36:04.200
<v Speaker 3>So here we can use Auras tool.

00:36:04.520 --> 00:36:06.200
<v Speaker 3>I installed Auras

00:36:06.200 --> 00:36:08.040
<v Speaker 3>v1.2.

00:36:08.040 --> 00:36:10.359
<v Speaker 3>This is the latest stable version in the

00:36:10.359 --> 00:36:13.535
<v Speaker 3>community. So we just need to use Aura's

00:36:13.535 --> 00:36:14.575
<v Speaker 3>push command

00:36:15.055 --> 00:36:16.415
<v Speaker 3>and specify

00:36:16.575 --> 00:36:19.135
<v Speaker 3>which directory you want to package

00:36:19.214 --> 00:36:21.295
<v Speaker 3>and push to the remote registry.

00:36:21.454 --> 00:36:22.895
<v Speaker 3>So here, we specify

00:36:23.470 --> 00:36:24.590
<v Speaker 3>the registry.

00:36:24.590 --> 00:36:27.150
<v Speaker 3>I'm just using the ACR as a sample

00:36:27.150 --> 00:36:29.630
<v Speaker 3>registry, but you can use any registry

00:36:29.870 --> 00:36:31.150
<v Speaker 3>on your demand.

00:36:32.030 --> 00:36:34.190
<v Speaker 3>And then you can specify

00:36:35.390 --> 00:36:38.110
<v Speaker 3>the target directory you want to package.

00:36:38.475 --> 00:36:41.995
<v Speaker 3>So here, as my model is located in

00:36:42.075 --> 00:36:43.675
<v Speaker 3>the OLAMA folder,

00:36:43.675 --> 00:36:46.795
<v Speaker 3>so I just specify the target directory here.

00:36:47.035 --> 00:36:49.915
<v Speaker 3>And you can also specify the artifact type

00:36:50.075 --> 00:36:52.740
<v Speaker 3>for your AI model. So here I just

00:36:52.740 --> 00:36:54.900
<v Speaker 3>use a sample artifact type here.

00:36:56.580 --> 00:36:57.860
<v Speaker 3>So if I

00:36:59.300 --> 00:37:00.740
<v Speaker 3>run this command,

00:37:01.380 --> 00:37:02.740
<v Speaker 3>I should use

00:37:04.660 --> 00:37:05.860
<v Speaker 3>a relative

00:37:05.860 --> 00:37:06.580
<v Speaker 3>file path.

00:37:12.075 --> 00:37:13.835
<v Speaker 3>So I just specify

00:37:14.555 --> 00:37:15.515
<v Speaker 3>V2

00:37:15.994 --> 00:37:17.595
<v Speaker 3>and models

00:37:17.595 --> 00:37:20.315
<v Speaker 3>because I'm already in the olamas folder.

00:37:28.100 --> 00:37:29.060
<v Speaker 3>So here,

00:37:29.460 --> 00:37:31.940
<v Speaker 3>OLAS is going to package

00:37:32.100 --> 00:37:34.420
<v Speaker 3>the directory into a TAR file

00:37:34.740 --> 00:37:35.460
<v Speaker 3>and

00:37:36.420 --> 00:37:37.140
<v Speaker 3>make it

00:37:37.540 --> 00:37:38.580
<v Speaker 3>containerized

00:37:38.785 --> 00:37:40.305
<v Speaker 3>in OCI artifact.

00:37:40.785 --> 00:37:43.025
<v Speaker 3>So if we run this command,

00:37:44.705 --> 00:37:45.985
<v Speaker 3>ORAS will be

00:37:46.625 --> 00:37:47.345
<v Speaker 3>studied,

00:37:47.825 --> 00:37:48.705
<v Speaker 3>packaged,

00:37:49.185 --> 00:37:49.905
<v Speaker 3>and

00:37:51.920 --> 00:37:54.320
<v Speaker 3>archive the folder into an

00:37:54.559 --> 00:37:56.720
<v Speaker 3>TAR file and make it as a layer

00:37:56.720 --> 00:37:58.080
<v Speaker 3>of an OCR artifact.

00:37:58.240 --> 00:37:59.599
<v Speaker 3>It may take some

00:37:59.760 --> 00:38:01.839
<v Speaker 3>time to execute the command.

00:38:05.795 --> 00:38:07.875
<v Speaker 2>As someone who tried to build that tooling

00:38:07.875 --> 00:38:09.795
<v Speaker 2>on their own, I could definitely appreciate

00:38:10.755 --> 00:38:14.115
<v Speaker 2>archiving it, zipping it up, creating the metadata

00:38:14.115 --> 00:38:15.315
<v Speaker 2>layout for it.

00:38:15.635 --> 00:38:17.155
<v Speaker 2>So I'm I'm a big fan of WebRTC

00:38:17.155 --> 00:38:19.235
<v Speaker 2>for a number of things, even

00:38:20.060 --> 00:38:22.860
<v Speaker 2>WebAssembly components. I actually hooked into that

00:38:23.820 --> 00:38:24.860
<v Speaker 2>library as well.

00:38:26.860 --> 00:38:27.900
<v Speaker 3>Yeah.

00:38:28.940 --> 00:38:31.340
<v Speaker 3>I remember Josh also has a nice demo

00:38:31.340 --> 00:38:34.620
<v Speaker 3>to demonstrate how to package WebAssembly modules

00:38:35.065 --> 00:38:37.385
<v Speaker 3>as an OCI effect and store it in

00:38:37.385 --> 00:38:38.665
<v Speaker 3>OCI registry.

00:38:40.425 --> 00:38:43.065
<v Speaker 3>This is similar to how we

00:38:43.865 --> 00:38:47.305
<v Speaker 3>distribute and package AI models. So here, you'll

00:38:47.305 --> 00:38:48.105
<v Speaker 3>find

00:38:48.849 --> 00:38:51.010
<v Speaker 3>the AI model has been packaged

00:38:52.130 --> 00:38:54.609
<v Speaker 3>into a TAR file, into a layer of

00:38:54.609 --> 00:38:57.410
<v Speaker 3>an OCI artifact. So we can look at

00:38:57.410 --> 00:38:57.970
<v Speaker 3>the

00:38:58.210 --> 00:38:59.570
<v Speaker 3>registry site.

00:38:59.730 --> 00:39:01.890
<v Speaker 3>And you will see there's repository

00:39:03.375 --> 00:39:05.375
<v Speaker 3>named Olama TinyLlama.

00:39:05.535 --> 00:39:07.695
<v Speaker 3>And if you're looking at the tags, this

00:39:07.695 --> 00:39:08.495
<v Speaker 3>is the

00:39:09.455 --> 00:39:11.375
<v Speaker 3>tag the V2 is the tag that we

00:39:11.375 --> 00:39:13.215
<v Speaker 3>just pushed to the OC registry.

00:39:14.815 --> 00:39:15.855
<v Speaker 3>So if we

00:39:16.420 --> 00:39:19.220
<v Speaker 3>zoom in and look at the layers,

00:39:19.300 --> 00:39:22.900
<v Speaker 3>you'll find there's a specific layer to store

00:39:22.900 --> 00:39:23.860
<v Speaker 3>the AI model.

00:39:32.755 --> 00:39:34.115
<v Speaker 3>It would just be a cool way to

00:39:34.115 --> 00:39:35.795
<v Speaker 2>show off some of that. This is what

00:39:35.795 --> 00:39:37.234
<v Speaker 2>I end up doing that keeps me out

00:39:37.234 --> 00:39:39.395
<v Speaker 2>of the the browser. I'm I'm a terminal

00:39:39.395 --> 00:39:41.954
<v Speaker 2>junkie personally, so I like if I can

00:39:41.954 --> 00:39:43.474
<v Speaker 2>get out of away from a browser, I

00:39:43.474 --> 00:39:45.770
<v Speaker 2>can. So here, this is the the ORS

00:39:45.770 --> 00:39:47.610
<v Speaker 2>command that you can use to to display

00:39:47.610 --> 00:39:49.050
<v Speaker 2>your manifest information.

00:39:49.610 --> 00:39:51.370
<v Speaker 3>Correct. Yeah. There you go. We can have

00:39:51.370 --> 00:39:54.570
<v Speaker 3>the same JSON format on terminal,

00:39:55.050 --> 00:39:57.290
<v Speaker 3>and we can use ORS manifest fetch to

00:39:57.290 --> 00:39:57.930
<v Speaker 3>fetch

00:39:58.715 --> 00:40:01.595
<v Speaker 3>an OCI artifact from the Container Registry.

00:40:01.595 --> 00:40:04.475
<v Speaker 3>And it will be the similar view with

00:40:04.475 --> 00:40:06.315
<v Speaker 3>the Container Registry portal.

00:40:07.595 --> 00:40:09.915
<v Speaker 3>Okay, I think we finished the first step,

00:40:09.915 --> 00:40:11.515
<v Speaker 3>which is to push the

00:40:11.859 --> 00:40:14.020
<v Speaker 3>AI model as an OCR effect to the

00:40:14.020 --> 00:40:14.740
<v Speaker 3>registry.

00:40:15.060 --> 00:40:16.980
<v Speaker 3>And then we're

00:40:16.980 --> 00:40:18.580
<v Speaker 3>going to create

00:40:19.060 --> 00:40:20.820
<v Speaker 3>the persistent volumes

00:40:20.820 --> 00:40:23.780
<v Speaker 3>and also a piece of the persistent volume

00:40:23.780 --> 00:40:24.580
<v Speaker 3>claim

00:40:24.580 --> 00:40:26.660
<v Speaker 3>to mount the AI models

00:40:27.015 --> 00:40:27.815
<v Speaker 3>into

00:40:28.135 --> 00:40:30.295
<v Speaker 3>a container and run it into a pod.

00:40:31.494 --> 00:40:33.015
<v Speaker 3>Here, you will need to

00:40:33.335 --> 00:40:34.135
<v Speaker 3>create

00:40:34.615 --> 00:40:36.695
<v Speaker 3>two YAML files for your

00:40:37.734 --> 00:40:40.800
<v Speaker 3>persistent volumes and persistent volume claim, which is

00:40:40.800 --> 00:40:42.000
<v Speaker 3>PV and PVC.

00:40:42.640 --> 00:40:43.280
<v Speaker 3>And

00:40:43.440 --> 00:40:46.400
<v Speaker 3>to save time, I already created those two

00:40:46.960 --> 00:40:47.840
<v Speaker 3>storage

00:40:48.080 --> 00:40:48.880
<v Speaker 3>stuffs.

00:40:48.880 --> 00:40:50.240
<v Speaker 3>The first one is

00:40:51.440 --> 00:40:52.800
<v Speaker 3>all Lama models PV.

00:40:54.015 --> 00:40:56.255
<v Speaker 3>Here you have to specify

00:40:56.255 --> 00:40:58.815
<v Speaker 3>your volume handle here, which is your

00:40:59.295 --> 00:41:00.415
<v Speaker 3>image reference.

00:41:01.135 --> 00:41:03.535
<v Speaker 3>We can just paste the image reference from

00:41:03.535 --> 00:41:05.055
<v Speaker 3>your Container Registry

00:41:05.135 --> 00:41:07.920
<v Speaker 3>and put it into the property

00:41:07.920 --> 00:41:09.920
<v Speaker 3>value volume handle here.

00:41:10.640 --> 00:41:11.600
<v Speaker 3>And next,

00:41:14.000 --> 00:41:17.280
<v Speaker 3>we can create a PVC to consume the

00:41:17.280 --> 00:41:18.000
<v Speaker 3>PV.

00:41:18.240 --> 00:41:20.320
<v Speaker 3>And here you just need to specify

00:41:20.480 --> 00:41:22.640
<v Speaker 3>which PV you want to

00:41:23.255 --> 00:41:25.255
<v Speaker 3>consume in this PVC.

00:41:26.535 --> 00:41:29.095
<v Speaker 3>And let me show you how it looks

00:41:29.095 --> 00:41:31.335
<v Speaker 3>like on my Kubernetes cluster.

00:41:33.095 --> 00:41:36.455
<v Speaker 3>So here I have a Olama models PV

00:41:36.455 --> 00:41:37.335
<v Speaker 3>created

00:41:37.335 --> 00:41:38.615
<v Speaker 3>on my local file system.

00:41:39.710 --> 00:41:41.869
<v Speaker 3>And I have a PVC

00:41:42.510 --> 00:41:44.350
<v Speaker 3>that consumes this PV.

00:41:45.869 --> 00:41:47.390
<v Speaker 3>And looking at the status,

00:41:50.030 --> 00:41:52.270
<v Speaker 3>the PVC has been bounded

00:41:53.355 --> 00:41:56.395
<v Speaker 3>with the PV. That means we can use

00:41:56.395 --> 00:41:58.235
<v Speaker 3>the PVC to

00:41:58.395 --> 00:42:00.075
<v Speaker 3>mount the OCI

00:42:00.155 --> 00:42:01.195
<v Speaker 3>image volume.

00:42:02.795 --> 00:42:04.875
<v Speaker 3>I have also defined

00:42:05.675 --> 00:42:07.650
<v Speaker 3>the part for our

00:42:07.890 --> 00:42:09.010
<v Speaker 3>AI model.

00:42:09.329 --> 00:42:11.890
<v Speaker 3>So here you can just use this piece

00:42:11.890 --> 00:42:14.850
<v Speaker 3>of YAML file to craft

00:42:15.730 --> 00:42:16.530
<v Speaker 3>your

00:42:16.770 --> 00:42:17.650
<v Speaker 3>part.

00:42:18.770 --> 00:42:19.810
<v Speaker 3>So here

00:42:19.965 --> 00:42:21.965
<v Speaker 3>I have already created this YAML file on

00:42:21.965 --> 00:42:24.685
<v Speaker 3>my local. I just need to apply it.

00:42:33.740 --> 00:42:36.940
<v Speaker 3>Okay, it might be another folder.

00:42:37.420 --> 00:42:38.380
<v Speaker 3>Oh, here.

00:42:39.740 --> 00:42:41.260
<v Speaker 3>I just need to apply

00:42:41.340 --> 00:42:44.780
<v Speaker 3>this Ollama pod YAML and create this pod

00:42:44.780 --> 00:42:47.500
<v Speaker 3>on my Kubernetes cluster. So by default,

00:42:48.444 --> 00:42:50.365
<v Speaker 3>the image volume will be mounted

00:42:50.605 --> 00:42:52.125
<v Speaker 3>into your specified

00:42:52.845 --> 00:42:54.685
<v Speaker 3>path in the container.

00:42:54.925 --> 00:42:56.685
<v Speaker 3>So I just need to apply

00:42:56.845 --> 00:42:57.965
<v Speaker 3>that part

00:42:58.765 --> 00:43:02.684
<v Speaker 3>and among the specified PVN PVC in that

00:43:02.684 --> 00:43:03.005
<v Speaker 3>part.

00:43:19.715 --> 00:43:21.715
<v Speaker 3>Okay. There might be something broken.

00:43:21.795 --> 00:43:22.835
<v Speaker 3>But ideally,

00:43:22.915 --> 00:43:23.555
<v Speaker 3>we should

00:43:25.875 --> 00:43:26.995
<v Speaker 3>have the AI

00:43:27.635 --> 00:43:30.915
<v Speaker 3>model as an artifact running as a part

00:43:30.915 --> 00:43:32.195
<v Speaker 3>in our local file system.

00:43:34.410 --> 00:43:36.970
<v Speaker 3>Maybe I can troubleshoot later, but there might

00:43:36.970 --> 00:43:37.850
<v Speaker 3>be some

00:43:38.170 --> 00:43:38.970
<v Speaker 3>configuration

00:43:38.970 --> 00:43:40.170
<v Speaker 3>problem here.

00:43:40.730 --> 00:43:41.530
<v Speaker 3>Let me check.

00:43:48.095 --> 00:43:50.815
<v Speaker 3>Oh, there might be some disconnection

00:43:50.815 --> 00:43:54.734
<v Speaker 3>of my Kubernetes API server because my kubectl

00:43:54.815 --> 00:43:56.655
<v Speaker 3>is broken. But I

00:43:57.934 --> 00:43:59.295
<v Speaker 3>can troubleshoot it later.

00:44:01.269 --> 00:44:03.829
<v Speaker 3>So the idea here is to

00:44:04.230 --> 00:44:07.910
<v Speaker 3>run the AI model as an OCR artifact

00:44:07.910 --> 00:44:09.510
<v Speaker 3>and mount the image,

00:44:10.069 --> 00:44:12.869
<v Speaker 3>the OCR image, into an image volume

00:44:13.175 --> 00:44:15.255
<v Speaker 3>so that it can be run as a

00:44:15.255 --> 00:44:17.575
<v Speaker 3>normal pod in Kubernetes cluster.

00:44:18.295 --> 00:44:20.695
<v Speaker 3>And we can use kubectl

00:44:20.695 --> 00:44:21.975
<v Speaker 3>sq into

00:44:23.175 --> 00:44:24.135
<v Speaker 3>the container

00:44:24.135 --> 00:44:27.175
<v Speaker 3>and run the OLAMA list and also OLAMA

00:44:27.175 --> 00:44:29.640
<v Speaker 3>run the tiny OLAMA

00:44:30.040 --> 00:44:33.080
<v Speaker 3>to use the OLAMA model in your container.

00:44:37.400 --> 00:44:40.119
<v Speaker 3>But unfortunately, the demo is broken, and I

00:44:40.119 --> 00:44:42.065
<v Speaker 3>will provide a recording

00:44:43.424 --> 00:44:45.905
<v Speaker 3>after this session and also share the

00:44:46.464 --> 00:44:47.265
<v Speaker 3>script

00:44:47.744 --> 00:44:48.945
<v Speaker 3>with all of you.

00:44:50.944 --> 00:44:52.145
<v Speaker 3>I will hand it over to

00:44:52.800 --> 00:44:54.720
<v Speaker 3>Josh. A question before we move over to

00:44:54.720 --> 00:44:56.720
<v Speaker 3>Josh. Yeah. Yeah. Yeah. Shoot. So

00:44:57.520 --> 00:45:00.160
<v Speaker 1>hack the Gibson, great username, by the way,

00:45:00.160 --> 00:45:01.920
<v Speaker 1>dropped some of the questions in, you know,

00:45:01.920 --> 00:45:04.000
<v Speaker 1>when you use the RRAS commands, you push

00:45:04.000 --> 00:45:05.440
<v Speaker 1>the entire model's directory.

00:45:06.645 --> 00:45:08.725
<v Speaker 1>Mhmm. I'm assuming it's pushing all the models

00:45:08.725 --> 00:45:11.285
<v Speaker 1>that are downloaded into a single OCI artifact,

00:45:11.605 --> 00:45:12.885
<v Speaker 1>or does it know that you were trying

00:45:12.885 --> 00:45:14.485
<v Speaker 1>to push the tiny LAMMA one? So how

00:45:14.485 --> 00:45:16.485
<v Speaker 1>do you work with all models and individual

00:45:16.485 --> 00:45:18.725
<v Speaker 1>models when you're using RRAS with the LAMMA?

00:45:19.040 --> 00:45:21.119
<v Speaker 2>You would have to so he he got

00:45:21.119 --> 00:45:22.720
<v Speaker 2>away with Raymond got away with it because

00:45:22.720 --> 00:45:25.040
<v Speaker 2>he'd only downloaded or pulled one model, so

00:45:25.040 --> 00:45:26.960
<v Speaker 2>it was only going to compress that. So

00:45:26.960 --> 00:45:28.320
<v Speaker 2>that'd be one way. The other way is

00:45:28.320 --> 00:45:30.320
<v Speaker 2>you would have to look at the manifest

00:45:30.320 --> 00:45:31.840
<v Speaker 2>and link what layers

00:45:32.000 --> 00:45:33.915
<v Speaker 2>for each model, and then you'd have to

00:45:33.915 --> 00:45:36.395
<v Speaker 2>run separate ORS commands to make sure you're

00:45:36.395 --> 00:45:37.755
<v Speaker 2>only pushing the elements

00:45:37.915 --> 00:45:39.595
<v Speaker 2>or the layers of the image that you

00:45:39.595 --> 00:45:40.955
<v Speaker 2>want to bundle it. So he can more

00:45:40.955 --> 00:45:43.195
<v Speaker 2>accurately instead of just models and putting or

00:45:43.195 --> 00:45:44.395
<v Speaker 2>he could just put all the models in

00:45:44.395 --> 00:45:45.515
<v Speaker 2>there and just, here's the models.

00:45:46.260 --> 00:45:47.700
<v Speaker 2>But he would wanna have to pick out

00:45:47.700 --> 00:45:48.980
<v Speaker 2>the digests

00:45:49.060 --> 00:45:50.820
<v Speaker 2>for those layers and then push them as

00:45:50.820 --> 00:45:52.900
<v Speaker 2>tiny llama and whatever the next model would

00:45:52.900 --> 00:45:53.620
<v Speaker 2>be. Yeah.

00:45:54.500 --> 00:45:56.500
<v Speaker 1>Alright. So I guess the preferred workflow, if

00:45:56.500 --> 00:45:58.100
<v Speaker 1>you are doing something like this, is to

00:45:58.100 --> 00:46:01.095
<v Speaker 1>pull one image, build the OCI artifact,

00:46:01.095 --> 00:46:03.255
<v Speaker 1>clean it up, and then repeat. That would

00:46:03.255 --> 00:46:05.495
<v Speaker 2>be the simplest way. The simplest way. Yeah.

00:46:05.495 --> 00:46:06.455
<v Speaker 2>Yep. Yeah.

00:46:07.575 --> 00:46:09.735
<v Speaker 1>Alright. Awesome. Thank you. And if there are

00:46:09.735 --> 00:46:11.335
<v Speaker 1>any more questions from the audience, please feel

00:46:11.335 --> 00:46:12.940
<v Speaker 1>free to drop them in the chat. Other

00:46:12.940 --> 00:46:14.860
<v Speaker 1>than that, I'll hand over to Josh for

00:46:14.860 --> 00:46:16.300
<v Speaker 1>demo two. Alright.

00:46:18.300 --> 00:46:20.060
<v Speaker 2>Let me see if I can move this.

00:46:20.380 --> 00:46:21.980
<v Speaker 2>Oh, I'll just disappear for a while. My

00:46:21.980 --> 00:46:22.780
<v Speaker 2>screen up?

00:46:23.420 --> 00:46:24.940
<v Speaker 1>It's

00:46:25.820 --> 00:46:28.715
<v Speaker 1>up there. Alright. Awesome. So we'll we'll go

00:46:28.715 --> 00:46:30.235
<v Speaker 2>with this one. I couldn't help myself from

00:46:30.235 --> 00:46:31.835
<v Speaker 2>trying to get demo magic to work, so

00:46:31.835 --> 00:46:33.115
<v Speaker 2>we'll see how well it works for me.

00:46:33.195 --> 00:46:34.875
<v Speaker 2>But, yeah, just to to start.

00:46:36.635 --> 00:46:38.715
<v Speaker 2>Hey, Famey. Do you mind muting your keyboard

00:46:38.715 --> 00:46:40.955
<v Speaker 2>right off? Sure. You got MX Blues? I

00:46:40.955 --> 00:46:42.809
<v Speaker 2>think. Could even come up with keyboards on

00:46:42.809 --> 00:46:44.010
<v Speaker 1>this stream. That's the problem.

00:46:44.569 --> 00:46:46.490
<v Speaker 2>So I I got the HH Keybys, which

00:46:46.490 --> 00:46:48.010
<v Speaker 2>is the quietest one I've ever had.

00:46:48.329 --> 00:46:50.089
<v Speaker 2>But, anyway, yeah, to set up this one,

00:46:50.089 --> 00:46:52.329
<v Speaker 2>what I'm gonna show real quickly is a

00:46:52.329 --> 00:46:55.049
<v Speaker 2>new feature from Notation, which is blobs

00:46:55.049 --> 00:46:56.329
<v Speaker 2>signing or and verification.

00:46:57.015 --> 00:46:57.655
<v Speaker 2>And

00:46:57.974 --> 00:46:59.335
<v Speaker 2>to kinda set the stage,

00:46:59.815 --> 00:47:02.055
<v Speaker 2>signatures are becoming more and more important. The

00:47:02.055 --> 00:47:04.375
<v Speaker 2>the analogy is I actually got this from

00:47:04.934 --> 00:47:07.575
<v Speaker 2>Kelsey Hightower's talk before he retired, sadly. I

00:47:07.575 --> 00:47:09.255
<v Speaker 2>know he's still around on Blue Sky and

00:47:09.255 --> 00:47:11.590
<v Speaker 2>stuff, but I'm not working full time.

00:47:11.830 --> 00:47:13.990
<v Speaker 2>But, anyway, he gave a supply chain talk

00:47:13.990 --> 00:47:15.430
<v Speaker 2>a couple years ago, and he used this

00:47:15.430 --> 00:47:17.030
<v Speaker 2>really great story where,

00:47:17.270 --> 00:47:18.550
<v Speaker 2>you know, he he went into a coffee

00:47:18.550 --> 00:47:19.990
<v Speaker 2>shop. He found a thumb drive,

00:47:20.310 --> 00:47:21.670
<v Speaker 2>and it was labeled,

00:47:21.670 --> 00:47:22.870
<v Speaker 2>you know, like, latest

00:47:23.270 --> 00:47:26.315
<v Speaker 2>go packages or whatever else that for for

00:47:26.315 --> 00:47:28.155
<v Speaker 2>compression or whatever. And so he's like, oh,

00:47:28.155 --> 00:47:30.315
<v Speaker 2>well, naturally, I'm just gonna plug that into

00:47:30.315 --> 00:47:31.115
<v Speaker 2>my computer,

00:47:31.515 --> 00:47:33.355
<v Speaker 2>and I'm like, oh, this is exactly the

00:47:33.355 --> 00:47:34.635
<v Speaker 2>source code I need. I'm gonna pull it

00:47:34.635 --> 00:47:36.875
<v Speaker 2>over. And he used that analogy to say,

00:47:36.875 --> 00:47:38.150
<v Speaker 2>like, we, of course, we would never do

00:47:38.150 --> 00:47:39.350
<v Speaker 2>that. We're not gonna take a random thumb

00:47:39.350 --> 00:47:40.550
<v Speaker 2>drive from a coffee shop and plug it

00:47:40.550 --> 00:47:42.950
<v Speaker 2>into our computer, but we pull down container

00:47:42.950 --> 00:47:44.550
<v Speaker 2>images and packages

00:47:45.430 --> 00:47:47.430
<v Speaker 2>that way. We don't have any verification. And

00:47:47.430 --> 00:47:48.790
<v Speaker 2>so signing is one

00:47:49.190 --> 00:47:51.510
<v Speaker 2>one way that's emerging now where we can

00:47:51.510 --> 00:47:53.885
<v Speaker 2>actually have some trust with whatever it is.

00:47:54.045 --> 00:47:57.244
<v Speaker 2>And so we have container image signing through

00:47:57.244 --> 00:48:00.285
<v Speaker 2>notation and other tools like cosign,

00:48:00.925 --> 00:48:03.005
<v Speaker 2>but we keep when we're doing these arbitrary

00:48:03.005 --> 00:48:07.005
<v Speaker 2>blobs since there isn't a predefined OCI

00:48:06.150 --> 00:48:08.230
<v Speaker 2>format and everything for the image quite yet,

00:48:08.230 --> 00:48:10.310
<v Speaker 2>and we're just pushing random

00:48:10.390 --> 00:48:13.109
<v Speaker 2>bits of you know, random archive or whatever,

00:48:13.589 --> 00:48:15.190
<v Speaker 2>can we still use those

00:48:15.510 --> 00:48:17.190
<v Speaker 2>signature best practices

00:48:17.190 --> 00:48:19.625
<v Speaker 2>and supply chain security on those things? And

00:48:19.625 --> 00:48:20.825
<v Speaker 2>the answer is yes. And so that's what

00:48:20.825 --> 00:48:22.505
<v Speaker 2>I'm gonna I'm gonna show off today.

00:48:22.905 --> 00:48:24.185
<v Speaker 2>So without further ado,

00:48:24.425 --> 00:48:25.785
<v Speaker 2>this is the notation.

00:48:26.185 --> 00:48:28.185
<v Speaker 2>It should say blob, not blog. That's a

00:48:28.185 --> 00:48:30.105
<v Speaker 2>typo. So blob signature.

00:48:30.345 --> 00:48:32.744
<v Speaker 2>This is only available in version two, the

00:48:32.744 --> 00:48:34.660
<v Speaker 2>alpha. So if you don't have this one,

00:48:34.660 --> 00:48:36.340
<v Speaker 2>you won't have the subcommands.

00:48:36.340 --> 00:48:37.780
<v Speaker 2>So just to be aware of that.

00:48:38.500 --> 00:48:41.860
<v Speaker 2>So first thing, I've I've gotten the model

00:48:41.860 --> 00:48:42.660
<v Speaker 2>into

00:48:42.980 --> 00:48:44.980
<v Speaker 2>an archive, and I've compressed it. So that's

00:48:44.980 --> 00:48:46.180
<v Speaker 2>what this is. And I'm gonna create a

00:48:46.180 --> 00:48:48.924
<v Speaker 2>signature for that with notation. That signature will

00:48:48.924 --> 00:48:51.005
<v Speaker 2>be local, and then I will use another

00:48:51.005 --> 00:48:52.925
<v Speaker 2>command in a second that will connect

00:48:53.405 --> 00:48:55.165
<v Speaker 2>them, which is why we preface to talk

00:48:55.165 --> 00:48:56.605
<v Speaker 2>with the referrer's

00:48:56.684 --> 00:48:58.925
<v Speaker 2>subject. So I've successfully signed it.

00:48:59.645 --> 00:49:01.885
<v Speaker 2>And let me just create a new one

00:49:01.885 --> 00:49:02.285
<v Speaker 2>here

00:49:02.859 --> 00:49:04.940
<v Speaker 2>so we could see it real quick. So

00:49:04.940 --> 00:49:06.300
<v Speaker 2>if I do l s here, I have

00:49:06.300 --> 00:49:08.460
<v Speaker 2>this signature file now. K?

00:49:09.099 --> 00:49:10.780
<v Speaker 2>We'll jump back to the demo.

00:49:11.900 --> 00:49:13.900
<v Speaker 2>So now I'm gonna push the model

00:49:14.380 --> 00:49:15.100
<v Speaker 2>as

00:49:15.180 --> 00:49:16.460
<v Speaker 2>this artifact

00:49:16.460 --> 00:49:17.100
<v Speaker 2>of

00:49:17.260 --> 00:49:19.214
<v Speaker 2>layers tar, and I'm gonna push it to

00:49:19.214 --> 00:49:20.015
<v Speaker 2>my registry.

00:49:21.775 --> 00:49:23.855
<v Speaker 2>So now I have the model on my

00:49:23.855 --> 00:49:24.655
<v Speaker 2>registry,

00:49:25.214 --> 00:49:26.815
<v Speaker 2>and I have a signature locally. But now

00:49:26.815 --> 00:49:28.815
<v Speaker 2>I want the registry to have the relationship

00:49:28.815 --> 00:49:30.335
<v Speaker 2>between the signature

00:49:30.414 --> 00:49:31.535
<v Speaker 2>and the artifact.

00:49:32.870 --> 00:49:34.870
<v Speaker 2>So I'm gonna use ORAS attach,

00:49:35.430 --> 00:49:37.190
<v Speaker 2>and this is gonna use the referrer's API.

00:49:37.190 --> 00:49:38.070
<v Speaker 2>So if we were to look at the

00:49:38.070 --> 00:49:40.230
<v Speaker 2>manifest, we're not actually gonna see the relationship.

00:49:40.230 --> 00:49:42.230
<v Speaker 2>We actually have to hit the referrer's API

00:49:42.230 --> 00:49:44.070
<v Speaker 2>to see the relationship between them. It's not

00:49:44.070 --> 00:49:45.590
<v Speaker 2>gonna be in the subject that I talked

00:49:45.590 --> 00:49:48.035
<v Speaker 2>about before. That's a separate way to establish

00:49:48.035 --> 00:49:49.875
<v Speaker 2>relationships in the registry.

00:49:51.075 --> 00:49:52.435
<v Speaker 2>So now it's attached.

00:49:53.395 --> 00:49:55.235
<v Speaker 2>Now that it's attached, I'm just gonna use

00:49:55.235 --> 00:49:56.835
<v Speaker 2>notation l s, and this is gonna show

00:49:56.835 --> 00:49:59.235
<v Speaker 2>us the relationship between the image and the

00:49:59.235 --> 00:50:01.555
<v Speaker 2>signature. So we can see here, here's my

00:50:01.555 --> 00:50:03.940
<v Speaker 2>model. It's yelling at me because I'm using

00:50:03.940 --> 00:50:05.780
<v Speaker 2>the tag and not the the digest because

00:50:05.780 --> 00:50:07.460
<v Speaker 2>that's more clear. Tags are mutable, so they

00:50:07.460 --> 00:50:08.180
<v Speaker 2>could change.

00:50:08.980 --> 00:50:10.580
<v Speaker 2>And so it's wanting me to use,

00:50:11.140 --> 00:50:12.980
<v Speaker 2>the immutable one, which would be

00:50:13.300 --> 00:50:16.275
<v Speaker 2>the digest. But, anyway, we have the model

00:50:16.275 --> 00:50:16.755
<v Speaker 2>here,

00:50:17.075 --> 00:50:18.595
<v Speaker 2>and this is the digest here. So that's

00:50:18.595 --> 00:50:20.515
<v Speaker 2>another way to reference

00:50:20.675 --> 00:50:22.994
<v Speaker 2>the OCI artifacts. And then underneath of that,

00:50:22.994 --> 00:50:24.675
<v Speaker 2>I can see that there's this

00:50:25.075 --> 00:50:27.875
<v Speaker 2>CNCF notary signature with a different digest. So

00:50:27.875 --> 00:50:30.035
<v Speaker 2>that's the digest of the signature itself

00:50:30.710 --> 00:50:33.109
<v Speaker 2>being linked to it or referred to it.

00:50:33.190 --> 00:50:33.670
<v Speaker 2>So

00:50:35.430 --> 00:50:38.230
<v Speaker 2>I'm gonna create a policy, a trustor policy

00:50:38.230 --> 00:50:40.070
<v Speaker 2>that will allow me to do verification.

00:50:40.230 --> 00:50:41.750
<v Speaker 2>So just to create the signature, I don't

00:50:41.750 --> 00:50:43.030
<v Speaker 2>do need to do any of this. But

00:50:43.030 --> 00:50:44.630
<v Speaker 2>if you ever wanted to validate the signature,

00:50:44.915 --> 00:50:46.195
<v Speaker 2>these are the steps now that you need

00:50:46.195 --> 00:50:46.835
<v Speaker 2>to follow.

00:50:47.714 --> 00:50:49.234
<v Speaker 2>So I already have it. I'm just gonna

00:50:49.234 --> 00:50:50.755
<v Speaker 2>override it locally.

00:50:50.994 --> 00:50:52.915
<v Speaker 2>So now I have a policy that states,

00:50:52.915 --> 00:50:55.955
<v Speaker 2>okay, it's it's basically setting up what certificate

00:50:55.955 --> 00:50:58.115
<v Speaker 2>should I trust for this entity,

00:50:58.195 --> 00:50:59.474
<v Speaker 2>for this this policy.

00:50:59.890 --> 00:51:02.050
<v Speaker 2>And so I'm gonna this is information from

00:51:02.050 --> 00:51:03.890
<v Speaker 2>the certificate that was generated that I used

00:51:03.890 --> 00:51:06.210
<v Speaker 2>to sign, and so that needs to match.

00:51:06.690 --> 00:51:08.609
<v Speaker 2>The trust store that it was stored in

00:51:08.609 --> 00:51:10.530
<v Speaker 2>was the the CA demo.

00:51:11.570 --> 00:51:13.410
<v Speaker 2>So now that I have a policy, I'm

00:51:13.410 --> 00:51:15.170
<v Speaker 2>gonna just pull down the artifact,

00:51:15.170 --> 00:51:17.385
<v Speaker 2>not validate the one that's local because that

00:51:17.385 --> 00:51:19.225
<v Speaker 2>one was assigned to someone in the registry.

00:51:19.225 --> 00:51:21.145
<v Speaker 2>I'm gonna put it in a downloads folder.

00:51:24.105 --> 00:51:25.545
<v Speaker 2>So I'll pull that down,

00:51:26.345 --> 00:51:28.905
<v Speaker 2>and then blob verify, give it a policy,

00:51:28.905 --> 00:51:30.560
<v Speaker 2>and then I'm gonna point to the signature

00:51:30.560 --> 00:51:32.400
<v Speaker 2>and then the path to the thing that

00:51:32.400 --> 00:51:33.440
<v Speaker 2>I wanna verify.

00:51:34.000 --> 00:51:35.360
<v Speaker 2>And and there we have it. You know,

00:51:35.360 --> 00:51:37.200
<v Speaker 2>pretty pretty straightforward. But that's how you can

00:51:37.200 --> 00:51:38.000
<v Speaker 2>use the new

00:51:38.320 --> 00:51:39.680
<v Speaker 2>notation blob,

00:51:39.680 --> 00:51:43.440
<v Speaker 2>not blog, blob, verify and and sign together

00:51:43.715 --> 00:51:46.195
<v Speaker 2>to kinda secure your ACM models.

00:51:52.355 --> 00:51:54.275
<v Speaker 2>That's it for me for that demo.

00:51:56.950 --> 00:51:58.310
<v Speaker 1>Is that the demo,

00:51:58.550 --> 00:52:00.630
<v Speaker 1>both demos finished? Yes? Yeah.

00:52:01.110 --> 00:52:01.670
<v Speaker 3>Actually,

00:52:02.630 --> 00:52:05.030
<v Speaker 3>I just saved myself because

00:52:05.030 --> 00:52:05.830
<v Speaker 3>I just

00:52:06.470 --> 00:52:08.630
<v Speaker 3>got the problem here and I can

00:52:08.950 --> 00:52:09.830
<v Speaker 3>finish my demo.

00:52:10.375 --> 00:52:11.655
<v Speaker 2>Oh yeah, over to you.

00:52:12.535 --> 00:52:13.495
<v Speaker 2>Good work.

00:52:14.375 --> 00:52:16.055
<v Speaker 1>If you could share your screen again, please.

00:52:16.215 --> 00:52:17.975
<v Speaker 3>Yeah, sure. Let me do it.

00:52:19.735 --> 00:52:23.255
<v Speaker 3>It turns out that live demo is sometimes

00:52:23.895 --> 00:52:24.935
<v Speaker 3>not always stable,

00:52:25.640 --> 00:52:26.600
<v Speaker 3>But actually,

00:52:26.920 --> 00:52:30.040
<v Speaker 3>the Kubernetes cluster is not done. I actually

00:52:30.040 --> 00:52:32.520
<v Speaker 3>have a kubectmin to run my local Kubernetes

00:52:32.520 --> 00:52:35.480
<v Speaker 3>cluster. I just forgot to switch to the

00:52:36.440 --> 00:52:38.535
<v Speaker 3>root user because I

00:52:38.775 --> 00:52:41.734
<v Speaker 3>installed it on a root user. The kubectl

00:52:41.734 --> 00:52:42.935
<v Speaker 3>only has the

00:52:43.175 --> 00:52:45.655
<v Speaker 3>access to if I run it in root

00:52:45.655 --> 00:52:46.935
<v Speaker 3>user. So here,

00:52:47.655 --> 00:52:48.215
<v Speaker 3>if

00:52:49.255 --> 00:52:50.295
<v Speaker 3>the

00:52:51.575 --> 00:52:51.734
<v Speaker 3>I

00:52:54.880 --> 00:52:56.320
<v Speaker 3>pod YAML file,

00:52:56.400 --> 00:52:57.680
<v Speaker 3>and it will create

00:52:57.840 --> 00:52:59.040
<v Speaker 3>a new pod,

00:52:59.520 --> 00:53:00.640
<v Speaker 3>consume the

00:53:01.040 --> 00:53:02.400
<v Speaker 3>OCI image

00:53:02.960 --> 00:53:05.520
<v Speaker 3>packaged with the AI model. So here,

00:53:06.825 --> 00:53:08.265
<v Speaker 3>as we're looking at

00:53:08.985 --> 00:53:11.785
<v Speaker 3>the OLAMA model file, the YAML file,

00:53:12.985 --> 00:53:13.785
<v Speaker 3>so we

00:53:14.744 --> 00:53:16.665
<v Speaker 3>can see the image

00:53:19.560 --> 00:53:22.520
<v Speaker 3>the OCI artifact that we just pushed to

00:53:22.520 --> 00:53:25.320
<v Speaker 3>the OCI registry. So we have two versions

00:53:25.320 --> 00:53:27.160
<v Speaker 3>here. I use v1.

00:53:27.160 --> 00:53:29.400
<v Speaker 3>That is the version that I previously pushed

00:53:29.400 --> 00:53:31.720
<v Speaker 3>to the registry. That also turns out that

00:53:31.720 --> 00:53:34.305
<v Speaker 3>we can have the versioning control for OCI

00:53:34.305 --> 00:53:35.105
<v Speaker 3>artifact

00:53:35.105 --> 00:53:36.625
<v Speaker 3>in the OCI registry.

00:53:36.865 --> 00:53:38.625
<v Speaker 3>And also, it can apply to

00:53:39.265 --> 00:53:40.225
<v Speaker 3>manage the

00:53:40.464 --> 00:53:42.225
<v Speaker 3>AI models in the registry.

00:53:42.625 --> 00:53:43.425
<v Speaker 3>So here,

00:53:43.825 --> 00:53:46.305
<v Speaker 3>if we apply that part and create a

00:53:46.305 --> 00:53:46.785
<v Speaker 3>new part,

00:53:47.280 --> 00:53:48.720
<v Speaker 3>then we got the

00:53:50.080 --> 00:53:51.520
<v Speaker 3>We should have that part

00:53:52.000 --> 00:53:54.720
<v Speaker 3>running right now. But as the model file

00:53:54.720 --> 00:53:57.280
<v Speaker 3>is relatively large, so it takes some time

00:53:57.280 --> 00:53:59.520
<v Speaker 3>to create a new container here.

00:53:59.600 --> 00:54:00.320
<v Speaker 3>So ideally,

00:54:00.984 --> 00:54:03.704
<v Speaker 3>if the container if the pod is running,

00:54:03.704 --> 00:54:05.065
<v Speaker 3>we should be able to

00:54:05.545 --> 00:54:09.464
<v Speaker 3>execute into the container of that pod and

00:54:09.464 --> 00:54:11.145
<v Speaker 3>run our LAMMA

00:54:13.145 --> 00:54:14.025
<v Speaker 3>tiny

00:54:15.704 --> 00:54:16.265
<v Speaker 3>LAMMA,

00:54:17.280 --> 00:54:19.600
<v Speaker 3>run this model in the container,

00:54:19.840 --> 00:54:21.360
<v Speaker 3>and interact with the

00:54:21.680 --> 00:54:22.800
<v Speaker 3>AI model.

00:54:23.520 --> 00:54:24.720
<v Speaker 3>So here, assume

00:54:28.240 --> 00:54:29.200
<v Speaker 3>we already

00:54:29.280 --> 00:54:30.400
<v Speaker 3>zoom into the

00:54:31.244 --> 00:54:32.204
<v Speaker 3>container,

00:54:32.285 --> 00:54:33.805
<v Speaker 3>and we should be able to

00:54:34.045 --> 00:54:36.684
<v Speaker 3>interact with the AI model. So who you

00:54:36.684 --> 00:54:37.244
<v Speaker 3>are?

00:54:40.525 --> 00:54:43.244
<v Speaker 3>It should tell me, hey, I'm an artificial

00:54:43.244 --> 00:54:43.724
<v Speaker 3>bot.

00:54:45.940 --> 00:54:47.220
<v Speaker 3>Okay. That's it.

00:54:49.460 --> 00:54:50.500
<v Speaker 1>Alright.

00:54:50.500 --> 00:54:52.340
<v Speaker 1>Awesome. Thank you. So

00:54:55.060 --> 00:54:55.940
<v Speaker 1>let's

00:54:55.940 --> 00:54:57.700
<v Speaker 1>tackle a couple of questions, and then and

00:54:57.700 --> 00:54:59.060
<v Speaker 1>then we'll wrap this up just on the

00:54:59.060 --> 00:54:59.700
<v Speaker 1>hour.

00:54:59.860 --> 00:55:02.875
<v Speaker 1>I I think ORAS is an absolutely fantastic

00:55:02.875 --> 00:55:04.875
<v Speaker 1>tool. Right? I'm seeing it used more and

00:55:04.875 --> 00:55:07.115
<v Speaker 1>more. It's almost the factor standard now for,

00:55:07.115 --> 00:55:08.955
<v Speaker 1>you know, pushing and pulling the things aren't,

00:55:09.035 --> 00:55:11.755
<v Speaker 1>you know, typically container images. I mean, even

00:55:11.755 --> 00:55:14.075
<v Speaker 1>to the point, I think anyone watching this

00:55:14.155 --> 00:55:14.875
<v Speaker 1>session

00:55:15.410 --> 00:55:18.450
<v Speaker 1>is probably already using OCI artifacts, and they

00:55:18.450 --> 00:55:19.650
<v Speaker 1>don't even know it. Because if you run

00:55:19.650 --> 00:55:21.970
<v Speaker 1>the brew command, all of those packages are

00:55:21.970 --> 00:55:24.770
<v Speaker 1>now coming from GitHub's container registry to the

00:55:24.770 --> 00:55:26.770
<v Speaker 1>best of my knowledge. Mhmm. So it's just

00:55:27.010 --> 00:55:28.770
<v Speaker 1>it's nice to see the OCI standard and

00:55:28.770 --> 00:55:30.610
<v Speaker 1>these registries being used for such

00:55:32.065 --> 00:55:33.905
<v Speaker 1>non container images cases.

00:55:34.465 --> 00:55:36.865
<v Speaker 1>What I'm curious about though is I'm assuming

00:55:37.345 --> 00:55:39.745
<v Speaker 1>that people maybe are not as familiar with

00:55:39.745 --> 00:55:42.465
<v Speaker 1>the Notary project as they are with OCI

00:55:42.465 --> 00:55:45.100
<v Speaker 1>and ORS, at least at the start of

00:55:45.100 --> 00:55:47.820
<v Speaker 1>2025. And I think that Notary version one

00:55:47.820 --> 00:55:51.260
<v Speaker 1>was always considered quite academic and a difficult

00:55:51.260 --> 00:55:52.380
<v Speaker 1>program to use.

00:55:52.700 --> 00:55:55.100
<v Speaker 1>You've shown us now that there's Notary V2

00:55:55.100 --> 00:55:57.740
<v Speaker 1>currently in alpha one. So my question is,

00:55:57.740 --> 00:55:58.780
<v Speaker 1>if I get to it

00:55:59.685 --> 00:56:02.645
<v Speaker 1>is the Notary developer experience improving with two

00:56:02.645 --> 00:56:04.885
<v Speaker 1>point zero and what is the roadmap like

00:56:04.885 --> 00:56:07.285
<v Speaker 1>to get to a GA release of Notary

00:56:07.285 --> 00:56:07.845
<v Speaker 1>two?

00:56:08.565 --> 00:56:09.445
<v Speaker 3>Just

00:56:09.445 --> 00:56:12.085
<v Speaker 3>to correct the branding, actually, we should say

00:56:12.085 --> 00:56:13.125
<v Speaker 3>Notary Project

00:56:15.000 --> 00:56:17.080
<v Speaker 3>two point zero because we

00:56:18.120 --> 00:56:20.760
<v Speaker 3>rebranded the project and we no longer use

00:56:20.760 --> 00:56:23.000
<v Speaker 3>the Notary V2 as a brand.

00:56:23.800 --> 00:56:26.120
<v Speaker 3>So in terms of the roadmap,

00:56:26.120 --> 00:56:28.360
<v Speaker 3>we want to make sure the

00:56:28.905 --> 00:56:30.825
<v Speaker 3>block signing feature is stable.

00:56:31.305 --> 00:56:33.065
<v Speaker 3>And also going forward,

00:56:33.385 --> 00:56:35.705
<v Speaker 3>we will support formatted output.

00:56:35.865 --> 00:56:38.745
<v Speaker 3>It will be used to pipe the output

00:56:38.825 --> 00:56:39.545
<v Speaker 3>to

00:56:39.625 --> 00:56:42.825
<v Speaker 3>the CICD pipelines and also the automation scenarios.

00:56:43.630 --> 00:56:45.950
<v Speaker 3>So here, all of the demos are running

00:56:45.950 --> 00:56:47.070
<v Speaker 3>in our terminal.

00:56:47.150 --> 00:56:49.070
<v Speaker 3>But in production environment,

00:56:49.150 --> 00:56:50.990
<v Speaker 3>developers will run

00:56:50.990 --> 00:56:54.190
<v Speaker 3>notation or RARS commands in a CICD pipeline

00:56:54.190 --> 00:56:56.990
<v Speaker 3>or in scripts. So with the formatted output

00:56:56.990 --> 00:56:57.310
<v Speaker 3>support,

00:56:58.155 --> 00:57:01.195
<v Speaker 3>developers will be able to pipe the output

00:57:02.395 --> 00:57:03.035
<v Speaker 3>and

00:57:03.435 --> 00:57:05.995
<v Speaker 3>use it in a CICD pipeline.

00:57:06.795 --> 00:57:09.275
<v Speaker 3>So two things. One is to make the

00:57:09.275 --> 00:57:11.755
<v Speaker 3>block signing and verification stable

00:57:11.755 --> 00:57:12.795
<v Speaker 3>and also

00:57:14.430 --> 00:57:15.310
<v Speaker 3>support

00:57:15.310 --> 00:57:16.590
<v Speaker 3>formatted output.

00:57:17.550 --> 00:57:20.670
<v Speaker 2>One quick note too. The note does

00:57:20.670 --> 00:57:22.430
<v Speaker 2>have a GitHub action that works for container

00:57:22.430 --> 00:57:25.310
<v Speaker 2>images. If you're worried about signing container images,

00:57:25.710 --> 00:57:27.230
<v Speaker 2>you don't need to have some kind of

00:57:27.855 --> 00:57:29.215
<v Speaker 2>bash script running

00:57:29.535 --> 00:57:31.295
<v Speaker 2>ins inside your workflow anymore. You can just

00:57:31.295 --> 00:57:32.494
<v Speaker 2>use an action, and it gives you all

00:57:32.494 --> 00:57:34.655
<v Speaker 2>the the features and stuff like that. So

00:57:35.375 --> 00:57:36.975
<v Speaker 2>do you have any personal experience? Like, what

00:57:36.975 --> 00:57:38.175
<v Speaker 2>were some of the rough edges that you

00:57:38.175 --> 00:57:40.095
<v Speaker 2>had in your mind that that you'd like

00:57:40.095 --> 00:57:41.535
<v Speaker 2>to see addressed? Maybe they have been. I

00:57:41.535 --> 00:57:41.855
<v Speaker 2>don't know.

00:57:42.940 --> 00:57:45.980
<v Speaker 1>Yeah. I think the the scriptability

00:57:45.980 --> 00:57:47.980
<v Speaker 1>of it was always a major challenge, but

00:57:47.980 --> 00:57:49.980
<v Speaker 1>also just, you know, the commands themselves are

00:57:49.980 --> 00:57:52.140
<v Speaker 1>quite verbose. You know? I'm assuming there's a

00:57:52.140 --> 00:57:53.660
<v Speaker 1>reason you recorded your demo or at least

00:57:53.660 --> 00:57:55.660
<v Speaker 1>set up some automation because those commands are

00:57:55.660 --> 00:57:57.955
<v Speaker 1>not an easy type, especially. So

00:57:59.234 --> 00:58:01.315
<v Speaker 1>I don't think that's necessarily a bad developer

00:58:01.315 --> 00:58:02.275
<v Speaker 1>experience,

00:58:02.435 --> 00:58:04.035
<v Speaker 1>but it can be quite daunting following along

00:58:04.035 --> 00:58:06.115
<v Speaker 1>with tutorials and copying big masses.

00:58:06.275 --> 00:58:07.474
<v Speaker 2>Yeah. It it does take a fair amount

00:58:07.474 --> 00:58:08.915
<v Speaker 2>of context. Like, okay. Well, what

00:58:09.680 --> 00:58:10.480
<v Speaker 2>what

00:58:10.640 --> 00:58:12.800
<v Speaker 2>like, the envelope size or or the envelope

00:58:12.800 --> 00:58:13.440
<v Speaker 2>itself.

00:58:13.680 --> 00:58:15.680
<v Speaker 2>You know? Like, I don't even fully understand

00:58:15.680 --> 00:58:17.280
<v Speaker 2>the difference between the two. You know? Like,

00:58:17.280 --> 00:58:18.480
<v Speaker 2>I know that there's a difference. I know

00:58:18.480 --> 00:58:20.800
<v Speaker 2>that it's changing how the signature is formatted,

00:58:20.800 --> 00:58:23.040
<v Speaker 2>but a lot of that gets into cryptography.

00:58:23.760 --> 00:58:25.200
<v Speaker 2>So, yeah, maybe, like, some

00:58:25.575 --> 00:58:28.295
<v Speaker 2>defaults to shorten the commands would be good.

00:58:28.295 --> 00:58:30.055
<v Speaker 2>So you don't need to necessarily what's a

00:58:30.055 --> 00:58:32.855
<v Speaker 2>good default for those more verbose

00:58:33.095 --> 00:58:34.055
<v Speaker 2>flags?

00:58:34.695 --> 00:58:36.214
<v Speaker 1>I think one of the other challenges was

00:58:36.214 --> 00:58:38.615
<v Speaker 1>also was key management. You know, people don't

00:58:38.615 --> 00:58:40.920
<v Speaker 1>like having to manage root certificates and such

00:58:40.920 --> 00:58:42.200
<v Speaker 1>like that. Uh-huh. Yeah.

00:58:42.760 --> 00:58:44.760
<v Speaker 1>But, you know, when it comes to to

00:58:44.760 --> 00:58:46.760
<v Speaker 1>trust, right, you gotta trust someone. And if

00:58:46.760 --> 00:58:48.839
<v Speaker 1>you don't meant those keys, there is no

00:58:48.839 --> 00:58:50.839
<v Speaker 1>trust. So Right. I guess what people really

00:58:50.839 --> 00:58:53.145
<v Speaker 1>should be doing is is leaning in to

00:58:53.145 --> 00:58:55.225
<v Speaker 1>Azure and all the other providers that have

00:58:55.225 --> 00:58:57.305
<v Speaker 1>KMS because, you know, these tools are invaluable

00:58:57.305 --> 00:58:59.545
<v Speaker 1>for management. This type of support material. I

00:58:59.545 --> 00:59:02.345
<v Speaker 2>could definitely see that. Yeah. We're getting getting

00:59:02.665 --> 00:59:05.225
<v Speaker 2>notation getting bundled in with a PKI infrastructure.

00:59:05.820 --> 00:59:07.580
<v Speaker 2>Right? Like, to use it, you actually have

00:59:07.580 --> 00:59:09.900
<v Speaker 2>to have a fairly mature PKI infrastructure, and

00:59:09.900 --> 00:59:11.420
<v Speaker 2>that's a big prerequisite

00:59:11.420 --> 00:59:12.780
<v Speaker 2>for a lot of people that would be

00:59:12.780 --> 00:59:13.420
<v Speaker 2>interested.

00:59:14.700 --> 00:59:15.740
<v Speaker 3>Yeah.

00:59:16.780 --> 00:59:19.420
<v Speaker 3>One more thing. So actually, Notation is also

00:59:19.420 --> 00:59:22.115
<v Speaker 3>working with the Azure Trusted Signing Service to

00:59:22.115 --> 00:59:25.315
<v Speaker 3>provide keyless signing experience. That would be That

00:59:26.194 --> 00:59:27.315
<v Speaker 3>would be coming soon.

00:59:28.515 --> 00:59:29.875
<v Speaker 1>All right. And you're not gonna stack a

00:59:29.875 --> 00:59:30.994
<v Speaker 1>date on that, are you? You're just gonna

00:59:30.994 --> 00:59:33.075
<v Speaker 1>leave me with the same here. Coming soon.

00:59:33.075 --> 00:59:35.075
<v Speaker 2>Do a theater near you. Maybe spring, who

00:59:35.075 --> 00:59:37.630
<v Speaker 2>knows? Yeah. I mean, that this definitely is

00:59:37.630 --> 00:59:39.550
<v Speaker 1>is addressing some of those challenges, and I

00:59:39.550 --> 00:59:41.150
<v Speaker 1>would like to see projects like this get

00:59:41.150 --> 00:59:43.390
<v Speaker 1>more uptake because security is often an afterthought.

00:59:43.390 --> 00:59:44.830
<v Speaker 1>And I think that is because, you know,

00:59:44.830 --> 00:59:46.750
<v Speaker 1>developers have a lot on their plate with

00:59:46.750 --> 00:59:48.830
<v Speaker 1>cloud native and Kubernetes in general. Right? They're

00:59:48.830 --> 00:59:50.815
<v Speaker 1>already going from, just wanted to write some

00:59:50.815 --> 00:59:52.735
<v Speaker 1>code to know I'm responsible for shipping it

00:59:52.735 --> 00:59:54.495
<v Speaker 1>and packaging it and distributing it and all

00:59:54.495 --> 00:59:56.575
<v Speaker 1>of these things. And the easier and the

00:59:56.575 --> 00:59:58.415
<v Speaker 1>more hurdles we can remove to allow people

00:59:58.415 --> 01:00:00.815
<v Speaker 1>to use something like Notary and have attestations

01:00:00.815 --> 01:00:03.410
<v Speaker 1>and all these things. Would honestly, I I

01:00:03.410 --> 01:00:04.849
<v Speaker 2>would love sorry to interrupt, but I would

01:00:04.849 --> 01:00:07.010
<v Speaker 2>love where you can just

01:00:08.049 --> 01:00:09.809
<v Speaker 2>it's done for you on your push command.

01:00:09.809 --> 01:00:11.330
<v Speaker 2>Like, Docker push signed.

01:00:11.890 --> 01:00:13.329
<v Speaker 2>You know? Like, how awesome would that be?

01:00:15.375 --> 01:00:17.215
<v Speaker 1>Yeah. Work on that, please.

01:00:19.615 --> 01:00:21.935
<v Speaker 1>I think that would be absolutely fantastic.

01:00:21.935 --> 01:00:23.935
<v Speaker 1>And, you know, it's it's

01:00:24.095 --> 01:00:26.575
<v Speaker 1>because you could have this whole integration in

01:00:26.575 --> 01:00:28.335
<v Speaker 1>the cluster if we just speak into the

01:00:28.335 --> 01:00:29.920
<v Speaker 1>registry and we get these keys and this

01:00:29.920 --> 01:00:31.520
<v Speaker 1>key exchange and all this, we can do

01:00:31.520 --> 01:00:32.080
<v Speaker 1>it for

01:00:32.480 --> 01:00:34.720
<v Speaker 1>OpenID Connect and stuff. I'm sure there's ways

01:00:34.720 --> 01:00:36.400
<v Speaker 1>that we can bridge this. But it's all

01:00:36.560 --> 01:00:37.040
<v Speaker 1>identifying

01:00:37.520 --> 01:00:39.440
<v Speaker 1>challenges and solving them in time. Right? And

01:00:39.440 --> 01:00:41.280
<v Speaker 1>I think the cloud native community in general

01:00:41.280 --> 01:00:43.045
<v Speaker 1>is is really good at that. We're seeing

01:00:43.045 --> 01:00:44.725
<v Speaker 1>so much progress with Kubernetes and all these

01:00:44.725 --> 01:00:45.605
<v Speaker 1>other tools.

01:00:46.165 --> 01:00:47.685
<v Speaker 1>I only have one more question, and then

01:00:47.685 --> 01:00:49.525
<v Speaker 1>I'll leave you both to have any final

01:00:49.525 --> 01:00:50.805
<v Speaker 1>thoughts that you guys to share.

01:00:51.605 --> 01:00:53.125
<v Speaker 1>We've taken a look at ORAS as well

01:00:53.125 --> 01:00:54.885
<v Speaker 1>now, and I love that we can push

01:00:54.885 --> 01:00:56.405
<v Speaker 1>anything we want with ORAS.

01:00:56.760 --> 01:00:59.160
<v Speaker 1>I'm curious about those type definitions that we

01:00:59.160 --> 01:01:00.840
<v Speaker 1>have, the ability to see that this is

01:01:00.840 --> 01:01:01.960
<v Speaker 1>an image layer.

01:01:02.120 --> 01:01:03.800
<v Speaker 1>This is an OLAMA model.

01:01:04.120 --> 01:01:07.160
<v Speaker 1>Who's responsible and controls those definitions? Can I

01:01:07.160 --> 01:01:09.240
<v Speaker 1>make them up to ship my

01:01:09.800 --> 01:01:10.600
<v Speaker 1>Rawkode

01:01:10.985 --> 01:01:13.065
<v Speaker 1>data layer and just type in whatever string

01:01:13.065 --> 01:01:14.585
<v Speaker 1>I want, or is there some sort of

01:01:14.585 --> 01:01:17.785
<v Speaker 1>OCI spec and registration process? Like, how does

01:01:17.785 --> 01:01:20.505
<v Speaker 1>that work? There is predefined

01:01:20.505 --> 01:01:22.345
<v Speaker 2>types in the spec that you'll wanna adhere

01:01:22.345 --> 01:01:23.785
<v Speaker 2>to. It depends on what you're packaging, but

01:01:23.785 --> 01:01:25.865
<v Speaker 2>if you're kind of packaging an arbitrary thing,

01:01:25.865 --> 01:01:26.505
<v Speaker 2>you can

01:01:26.920 --> 01:01:28.600
<v Speaker 2>you ought to pick, like, a a generic

01:01:28.600 --> 01:01:30.680
<v Speaker 2>one, right, like what we do with TAR.

01:01:31.480 --> 01:01:33.000
<v Speaker 2>So there's a couple to find. You can

01:01:33.000 --> 01:01:33.960
<v Speaker 2>define your own,

01:01:34.440 --> 01:01:35.720
<v Speaker 2>but then it's not gonna give any help

01:01:35.720 --> 01:01:37.640
<v Speaker 2>to, like, how it should actually be structured.

01:01:37.640 --> 01:01:39.160
<v Speaker 2>But you totally can, if there's nothing on

01:01:39.160 --> 01:01:41.245
<v Speaker 2>the end, expecting that format to be there.

01:01:41.485 --> 01:01:42.765
<v Speaker 2>So, yeah, if you go to the OCI

01:01:42.925 --> 01:01:43.965
<v Speaker 2>I think he had a link to it.

01:01:43.965 --> 01:01:45.085
<v Speaker 2>But the OCI spec,

01:01:45.405 --> 01:01:47.485
<v Speaker 2>the different type definitions, there's a number of

01:01:47.485 --> 01:01:49.405
<v Speaker 2>generic ones that you could probably squeeze into,

01:01:49.405 --> 01:01:51.645
<v Speaker 2>like, whatever file you're gonna just archive and

01:01:51.645 --> 01:01:52.285
<v Speaker 2>zip it.

01:01:53.085 --> 01:01:53.885
<v Speaker 2>You could use that

01:01:54.579 --> 01:01:56.099
<v Speaker 2>that type like we did in the demo,

01:01:56.099 --> 01:01:58.099
<v Speaker 2>or you can create your own if there's

01:01:58.099 --> 01:01:59.619
<v Speaker 2>no tooling again, like on the other side

01:01:59.619 --> 01:02:01.380
<v Speaker 2>expecting a particular format.

01:02:02.420 --> 01:02:03.540
<v Speaker 1>Nice. Awesome.

01:02:03.700 --> 01:02:05.540
<v Speaker 3>Yeah. Actually, the

01:02:05.700 --> 01:02:07.375
<v Speaker 3>industry is kind of

01:02:08.335 --> 01:02:09.775
<v Speaker 3>wanting to standardize

01:02:09.855 --> 01:02:12.175
<v Speaker 3>the AI model spec.

01:02:12.255 --> 01:02:15.135
<v Speaker 3>There's a working group under CNCF

01:02:15.455 --> 01:02:16.255
<v Speaker 3>named

01:02:16.335 --> 01:02:18.735
<v Speaker 3>Cloud Native AI Model Spec Group.

01:02:19.400 --> 01:02:21.240
<v Speaker 3>We are working with them to define the

01:02:21.240 --> 01:02:23.880
<v Speaker 3>standards for package and

01:02:24.920 --> 01:02:27.960
<v Speaker 3>managing AI models in Cloud Native world.

01:02:28.280 --> 01:02:30.520
<v Speaker 3>Here's the open source repository

01:02:31.320 --> 01:02:33.080
<v Speaker 3>with the AI model spec.

01:02:35.305 --> 01:02:36.265
<v Speaker 2>Coming soon.

01:02:37.705 --> 01:02:39.785
<v Speaker 3>We don't have commitment right now. It's still

01:02:39.785 --> 01:02:41.785
<v Speaker 3>in a very stage. Yeah.

01:02:43.465 --> 01:02:44.185
<v Speaker 1>Awesome.

01:02:44.425 --> 01:02:45.785
<v Speaker 1>I mean, it's just nice to know that

01:02:45.785 --> 01:02:47.559
<v Speaker 1>all these things are being on. And in

01:02:47.559 --> 01:02:49.400
<v Speaker 1>due course, you know, we're making the cloud

01:02:49.400 --> 01:02:51.240
<v Speaker 1>native ecosystem and landscape that a little bit

01:02:51.240 --> 01:02:53.400
<v Speaker 1>easier day by day. So, you know, thank

01:02:53.400 --> 01:02:55.559
<v Speaker 1>you for your continued commitment and making things

01:02:55.559 --> 01:02:58.280
<v Speaker 1>awesome for us. Do you either of you

01:02:58.280 --> 01:03:00.119
<v Speaker 1>have any final words to share with the

01:03:00.119 --> 01:03:01.400
<v Speaker 1>audience before we wrap this up?

01:03:02.225 --> 01:03:04.065
<v Speaker 2>Just always welcome the feedback. Like, even just

01:03:04.065 --> 01:03:05.825
<v Speaker 2>your couple notes on notation and the pain

01:03:05.825 --> 01:03:07.665
<v Speaker 2>points and where that would be good. So,

01:03:07.665 --> 01:03:09.345
<v Speaker 2>yeah, if anybody has any feedback from this

01:03:09.345 --> 01:03:10.865
<v Speaker 2>session, things that you'd like to dive you

01:03:10.865 --> 01:03:12.065
<v Speaker 2>deeper in or questions,

01:03:12.305 --> 01:03:13.745
<v Speaker 2>you know, feel free to reach out to

01:03:13.745 --> 01:03:16.145
<v Speaker 2>us. We're both on many different social media

01:03:16.145 --> 01:03:16.465
<v Speaker 2>platforms.

01:03:17.660 --> 01:03:19.020
<v Speaker 2>So you can you can find us in

01:03:19.020 --> 01:03:21.420
<v Speaker 2>all those places. But, yeah, just mainly feedback

01:03:21.420 --> 01:03:24.300
<v Speaker 2>if anybody has any. More more than welcome

01:03:24.540 --> 01:03:25.500
<v Speaker 2>to take that in.

01:03:26.060 --> 01:03:28.540
<v Speaker 1>Alright. And for everyone watching this not live,

01:03:28.540 --> 01:03:29.900
<v Speaker 1>all of the links and things that we

01:03:29.900 --> 01:03:32.300
<v Speaker 1>have discussed will be in the description soon.

01:03:32.300 --> 01:03:33.845
<v Speaker 1>I'm not gonna put time on that very

01:03:33.845 --> 01:03:36.165
<v Speaker 1>soon. So go check them out and please

01:03:36.165 --> 01:03:38.484
<v Speaker 1>feedback to the projects. The GitHub links will

01:03:38.484 --> 01:03:40.085
<v Speaker 1>also be in the show notes below.

01:03:40.244 --> 01:03:42.085
<v Speaker 1>Alright. Thank you both so much for taking

01:03:42.085 --> 01:03:43.365
<v Speaker 1>time out for your day to join us.

01:03:43.365 --> 01:03:44.965
<v Speaker 1>Those are great demos,

01:03:45.125 --> 01:03:47.850
<v Speaker 1>revealing aspects of cloud native and ORAZ and

01:03:47.850 --> 01:03:48.810
<v Speaker 1>notation

01:03:49.370 --> 01:03:51.050
<v Speaker 1>that I think people should just go and

01:03:51.050 --> 01:03:52.250
<v Speaker 1>kick the tires on it and try it

01:03:52.250 --> 01:03:54.250
<v Speaker 1>out and definitely provide feedback. So thank you

01:03:54.250 --> 01:03:55.770
<v Speaker 1>both again, and I I hope you both

01:03:55.770 --> 01:03:57.690
<v Speaker 1>have a lovely day and a lovely week.

01:03:57.690 --> 01:04:00.330
<v Speaker 2>Thank you. Thanks for having us. Thank you,

01:04:00.330 --> 01:04:00.570
<v Speaker 3>everyone.

01:04:01.555 --> 01:04:02.115
<v Speaker 1>Bye, all.

01:05:05.640 --> 01:05:08.440
<v Speaker 0>Native patterns are sure to please.

01:05:09.319 --> 01:05:09.720
<v Speaker 0>Thank

01:05:10.839 --> 01:05:12.599
<v Speaker 0>you for watching

01:05:12.760 --> 01:05:14.599
<v Speaker 0>R OCI show.

01:05:14.680 --> 01:05:17.480
<v Speaker 0>Your support helps Rawkode

01:05:51.015 --> 01:05:51.735
<v Speaker 0>Thank

01:06:02.455 --> 01:06:05.815
<v Speaker 0>you for watching

01:06:34.799 --> 01:06:37.119
<v Speaker 0>Doctor.

01:06:37.119 --> 01:06:37.919
<v Speaker 0>KELLY:
